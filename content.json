{"meta":{"title":"乌龙波霸七分甜","subtitle":"每一个不曾起舞的日子，都是对生命的辜负","description":null,"author":"malizhen","url":"http://malizhen.github.io"},"pages":[{"title":"about","date":"2019-06-10T07:49:26.000Z","updated":"2019-06-10T08:18:05.956Z","comments":true,"path":"about/index.html","permalink":"http://malizhen.github.io/about/index.html","excerpt":"","text":""},{"title":"tags","date":"2019-06-06T02:48:25.000Z","updated":"2019-06-06T02:49:08.153Z","comments":true,"path":"tags/index.html","permalink":"http://malizhen.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Data Compression Techniques for Cache and Main Memory","slug":"Compression","date":"2019-06-26T06:57:53.000Z","updated":"2019-06-28T06:47:55.702Z","comments":true,"path":"2019/06/26/Compression/","link":"","permalink":"http://malizhen.github.io/2019/06/26/Compression/","excerpt":"","text":"最近读了比较多的关于数据压缩的论文，具体的论文阅读记录后续会慢慢抽时间写出来，本文先对最近所读简单地进行一个归纳与总结。主要按照以下目录分几个方面来进行总结。 Motivation 现在的应用程序多为数据密集型； 内存需求近些年一直在增加； 而DRAM作为最常见的系统内存，存储密度低，简单来说就是，目前单个DRAM芯片的集成度已经接近极限，远不能满足大数据对内存容量TB级甚至PB级的需求。显然，数据压缩技术对于未来的系统是必不可少的。 Benefits of Data Compression为什么研究数据压缩，肯定是因为有好处，有前景，那么有哪些好处呢？ 不增加内存大小，就能获得更多的有效容量； 避免内存溢出：尤其适用于嵌入式系统； 减少缺失率和带宽占用； 节省能耗，在能耗相同的情况下，能够做更多的计算。 此外，在NVM和3D内存中尤其适用，能够： 减少写数据量和写能耗； 减轻NVM的耐力问题； Storage Compression(例如，缓存压缩)：减少数据存储能耗 Bandwidth Compression：减少数据移动能耗 Opportunities for Compression就目前研究来看，什么情况下什么类型的数据经常被压缩？ 常量、数据复制和赋值 使用公共值初始化 较大的数据类型用于存储较小的数据 特殊值的大量出现，如0,1 以上情况下的数据有很大的冗余，能够考虑利用压缩来消除冗余，具体是什么类型的数据用下图程序段来举例说明。 图片 目前有很多利用图片中相邻像素点值差异很小这一特点来进行的相关研究。 针对以上前四种数据类型，很多论文中有专业的名词来表示它们，分别是Other Patterns、Repeated Values、Narrow Values、Zero Values。 Challenge in using Compression任何一种技术都不可能十全十美，那么压缩有啥坏处呢？ 有压缩那就对应地有解压缩，而压缩和解压缩都会产生额外的延迟和能耗，压缩延迟不在关键路径上，但是解压缩延迟位于缓存命中的关键路径上，对性能影响很大。 往往现有的压缩率高的压缩算法，对应的就会有复杂的硬件设计，同时有很高的解压延迟开销。 压缩仅在最后一级cache和main memory中有用，因为在L1 cache中存储压缩数据，由于解压缩带来的延迟开销无法接受。 由于压缩是变长的，使得不同cache line的压缩不能并行。 有些技术单独存储未压缩的line，由于复杂的硬件设计会造成很重的开销。 存在某些不可压缩的数据(如加密数据)或低效的压缩算法。 压缩块大小不是固定的，这会使得后续寻址变得困难，因为压缩前原有的线性映射会发生变化，或者由于压缩产生碎片可用空间。 删除和插入数据的大小可能不同，导致替换策略变得复杂。 最重要的一个问题，会或多或少产生额外的元数据，带来额外的存储开销。 如果应用程序内存占用已经很小，压缩没有多大用处，如果内存占用较大，则压缩提供的额外容量也不够，这样来看怎么压缩好像显得有点鸡肋？ Need of Carefully Choosing Data-Block Size如何选择压缩数据块的大小，即压缩粒度怎么决定？越大越好or越小越好？ 大的数据块大小作为压缩粒度：大块内会有更高的冗余，似乎还能够获得更高的压缩比，而且元数据存储开销也会比较低。但是即使只访问大块（例如，2KB）之中的某一个子块（例如，64B），也需要解压整个大块，产生无谓的解压开销，而这很影响性能。此外，在大块内想要找到特殊的模式（例如全为零）比较困难。 小的数据块大小作为压缩粒度：与以上相反，此优点为彼缺点吧！值得注意的是，tag元数据存储开销会大大增加。 因此可以看出，压缩粒度的选择需要根据不同类型应用程序动态选择。 Some Compression Algorithm Huffman coding Lempel-Ziv (LZ) algorithm (and derivatives) X-match and X-RL Frequent value compression (FVC) Frequent pattern compression (FPC) C-PACK Base delta immediate (BDI) compression Zero-value and narrow-value detection …","categories":[{"name":"论文阅读记录","slug":"论文阅读记录","permalink":"http://malizhen.github.io/categories/论文阅读记录/"}],"tags":[{"name":"compression algorithm","slug":"compression-algorithm","permalink":"http://malizhen.github.io/tags/compression-algorithm/"}],"keywords":[{"name":"论文阅读记录","slug":"论文阅读记录","permalink":"http://malizhen.github.io/categories/论文阅读记录/"}]},{"title":"DRAM层次结构","slug":"DRAM-Hierarchy","date":"2019-06-12T13:14:01.000Z","updated":"2019-06-13T01:19:17.334Z","comments":true,"path":"2019/06/12/DRAM-Hierarchy/","link":"","permalink":"http://malizhen.github.io/2019/06/12/DRAM-Hierarchy/","excerpt":"","text":"DRAM（Dynamic Random Access Memory），即动态随机存取存储器，最为常见的系统内存。DRAM 只能将数据保持很短的时间。为了保持数据，DRAM使用电容存储，所以必须隔一段时间刷新（refresh）一次，如果存储单元没有被刷新，存储的信息就会丢失。设备关机也会丢失数据，不像磁盘硬盘等存储介质，类似于我们平时笔记本电脑的内存条。 本文对DRAM系统的层次结构，做出了比较清晰直观的解读。 DRAM系统的层次结构 该图为DRAM系统的层次结构图，从顶层到底层包含Rank、Chip、Bank、Sub-array、MAT、Cell。一个Rank由多个Chip并列组成，同步工作，共同驱动内存总线，一个Chip内部包含多个Bank，它们包含独立的行地址译码器和感应放大器，可以并发访问。通常认为，Bank是DRAM完成独立操作的最小单元。但事实上，每个Bank又可以进一步分割为很多的Sub-array（纵向），每个Sub-array包含很多MAT（横向）。每个MAT有独立的局部感应放大器。一个典型的MAT包含512*512个Cell，即存储单元。每个存储单元由一个电容和一个晶体管组成：电容的电荷多少表示数字0或1，晶体管的栅极与字线相连，由字线控制晶体管的导通；晶体管的漏极与位线相连，导通时由位线表示单元里存储的数据。 存储单元cellDRAM的内部结构可以说是PC芯片中最简单的，是由许多重复的“单元”——cell组成，每一个cell由一个电容和一个晶体管（一般是N沟道MOSFET）构成，电容可储存1bit数据量，充放电后电荷的多少（电势高低）分别对应二进制数据0和1。由于电容会有漏电现象，因此过一段时间之后电荷会丢失，导致电势不足而丢失数据，因此必须经常进行充电保持电势，这个充电的动作叫做刷新（Refresh），因此动态存储器具有刷新特性，这个刷新的操作一直要持续到数据改变或者断电。而MOSFET则是控制电容充放电的开关。DRAM由于结构简单，可以做到面积很小，存储容量很大。放大cell的结构，对cell进行分析，了解DRAM是如何通过电容存取数据的。 1、写入数据如图，向cell中写入数据时，将WL设置为高电平，使晶体管M处于导通状态。此时，Cs和Bitline共享电荷，对Cs进行充电，电压升高到Vs，Bitline处于高电平，写入1；对Cs进行放电，电压降到0，Bitline处于低电平，写入0。 2、读取数据从cell中读取数据时，同样，首先将WL设为高电平，使晶体管M处于导通状态，逻辑电路通过Bitline感知Cs电荷的重新分配，从而读取数据。具体过程如下：首先，对Bitline进行Precharge，即将Bitline上的电压升到Vs/2，这样的话一旦M处于导通状态，如果cell中保存了1，那么Cs中电压为Vs，与Bitline上电压存在电压差，电荷会从Cs流出到Bitline，使Bitline上的电压升高。cell之外的一个逻辑电路块可以感知这种变化，从而读出数据1。同理，若cell保存的是数据0，那么Cs中电压为0，则Bitline中电荷流出，电压降低，电路感知到这种变化，读出数据0。 注意：由于这种读取操作造成电荷的流入流出，是破坏性的。因此，读操作之后需要Refresh操作，恢复Cs的电荷状态。","categories":[{"name":"存储","slug":"存储","permalink":"http://malizhen.github.io/categories/存储/"}],"tags":[{"name":"DRAM","slug":"DRAM","permalink":"http://malizhen.github.io/tags/DRAM/"}],"keywords":[{"name":"存储","slug":"存储","permalink":"http://malizhen.github.io/categories/存储/"}]},{"title":"VSCode:Remote-SSH配置","slug":"VsCode","date":"2019-06-10T01:54:25.000Z","updated":"2019-06-10T13:05:58.565Z","comments":true,"path":"2019/06/10/VsCode/","link":"","permalink":"http://malizhen.github.io/2019/06/10/VsCode/","excerpt":"","text":"最近VScode发布了远程编程与调试的插件Remote Development，使用这个插件可以在很多情况下代替vim直接远程修改与调试服务器上的代码，就和在本地使用VScode一样。终于不用在服务器端翻来覆去的配置vim插件了，同时服务器端的比如tmux配置可以原封不动地在本地VScode使用。本文介绍配置的过程以及如何在本地通过ssh的方法连接到远程机器上。 配置过程安装VScode原本Remote-SSH这个插件仅支持VSCode的Insider版本（2019.5.8发布），所以你需要下载VSCode的Insider版本 安装过程很简单，直接下一步直到完成，然后在扩展搜索remote ssh点击安装。 安装完成后侧边栏会出现新的图标。 客户端服务器端SSH配置在本地机器（我这里是自己的windows宿主机），后文称为客户端，安装的vmware虚拟机称为服务器端（Linux）。 1、首先在客户端安装ssh 打开计算机设置页面 选择应用-应用和功能-管理可选功能，安装OpenSSH客户端 在客户端左下角搜索输入cmd，命令行输入ssh-keygen -t rsa，输入你想要放置SSH密钥对的目录，这里一般不更改，一直enter直到结束即可，最后在`c:\\user目录下生成密钥文件id-rsa和id-rsa.pub，第一个是私钥文件，第二个是公钥文件。 2、接下来将客户端的公钥内容添加到服务器端，步骤如下： 首先检测ssh服务是否启动 ： netstat -ntlp | grep ssh 如果ssh服务没有启动 ：/etc/init.d/ssh resart 方法一： 手动创建.ssh文件夹如下所示，我这里已经建好了，只是截图展示一下文件位置，并在.ssh文件夹下创建文件authorized_keys，将客户端公钥复制进去。这里注意文件权限可能需要修改。 1) .ssh目录的权限必须是700 2) .ssh/authorized_keys文件权限必须是600 下图第一列就是文件权限。 修改配置文件：vim /etc/ssh/sshd_config，把PubkeyAuthentication配置为 yes ，允许使用基于密钥认证的方式登录。 方法二： 也可以通过ssh-copy-id的方式，需要在客户端安装bash，cmd无法识别linux命令。可以将公钥复制到远程机器。 1$ ssh-copy-id -i .ssh/id_rsa.pub 用户名@192.168.x.xxx 远程连接如图选择文件目录，这是让你选择你的config文件放在哪里，必须放在客户端密钥文件夹下 配置文件内容很简单，就两行 123$ Host alias $ HostName 1.1.1.1 #服务器的ip，服务器终端输入ifconfig命令查看inet地址 $ User username #远程服务器的用户名，其实就是你的虚拟机终端前面显示的用户名 配置完成，选择在当前窗口开启连接 连接成功，左下角会如下图所示 接下来可以导入服务器端的项目，选择编辑栏File-Open Workspace，成功导入项目 VSCode更新一个功能如果只能针对特定版本可用，那就谈不上任何方便了。因此不到一个月VSCode版本发布了更新，目前的VSCode 1.35支持Remote SSH配置，需要可官网下载下载链接，若已下载老版本，点击菜单栏Help-Check for Updates进行更新，重启即可生效，然后同样的安装Remote - SSH，密钥已经配置好了，只需再选择Config文件，就能够远程连接上服务器，配置完成之后，每次开启服务器之后，在客户端开启VSCode就会自动连接上服务器，很方便。","categories":[{"name":"搭建与配置","slug":"搭建与配置","permalink":"http://malizhen.github.io/categories/搭建与配置/"}],"tags":[{"name":"VSCode","slug":"VSCode","permalink":"http://malizhen.github.io/tags/VSCode/"}],"keywords":[{"name":"搭建与配置","slug":"搭建与配置","permalink":"http://malizhen.github.io/categories/搭建与配置/"}]},{"title":"Base-Delta-Immediate Compression","slug":"Base-Delta-Immediate Compression","date":"2019-06-06T01:56:23.000Z","updated":"2019-06-13T13:50:47.451Z","comments":true,"path":"2019/06/06/Base-Delta-Immediate Compression/","link":"","permalink":"http://malizhen.github.io/2019/06/06/Base-Delta-Immediate Compression/","excerpt":"","text":"Base-Delta-Immediate Compression:Practical Data Compression for On-Chip Caches。原文链接很多基于软件的缓存压缩算法主要有两大缺点：造成很高的硬件复杂度；无法接受的解压延迟。本文提出了一种新的压缩算法Base-Delta-Immediate (B∆I) ，关键思想是：大多数cache line有一个特点，同一cache line中存储的数据差异很小。基于这一观察，cache line的数据可以用一个基值（Base）+ 一组差异值（Delta）来表示，所需存储空间必然会比原始cache line大小小得多。 背景为了缓解CPU和主存之间速度不匹配的问题，在主存与CPU之间插入一级或多级cache。然而cache并不是越大越好，虽然更大的cache通常会带来更少的cache miss，但是这种好处是以更长的访问延迟、更大的cache面积（昂贵）和更大的功耗为代价的。 基于这些限制，为了提高cache的利用率，可能会想到通过数据压缩来减少数据量，然而数据压缩并没有被现代商用微处理器作为一种提高有效缓存容量的方法，为什么？理想的缓存压缩技术应该是快速（压缩/解压延迟低）、简单（硬件复杂度低）、高效（高压缩率）的，而如果在商用微处理器中采用缓存压缩，会面临的最大障碍可能是解压延迟，解压与压缩不同，压缩是在缓存写入时(在提供关键字之后)在后台进行的，而解压缩位于cache hit的关键路径上，在此路径上最小化延迟对于性能非常重要。 因此，快速、简单、高效的缓存压缩方案，不可兼得，怎么办？只能权衡得到最佳方案，要么压缩率低、要么硬件复杂度高、要么解压延迟高，总会有缺陷，方案是否可行就看好处是否大于坏处，为了在降低硬件复杂度和解压缩延迟的同时达到显著的压缩比，本文提出了一种新的缓存压缩技术Base-Delta-Immediate(B∆I)压缩。 BASE + DELTA ENCODING: BASIC IDEA基于两个特点： 数据在内存中分配的规律性（相似的数据值和类型分组在一起）。 缓存/内存数据的动态范围较低（例如，同一cache line的数据差异很小）。 设计了Base+Delta 压缩方案，通过存储一个Base和一组Delta来减少冗余从而提高Cache line的利用率。接下来通过两个直观的例子来更好地理解。 应用程序h264ref的32-byte cache line利用Base+Delta 方案压缩如上图所示，该cache line包含一组（8个）以4字节整数形式存储的窄值。 1窄值是使用大数据类型存储的小值。例如，一个one-byte的值存储为一个four-byte整型数。程序员通常在各种数据结构中以最坏的情况为标准提供数据类型，即使大多数数值可能适合较小的数据类型。 从Figure 3我们看到，cache line通过一个全0的base+一组八个1-byte的差异值即可表示所有存储的数值，只要4+8*1共12 byte就能表示整个cache line，这样消除冗余之后相比原来节省了20 byte的空间。看到这里就很容易联想到一个问题，如果说base的byte数太大，差异值节省出来的空间不够多，那么压缩还不如不压缩对不对？这个问题作者在下文考虑到了，base数目、base字节数、差异值的字节数多少才最合适？选择哪个value做base效果会一样吗？不一样的话那如何确定呢？都是我们需要考虑权衡的点。 由Figure 4，在perlbench应用程序负载上，同样是一个32-byte的cache line，存储的是pointer，可以看到，同一cache line的pointer值依然具有很高的相似度。 注意：虽然这里例子使用的是32-byte的cache line，最后实验评估部分有考虑更常见的64-byte cache line。 Compression Algorithm关于该算法的具体描述，论文里面给出了公式（貌似有误，反了），也很容易理解，就是通过简单的向量减法得到Delta。 1∆i = Vi - B* ，其中V表示原始值的集合，∆表示差异值的集合，B*表示base值，若cache line的大小为C byte，其中每个value的大小为k byte，那么i的取值为1~C/k 这里有两个观察： 若存在任意一个Vi和所选base相似度为0，即Delta(i)的大小等于k，那么该缓存行不能压缩。因为本来引入base就加重了开销，压缩效果不好不如不压缩。 如何确定哪个value被选为base？要么Vi的最小值或最大值，要么中间值，被认为是最佳的。理论上是这样的，实际上的做法呢？ 我们除了确定base，还需要确定k，即每个value的大小，决定了一个cache line能容纳多少个value。 Determining kk在2、4、8之间选择最佳压缩率的k值。选择2、4、8是因为几乎所有由各种编程语言支持的基本数据类型都有这三种大小之一。 Determining B*B*可以依据上述观察2来选取，然而，用这种方式寻找base需要计算原始集合的最大value与最小value，这会大大增加硬件的逻辑复杂度，并且会明显增加压缩延迟。所以为了简单起见，选择第一个value作为base即可，并且实验表明，压缩率相比选择理论最优base降低仅仅0.4%，很微不足道了，并且还不会增加硬件复杂度以及压缩延迟。 Decompression Algorithm通过B*和∆的值能够计算得到V，实现解压： 1Vi = ∆i + B* 因此，cache line中的值可以使用SIMD-style的向量加法器并行计算得到。即使用一组简单的加法器，可以在执行整数向量加法所需的时间内解压缩整个cache line。 B∆I COMPRESSION前一部分介绍了Base + Delta，以此为基础怎样能够更完善我们的压缩算法呢？ 因为尽管B+∆被证明适用于大多数的应用程序，但是不可能所有的cache line都能用这种形式来表示，有一些基准测试压缩率就不见得好，比如mcf。这是因为有些应用程序在同一cache line中间可能混合有不同类型的数据，比如指针和1-byte的整数。这种情况下，很显然，如果我们选取多个base，一种类型一个base的话是不是压缩效果会好很多呢？ 如Figure 5所示，我们发现对于在同一cache line可能存储着不同类型的数据的应用程序，多个base压缩效果会更好，但是这会造成更大的base存储开销，所以，存在一个tradeoff，因为显然不是多个base一定会更好，那么选取多少个base才是最优的呢？ 光说都是没有依据的，通过实验来说话，作者设计了一个实验，评估了选择不同数量base(使用贪婪算法依次选择次优base)的有效压缩比，Figure 6展示了实验结果。 结果表明，就有效压缩比而言，经验上最优的base个数是2，虽然少数benchmark在1或3个base上也有最优，最后的结论还是B+∆在两个base的情况下，性能明显优于B+∆在base为1时(压缩比平均为1.51:1.40)，说明值得考虑实现。结果还表明有两个以上的base并不会为这些工作负载提供额外的压缩比改进，因为存储更多的base的开销要高于压缩更多cache line的好处。 注意：Figure 6中我们发现有0个base，这很必要，因为如果不考虑0个base，对于比如说最简单的全0数据，如果使用简单的压缩去冗余，不需要base，直接压缩到1byte，而base越多，显然，压缩率越低，并且增大存储开销。 那么，如何高效地找到两个base？不增加硬件的复杂度，或者说如何以最小的硬件复杂度寻找两个base来获得最大的压缩好处？下一节介绍 B∆I: Refining B+∆ with Two Bases and Minimal Complexity我们发现，第二个base直接设置为0能够和任意选取任何一个vaule作为第二个base一样，为什么会这样？因为大多数情况下，是动态范围较小的宽值（比如指针）与窄值（比如小整数）混合，那么第一个base可以使用base+delta编码压缩动态范围较低的宽值，而第二个0 base则可以有效地压缩窄值。基于这一观察，我们额外增加一个隐式（implicit）的0 base来改进B+∆，称为Base-Delta-Immediate或B∆I压缩。 那么两个base的B+∆好还是B∆I好呢？又存在tradeoff。显然，B∆I有一个base是隐式的0，存储开销更小，这意味着对于用这两种技术都可压缩的cache line，B∆I的平均压缩率可能更高。有两个base的B+∆需要更多的存储空间来存储第二个base，但是可以压缩更多的cache line，因为base可以是任何value，从中选择最佳。到底哪个好呢？可能取决于cache line的模式，甲之砒霜，乙之蜜糖。关键时刻依然还是得实验来说话 Figure 7表明，虽然有个别负载B+∆的表现比B∆I好，但是总体来说还是B∆I的压缩比（1.53）高于B+∆（1.51），虽然不是高太多，但是考虑到B+∆有两个base，那就有比B∆I更复杂的硬件机制，所以认为缓存压缩设计还是应该基于B∆I的思想。 DesignCompress在具体的设计中，所有的可能压缩大小是静态已知的，如Table 2。如果cache line有多个压缩选项可用(例如，8-byte base 1-byte ∆或者Zeros压缩)，则Compression Selection 选择压缩cache line大小最小的一个（即选择压缩率最高的）。基于Table 2选择合适的压缩大小，Figure 8中所有压缩单元可并发执行。 Figure 9展示了32-byte的cache line在8-byte-base 1-byte-∆时压缩单元的情况，每个V通过减法器进行运算之后，判断是否每个V的运算结果∆前七位均为0或者1，如果是的话，cache line能够以该种模式（8-byte-base 1-byte-∆）存储，否则，说明至少有一个∆不能用1-byte表示，那么不压缩该cache line。 Decompress解压的硬件设计很简单，如上文描述一样，就是一个减法器。如下图所示 关于实现的更多细节，以及实验部分，如果感兴趣的话可以阅读原文，本文的分析重在了解基本思想。","categories":[{"name":"论文阅读记录","slug":"论文阅读记录","permalink":"http://malizhen.github.io/categories/论文阅读记录/"}],"tags":[{"name":"compression algorithm","slug":"compression-algorithm","permalink":"http://malizhen.github.io/tags/compression-algorithm/"}],"keywords":[{"name":"论文阅读记录","slug":"论文阅读记录","permalink":"http://malizhen.github.io/categories/论文阅读记录/"}]},{"title":"重庆四人游","slug":"Chongqing","date":"2019-06-06T01:44:35.540Z","updated":"2019-06-10T13:22:21.820Z","comments":true,"path":"2019/06/06/Chongqing/","link":"","permalink":"http://malizhen.github.io/2019/06/06/Chongqing/","excerpt":"","text":"2018年5月1日的前一天，我的小Z突然问我想不想五一去重庆，距离我俩上次旅行已经过去快三年，贫穷的大学时期，只是在2015年八月底去了一趟凤凰，好在自从小Z毕业工作以来，似乎异地恋也不再受限于没钱见面，哈哈哈，虽然自从我读研以来科研才是他的情敌。于是有了这次说走就走的旅行。 前期准备出行方式的选择我们总共四个人，小姜和他女朋友都在湖南，小Z也是，我在武汉，所以最后我们决定长沙会合，然后坐飞机去重庆。买的五一当晚11点长沙到重庆的特价机票，票价不贵，500元左右，不同买票软件不一样，我发现的最实惠的是智行，比携程飞猪等少大概80。这里真的要吐槽一下西部航空，返程买的奥凯航空，对比起来简直一个天上一个地下，西部航空没有免费行李托运额度，奥凯航空有，而且有充饥曲奇饼和水，hhh，曲奇饼超好吃，可惜产地俄罗斯，淘宝没找到有卖的。 还有，第一次坐飞机我发现自己不仅晕车居然还晕机，所以晕车的小伙伴坐飞机的话一定记得吃药。话说不管哪个航空公司空姐都人美心善，因为晕机不舒服，下飞机的时候满脸不开心，得到了空乘小姐姐的大大的笑容问候。 关于住宿全程不到两个小时，所以看来比起火车虽然贵点，但是性价比真是不知道高多少。5月1日抵达重庆的时候已经是次日凌晨，所以当晚的住宿定在江北国际机场附近，首选有接机服务的酒店，1日晚的酒店很一般，而且由于五一价钱还不便宜，接近三百，就不说店名了。因为商圈附近住宿都很贵，两个男孩子不想住民宿，最后2日晚选择住宿在南坪，南坪轻轨站附近的金凯斯精品酒店，接近三百一晚，酒店有些陈旧，但是房间面积很大，虽然这并没什么用，卫生间很小，期间马桶还坏了，不过胜在位置很好，从机场坐轻轨到南坪，轻轨站一出来就能看到这家酒店。五一这个价钱只能说无功无过吧。 之后的两个晚上住在我们东道主煦煦家哈哈哈，这就有了接下来几天连续爆肝用生命没日没夜地浪的契机hhhh。 咳咳咳正文来了去重庆之前做的攻略，在有了李导（煦煦）加持之后都是浮云了，吃了超级正宗的重庆火锅，啊哈好像叫大队长火锅，晚上在路边摊吃的烧烤，虽然菜都从牵牵上弄下来变成了大锅菜的样子，卖相不太好，但是味道真的很棒。 去了各大网红景点，包括洪崖洞、解放碑、磁器口还有南山一棵树风景区。一个一个说吧，洪崖洞解放碑在一起，就晚上去夜景真的很棒，虽然洪崖洞不知道在地下多少层，当时人山人海，没有电梯，排队进入口，然后一层一层的楼梯走到腿快废了。 解放碑就是那种来了就必去拍张照的地方，hhh，我当时竟然有一种武汉大学校门口的错觉，永远好多人对着那个国立武汉大学咔擦咔擦。 磁器口吧，有点不是很推荐，在一个在武汉待了五年的人看来，它就是另一个户部巷，一条小吃街也卖一些小玩意，东西很难吃而且很贵，不过有个酒庄老板超好，免费尝了好多酒，要不是坐飞机不能带，当时超想买一小罐女儿红。以上地方总结起来就是五一真的超级多人，多到无法想象的那种，寸步难行。 4号晚去的南山一棵树，因为假期最后一天，人不多，打车过去的，晚上俯瞰重庆夜景很美，基本照片都在这拍的hhh，原本计划去川美涂鸦一条街拍照的，最后时间不够了。 5号租车去了奥陶纪，我们总共五个人，租车比跟团划算而且更方便，这里还是很推荐的，感觉像张家界和大型欢乐谷的结合体，有玻璃桥有很多高空项目，室内冰雪世界很美，虽然这个地方被抖音带火的，这两年才出名，还是去得很值。 最后记了一堆流水账，最后想要矫情一下，旅途中的情侣难免会有些小矛盾，不过和小Z在一起的六年以来，很感谢他每次包容我的小性子，有时候觉得，遇到一个三观相合而且三观超正的小奶狗，只想每天多爱对方一点点，也许这就是那啥操蛋的异地恋维持的新鲜感吧，hhhh！","categories":[{"name":"随笔","slug":"随笔","permalink":"http://malizhen.github.io/categories/随笔/"}],"tags":[{"name":"旅游","slug":"旅游","permalink":"http://malizhen.github.io/tags/旅游/"}],"keywords":[{"name":"随笔","slug":"随笔","permalink":"http://malizhen.github.io/categories/随笔/"}]}]}