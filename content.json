{"meta":{"title":"乌龙波霸七分甜","subtitle":"每一个不曾起舞的日子，都是对生命的辜负","description":null,"author":"malizhen","url":"http://malizhen.github.io"},"pages":[{"title":"tags","date":"2019-06-06T02:48:25.000Z","updated":"2019-06-06T02:49:08.153Z","comments":true,"path":"tags/index.html","permalink":"http://malizhen.github.io/tags/index.html","excerpt":"","text":""},{"title":"about","date":"2019-06-10T07:49:26.000Z","updated":"2019-06-10T08:18:05.956Z","comments":true,"path":"about/index.html","permalink":"http://malizhen.github.io/about/index.html","excerpt":"","text":""}],"posts":[{"title":"Frequent Pattern Compression","slug":"FPC","date":"2019-07-01T12:39:37.000Z","updated":"2019-07-02T08:29:21.577Z","comments":true,"path":"2019/07/01/FPC/","link":"","permalink":"http://malizhen.github.io/2019/07/01/FPC/","excerpt":"","text":"Frequent Pattern Compression: A Significance-Based Compression Scheme for L2 Caches（ 原文链接）。随着处理器和内存速度之间差距的扩大，内存系统设计人员可能会发现缓存压缩有利于增加缓存容量和减少片外带宽。大多数硬件压缩算法都属于基于字典的类别，这依赖于构建字典并使用其条目对重复数据值进行编码，在压缩大数据块和文件时非常有效。然而，cache line通常为32-256 bytes，每行字典的开销很大，这限制了这种算法的可压缩性，并增加了解压缩延迟。对于这样的短行，基于重要性的压缩可以考虑。 本文提出并评估一种简单的基于重要性的压缩方案，该方案具有较低的压缩和解压缩开销。该方案使用带适当前缀的压缩格式存储常见的word模式，从而按word逐行压缩cache line。提出一种压缩缓存设计，其中数据以压缩形式存储在L2中，但在L1中未压缩。L2被压缩到预先确定的大小，以减少解压开销。 基于重要性的压缩基于这样的观察：大多数数据类型(例如，32位整数)可以存储在比允许的最大位数更少的位中。即窄值与0值大量存在。与基于字典的压缩方案相比，基于重要性的压缩不会产生每行字典开销，这使得它更适用于典型的短缓存行。此外，压缩和解压硬件比基于字典的编码和解码要快。然而，对于长缓存行，可压缩性可能会显著降低。 Frequent Pattern Compression每个cache line被分成一些32-bit大小的word(例如，64-byte的cache line分成16个word)。表1显示了每个前缀对应的不同模式。这些模式是根据许多商业基准测试中的高频模式选择的。每个32-bit的word都根据模式表被编码为一个3-bit前缀加上数据的压缩格式。 与这些模式都不匹配的word以其原始的32位格式存储。如果某个word与表1前七行中的任一模式匹配，则将其编码为压缩格式。 Segmented Frequent Pattern Compression与未压缩相比，L2 cache必须能够在相同的空间中容纳更多的压缩cache line。这就会导致原本的线性映射被破坏，或者产生碎片可利用空间。最常见的解决这一问题的办法是解耦缓存访问，在address tag与data storage之间添加间接层。 理论上，cache line可以压缩成任意数量的bit。然而，这种设计增加了缓存管理的复杂性。本文的压缩缓存设计中，每个缓存行存储为一组8-byte segemnt。例如，64-byte的cache line一定能够被存储为1-8个segment，未压缩为8个8-byte segment。压缩的cache line，填充0，直到其大小变为段大小(8 byte)的倍数，这些额外的0(与任何tag不对应)在解压缩期间被忽略。虽然这种方法可能在某些模式下不具有高压缩比，比如，全0的情况下，但是它能够更快地实现缓存访问。 Compression and Decompression本文提出了一种压缩缓存设计，其中未压缩数据存储在L1中，压缩数据存储在L2中。这有助于减少许多阻碍性能的L2缓存缺失，同时不影响L1缓存的命中。然而，这样的设计增加了在两个级别缓存之间移动时压缩或解压的开销。而FPC能够尽可能降低压缩与解压开销。 Compressioncache line压缩发生在数据从L1写到L2时。使用一个简单的电路(并行地)检查每个word的模式匹配，如果一个word匹配七个可压缩模式中的任何一个，就使用一个简单的编码电路将word编码成最紧凑的形式。如果没有找到匹配项，则将整个word存储为前缀“111”。对于zero run，需要检测连续运行的零，并递增第一次出现的数据值来表示它们的计数。由于本文的设计中zero run被限制为8个零，这可以在一个循环中使用一个简单的多路复用器/加法器电路来实现。cache line压缩可以在内存管道中实现，方法是在L1到L2的写路径上分配三个管道阶段(一个用于模式匹配，一个用于zero run编码，一个用于收集压缩行)。一个包含少量压缩和非压缩形式条目的小受害者缓存可以用来隐藏L1写回时的压缩延迟。 Decompression当数据从L2读取到L1时，会发生cache line解压缩。解压延迟非常重要，因为它被直接添加到L2 hit延迟中。解压缩比压缩慢，因为cache line中所有word的前缀都必须按顺序访问，因为每个前缀用于确定其对应的编码word的长度，从而确定所有后续压缩word的起始位置。 下图展示了一种可用于解压64-byte cache line的五阶段硬件管道。","categories":[{"name":"论文阅读记录","slug":"论文阅读记录","permalink":"http://malizhen.github.io/categories/论文阅读记录/"}],"tags":[{"name":"compression algorithm","slug":"compression-algorithm","permalink":"http://malizhen.github.io/tags/compression-algorithm/"}],"keywords":[{"name":"论文阅读记录","slug":"论文阅读记录","permalink":"http://malizhen.github.io/categories/论文阅读记录/"}]},{"title":"Gem5简介","slug":"Gem5","date":"2019-06-28T06:51:26.000Z","updated":"2019-06-28T07:07:08.096Z","comments":true,"path":"2019/06/28/Gem5/","link":"","permalink":"http://malizhen.github.io/2019/06/28/Gem5/","excerpt":"","text":"Gem5是一款模块化的离散事件驱动全系统模拟器，它结合了M5和GEMS中最优秀的部分，M5提供了高度可配置的模拟框架，支持多种ISAs和CPU模型；GEMS补充了M5的特性，提供了详细而灵活的内存系统，包括多种cache 一致性协议和互连模型，是一款高度可配置、集成多种ISA，多种CPU模型的体系结构模拟器。 gem5模拟器目前支持多种ISAs，包括Alpha、ARM、MIPS、Power、SPARC和x86。模拟器的模块性允许这些不同的ISAs插入到通用CPU模型和内存系统中，而不需要为每一种ISAs设置一种专用的CPU模型和存储模型，这使得模拟器模块化程度较高且易于在不同CPU之间切换。 M5是由Michigan大学开发的一款开源的多处理机模拟器，受到了业内的广泛关注，很多高水平论文都采用M5作为研究工具。另一方面，Wisconsin推出的GEMS能够对储存层次进行详细而灵活的模拟，包括对多种不同的cache一致性协议和互联模型的支持。目前的GEM5是M5和GEMS的一个紧耦合版本。 1.总体目标gem5模拟器的目标是成为一个用于体系结构建模的优秀工具。这一目标的三个关键方面是灵活性，可用性，高度可协作性。 图一 Speed vs. Accuracy 1.1 灵活性灵活性是一个好的模拟器的基础。当一个想法从概念落地到一个特定的设计时，程序员需要一个工具来评估系统，平衡仿真速度和准确性。不同类型的实验可能有不同的模拟要求。例如，某些实验可能需要一个精细的CPU模型，但是没有必要进行多核建模。而某些实验可能需要多个CPU，但是这些CPU不需要太多的细节。所以模拟器的灵活性必不可少，使得程序员能够以更少的开销更快地完成更多的工作。 gem5模拟器就是这样一个工具，提供了各种各样的功能和组件，涵盖了仿真速度和精度之间的权衡。如图1所示。 CPU模型gem5模拟器目前提供了四种不同的CPU模型：AtomicSimple、TimingSimple、InOrder和O3。AtomicSimple和TimingSimple是非流水线CPU模型，AtomicSimple是一种最小的单IPC CPU模型，适用于快速功能模拟；TimingSimple与之类似，但是使用了存储器访问时序模型，用以统计存储器访问延迟；InOrder是一个按序流水线CPU模型，该模式下，可以配置硬件支持的线程数量；O3是一个乱序流水线CPU模型，可以支持超标量结构和SMT。InOrder与O3都是execute-in-execute（指令的执行只在执行阶段）的设计。 系统模式gem5支持两种执行模式：System-call Emulation（SE）和Full-System（FS）。 SE模式中，当程序执行系统调用时，gem5会捕捉到，同时模拟调用，通常是传递给主机操作系统。通过模拟大部分的系统调用，避免了对外设和OS进行建模的需要。SE模式下，没有线程调度器，线程必须静态的映射到cores，因此会限制多线程应用。SPEC CPU基准测试通常在SE模式下运行。FS（全系统）模式对一个完整系统，包括OS和外设，进行了建模，支持执行用户和内核指令。FS模式中，gem5提供了一个适合运行操作系统的裸机环境，包括中断，异常等，并不是所有ISAs都支持此模式。FS相对于SE，精度更高，可以执行更多类型的负载。虽然SPEC CPU基准测试通常在SE模式下运行，但是在FS模式下运行它们将提供与OS更实际的交互。因此需要许多OS服务或I/O设备的工作负载可能只在FS模式下运行。 存储系统支持两种存储系统模型：Classic和Ruby。Classic模型（来自M5）提供了一个快速且易于配置的内存系统；Ruby模型（来自GEMS）提供了一种灵活且能够精确模拟的内存系统，支持cache一致性。Ruby内存模型支持大量的互连拓扑结构，同时包括两种不同的网络模型。组件之间的链接使用一个简单的python文件声明，然后通过最短路径分析创建路由表。在确定链接和路由表后，根据不同的网络模型进行实现。两种网络模型为： 1、Simple网络模型：只对链接，路由延迟和链路带宽，并没有对路由器资源争用和流量控制建模。 2、Garnet网络模型：对路由建立了详细的模型，包括相关的资源竞争和流量控制。 1.2 可用性gem5用户有几种类型，每个人都有不同的目标和需求。这些人包括学术和企业研究人员、工业工程师、本科生和研究生。Gem5的开发者们希望gem5模拟器能够广泛地提供给所有这些类型的用户。gem5许可证(基于BSD)对企业用户和学术界都很友好。gem5社区非常活跃，有很多协作技术可以促进gem5的使用和开发。 2.设计特点本节重点介绍gem5实现的几个关键方面：面向对象的设计、Python集成、特定领域的语言和标准化接口的使用。 2.1 面向对象灵活性是gem5模拟器的一个重要目标，也是其成功的关键方面。灵活性主要是通过面向对象的设计来实现的。gem5模拟器中的每个主要仿真组件都是SimObjects，它们共享配置、初始化、统计和序列化(检查点)的公共行为。SimObjects包括了具体的硬件组件(如处理器内核、缓存、互连元素和外设)以及更抽象的实体(如用于系统调用仿真的工作负载及其关联的流程上下文)。这里的外设包括简单的定时器到复杂的网络接口控制器，通过使用基类来封装公共设备接口，以避免代码重复，简化实现。所有的SimObject对象都由两种类表示，python类和c++类。Python类的定义指定了SimObject的参数，并且可以在配置脚本文件中使用。公共Python基类为实例化、命名和设置参数值提供了统一的机制。C++类包含了SimObject的状态和其它行为，同时包括了关键性能的仿真模型。 2.2 Python集成gem5中的代码85%是用C++写成的，15%的Python代码主要负责SimObject的初始化、配置和模拟控制。模拟器在启动时立即开始执行Python代码，标准的main函数使用python编写，所有的命令行处理和启动代码都是python代码。 2.3 领域特定语言gem5提供了两种特定领域的语言，一种用于描述ISA（继承自M5），另一种用于描述cache的一致性协议（继承自GEMS）。 ISA DSL用于统一二进制指令的解码和它们的语义规范。gem5通过使用一个通用的C++基类来描述指令，从而实现了ISA的独立。每种ISA会重新基类中继承的方法，例如execute()。ISA描述语言允许用户简洁地指定所需的c++代码。 Cache Coherence DSLSLICC是一种DSL，用于灵活的实现cache一致性协议。SLICC目前支持AMD Opteron的基于广播的一致性协议和CMP的目录协议。SLICC将cache，mem，DMA控制器定义为单独的per-memory-block的状态机，这些状态机组合称为整个的协议。gem5中的SLICC将协议定义为一组状态、事件、转换和操作，同时将状态机特定的逻辑和协议无关的组件（例如cache）绑定在一起。gem5的SLICC会自动生成python和c++文件，同时也支持局部变量，以简化编程提高性能 2.4 标准化接口标准化接口是面向对象的基础。有两个核心的接口，端口（port）接口和消息缓冲（message buffer）接口。 1、端口接口：连接内存对象，包括cpu和caches，caches到总线，总线到外设和内存。该接口支持三种机制来访问数据，1) timing模式，用来建模带有详细时序的内存访问，会有request和response的消息机制；2) atomic模式，用来获取时序信息，但是没有消息机制，状态会直接发生变化；3) 功能模式，存储操作不会改变时序信息。 2、消息缓冲接口：Ruby使用端口接口来连接cpu和外设，同时使用消息缓冲接口连接Ruby内部对象。两个接口非常类似。 3.用户资源所有gem5模拟器的文档和信息都可以在网站http://www.gem5.org上找到。该网站包括如何检查、构建和运行gem5模拟器的说明，以及如何下载OS二进制文件和磁盘映像等补充支持文件。","categories":[{"name":"模拟器","slug":"模拟器","permalink":"http://malizhen.github.io/categories/模拟器/"}],"tags":[{"name":"gem5","slug":"gem5","permalink":"http://malizhen.github.io/tags/gem5/"}],"keywords":[{"name":"模拟器","slug":"模拟器","permalink":"http://malizhen.github.io/categories/模拟器/"}]},{"title":"Data Compression Techniques for Cache and Main Memory","slug":"Compression","date":"2019-06-26T06:57:53.000Z","updated":"2019-07-03T13:40:32.273Z","comments":true,"path":"2019/06/26/Compression/","link":"","permalink":"http://malizhen.github.io/2019/06/26/Compression/","excerpt":"","text":"最近读了比较多的关于数据压缩的论文，具体的论文阅读记录后续会慢慢抽时间写出来，本文先对最近所读简单地进行一个归纳与总结。主要按照以下目录分几个方面来进行总结。 Motivation 现在的应用程序多为数据密集型； 内存需求近些年一直在增加； 而DRAM作为最常见的系统内存，存储密度低，简单来说就是，目前单个DRAM芯片的集成度已经接近极限，远不能满足大数据对内存容量TB级甚至PB级的需求。显然，数据压缩技术对于未来的系统是必不可少的。 Benefits of Data Compression为什么研究数据压缩，肯定是因为有好处，有前景，那么有哪些好处呢？ 不增加内存大小，就能获得更多的有效容量； 避免内存溢出：尤其适用于嵌入式系统； 减少缺失率和带宽占用； 节省能耗，在能耗相同的情况下，能够做更多的计算。 此外，在NVM和3D内存中尤其适用，能够： 减少写数据量和写能耗； 减轻NVM的耐力问题； Storage Compression(例如，缓存压缩)：减少数据存储能耗 Bandwidth Compression：减少数据移动能耗 Opportunities for Compression就目前研究来看，什么情况下什么类型的数据经常被压缩？ 常量、数据复制和赋值 使用公共值初始化 较大的数据类型用于存储较小的数据 特殊值的大量出现，如0,1 以上情况下的数据有很大的冗余，能够考虑利用压缩来消除冗余，具体是什么类型的数据用下图程序段来举例说明。 图片 目前有很多利用图片中相邻像素点值差异很小这一特点来进行的相关研究。 针对以上前四种数据类型，很多论文中有专业的名词来表示它们，分别是Other Patterns、Repeated Values、Narrow Values、Zero Values。 Challenge in using Compression任何一种技术都不可能十全十美，那么压缩有啥坏处呢？ 有压缩那就对应地有解压缩，而压缩和解压缩都会产生额外的延迟和能耗，压缩延迟不在关键路径上，但是解压缩延迟位于缓存命中的关键路径上，对性能影响很大。 往往现有的压缩率高的压缩算法，对应的就会有复杂的硬件设计，同时有很高的解压延迟开销。 压缩仅在最后一级cache和main memory中有用，因为在L1 cache中存储压缩数据，由于解压缩带来的延迟开销无法接受。 由于压缩是变长的，使得不同cache line的压缩不能并行。 有些技术单独存储未压缩的line，由于复杂的硬件设计会造成很重的开销。 存在某些不可压缩的数据(如加密数据)或低效的压缩算法。 压缩块大小不是固定的，这会使得后续寻址变得困难，因为压缩前原有的线性映射会发生变化，或者由于压缩产生碎片可用空间。 删除和插入数据的大小可能不同，导致替换策略变得复杂。 最重要的一个问题，会或多或少产生额外的元数据，带来额外的存储开销。 如果应用程序内存占用已经很小，压缩没有多大用处，如果内存占用较大，则压缩提供的额外容量也不够，这样来看怎么压缩好像显得有点鸡肋？ Need of Carefully Choosing Data-Block Size如何选择压缩数据块的大小，即压缩粒度怎么决定？越大越好or越小越好？ 大的数据块大小作为压缩粒度：大块内会有更高的冗余，似乎还能够获得更高的压缩比，而且元数据存储开销也会比较低。但是即使只访问大块（例如，2KB）之中的某一个子块（例如，64B），也需要解压整个大块，产生无谓的解压开销，而这很影响性能。此外，在大块内想要找到特殊的模式（例如全为零）比较困难。 小的数据块大小作为压缩粒度：与以上相反，此优点为彼缺点吧！值得注意的是，tag元数据存储开销会大大增加。 因此可以看出，压缩粒度的选择需要根据不同类型应用程序动态选择。 Some Compression Algorithm Huffman coding Lempel-Ziv (LZ) algorithm (and derivatives) X-match and X-RL Frequent value compression (FVC) Frequent pattern compression (FPC) C-PACK Base delta immediate (BDI) compression Zero-value and narrow-value detection … Granularity of Exploiting Redundancy Across different blocks of the whole cache (also called deduplication) Across different words of a cache block Across different bytes of a cache word","categories":[{"name":"论文阅读记录","slug":"论文阅读记录","permalink":"http://malizhen.github.io/categories/论文阅读记录/"}],"tags":[{"name":"compression algorithm","slug":"compression-algorithm","permalink":"http://malizhen.github.io/tags/compression-algorithm/"}],"keywords":[{"name":"论文阅读记录","slug":"论文阅读记录","permalink":"http://malizhen.github.io/categories/论文阅读记录/"}]},{"title":"DRAM层次结构","slug":"DRAM-Hierarchy","date":"2019-06-12T13:14:01.000Z","updated":"2019-06-13T01:19:17.334Z","comments":true,"path":"2019/06/12/DRAM-Hierarchy/","link":"","permalink":"http://malizhen.github.io/2019/06/12/DRAM-Hierarchy/","excerpt":"","text":"DRAM（Dynamic Random Access Memory），即动态随机存取存储器，最为常见的系统内存。DRAM 只能将数据保持很短的时间。为了保持数据，DRAM使用电容存储，所以必须隔一段时间刷新（refresh）一次，如果存储单元没有被刷新，存储的信息就会丢失。设备关机也会丢失数据，不像磁盘硬盘等存储介质，类似于我们平时笔记本电脑的内存条。 本文对DRAM系统的层次结构，做出了比较清晰直观的解读。 DRAM系统的层次结构 该图为DRAM系统的层次结构图，从顶层到底层包含Rank、Chip、Bank、Sub-array、MAT、Cell。一个Rank由多个Chip并列组成，同步工作，共同驱动内存总线，一个Chip内部包含多个Bank，它们包含独立的行地址译码器和感应放大器，可以并发访问。通常认为，Bank是DRAM完成独立操作的最小单元。但事实上，每个Bank又可以进一步分割为很多的Sub-array（纵向），每个Sub-array包含很多MAT（横向）。每个MAT有独立的局部感应放大器。一个典型的MAT包含512*512个Cell，即存储单元。每个存储单元由一个电容和一个晶体管组成：电容的电荷多少表示数字0或1，晶体管的栅极与字线相连，由字线控制晶体管的导通；晶体管的漏极与位线相连，导通时由位线表示单元里存储的数据。 存储单元cellDRAM的内部结构可以说是PC芯片中最简单的，是由许多重复的“单元”——cell组成，每一个cell由一个电容和一个晶体管（一般是N沟道MOSFET）构成，电容可储存1bit数据量，充放电后电荷的多少（电势高低）分别对应二进制数据0和1。由于电容会有漏电现象，因此过一段时间之后电荷会丢失，导致电势不足而丢失数据，因此必须经常进行充电保持电势，这个充电的动作叫做刷新（Refresh），因此动态存储器具有刷新特性，这个刷新的操作一直要持续到数据改变或者断电。而MOSFET则是控制电容充放电的开关。DRAM由于结构简单，可以做到面积很小，存储容量很大。放大cell的结构，对cell进行分析，了解DRAM是如何通过电容存取数据的。 1、写入数据如图，向cell中写入数据时，将WL设置为高电平，使晶体管M处于导通状态。此时，Cs和Bitline共享电荷，对Cs进行充电，电压升高到Vs，Bitline处于高电平，写入1；对Cs进行放电，电压降到0，Bitline处于低电平，写入0。 2、读取数据从cell中读取数据时，同样，首先将WL设为高电平，使晶体管M处于导通状态，逻辑电路通过Bitline感知Cs电荷的重新分配，从而读取数据。具体过程如下：首先，对Bitline进行Precharge，即将Bitline上的电压升到Vs/2，这样的话一旦M处于导通状态，如果cell中保存了1，那么Cs中电压为Vs，与Bitline上电压存在电压差，电荷会从Cs流出到Bitline，使Bitline上的电压升高。cell之外的一个逻辑电路块可以感知这种变化，从而读出数据1。同理，若cell保存的是数据0，那么Cs中电压为0，则Bitline中电荷流出，电压降低，电路感知到这种变化，读出数据0。 注意：由于这种读取操作造成电荷的流入流出，是破坏性的。因此，读操作之后需要Refresh操作，恢复Cs的电荷状态。","categories":[{"name":"存储","slug":"存储","permalink":"http://malizhen.github.io/categories/存储/"}],"tags":[{"name":"DRAM","slug":"DRAM","permalink":"http://malizhen.github.io/tags/DRAM/"}],"keywords":[{"name":"存储","slug":"存储","permalink":"http://malizhen.github.io/categories/存储/"}]},{"title":"VSCode:Remote-SSH配置","slug":"VsCode","date":"2019-06-10T01:54:25.000Z","updated":"2019-06-10T13:05:58.565Z","comments":true,"path":"2019/06/10/VsCode/","link":"","permalink":"http://malizhen.github.io/2019/06/10/VsCode/","excerpt":"","text":"最近VScode发布了远程编程与调试的插件Remote Development，使用这个插件可以在很多情况下代替vim直接远程修改与调试服务器上的代码，就和在本地使用VScode一样。终于不用在服务器端翻来覆去的配置vim插件了，同时服务器端的比如tmux配置可以原封不动地在本地VScode使用。本文介绍配置的过程以及如何在本地通过ssh的方法连接到远程机器上。 配置过程安装VScode原本Remote-SSH这个插件仅支持VSCode的Insider版本（2019.5.8发布），所以你需要下载VSCode的Insider版本 安装过程很简单，直接下一步直到完成，然后在扩展搜索remote ssh点击安装。 安装完成后侧边栏会出现新的图标。 客户端服务器端SSH配置在本地机器（我这里是自己的windows宿主机），后文称为客户端，安装的vmware虚拟机称为服务器端（Linux）。 1、首先在客户端安装ssh 打开计算机设置页面 选择应用-应用和功能-管理可选功能，安装OpenSSH客户端 在客户端左下角搜索输入cmd，命令行输入ssh-keygen -t rsa，输入你想要放置SSH密钥对的目录，这里一般不更改，一直enter直到结束即可，最后在`c:\\user目录下生成密钥文件id-rsa和id-rsa.pub，第一个是私钥文件，第二个是公钥文件。 2、接下来将客户端的公钥内容添加到服务器端，步骤如下： 首先检测ssh服务是否启动 ： netstat -ntlp | grep ssh 如果ssh服务没有启动 ：/etc/init.d/ssh resart 方法一： 手动创建.ssh文件夹如下所示，我这里已经建好了，只是截图展示一下文件位置，并在.ssh文件夹下创建文件authorized_keys，将客户端公钥复制进去。这里注意文件权限可能需要修改。 1) .ssh目录的权限必须是700 2) .ssh/authorized_keys文件权限必须是600 下图第一列就是文件权限。 修改配置文件：vim /etc/ssh/sshd_config，把PubkeyAuthentication配置为 yes ，允许使用基于密钥认证的方式登录。 方法二： 也可以通过ssh-copy-id的方式，需要在客户端安装bash，cmd无法识别linux命令。可以将公钥复制到远程机器。 1$ ssh-copy-id -i .ssh/id_rsa.pub 用户名@192.168.x.xxx 远程连接如图选择文件目录，这是让你选择你的config文件放在哪里，必须放在客户端密钥文件夹下 配置文件内容很简单，就两行 123$ Host alias $ HostName 1.1.1.1 #服务器的ip，服务器终端输入ifconfig命令查看inet地址 $ User username #远程服务器的用户名，其实就是你的虚拟机终端前面显示的用户名 配置完成，选择在当前窗口开启连接 连接成功，左下角会如下图所示 接下来可以导入服务器端的项目，选择编辑栏File-Open Workspace，成功导入项目 VSCode更新一个功能如果只能针对特定版本可用，那就谈不上任何方便了。因此不到一个月VSCode版本发布了更新，目前的VSCode 1.35支持Remote SSH配置，需要可官网下载下载链接，若已下载老版本，点击菜单栏Help-Check for Updates进行更新，重启即可生效，然后同样的安装Remote - SSH，密钥已经配置好了，只需再选择Config文件，就能够远程连接上服务器，配置完成之后，每次开启服务器之后，在客户端开启VSCode就会自动连接上服务器，很方便。","categories":[{"name":"搭建与配置","slug":"搭建与配置","permalink":"http://malizhen.github.io/categories/搭建与配置/"}],"tags":[{"name":"VSCode","slug":"VSCode","permalink":"http://malizhen.github.io/tags/VSCode/"}],"keywords":[{"name":"搭建与配置","slug":"搭建与配置","permalink":"http://malizhen.github.io/categories/搭建与配置/"}]},{"title":"Base-Delta-Immediate Compression","slug":"Base-Delta-Immediate Compression","date":"2019-06-06T01:56:23.000Z","updated":"2019-06-13T13:50:47.451Z","comments":true,"path":"2019/06/06/Base-Delta-Immediate Compression/","link":"","permalink":"http://malizhen.github.io/2019/06/06/Base-Delta-Immediate Compression/","excerpt":"","text":"Base-Delta-Immediate Compression:Practical Data Compression for On-Chip Caches。原文链接很多基于软件的缓存压缩算法主要有两大缺点：造成很高的硬件复杂度；无法接受的解压延迟。本文提出了一种新的压缩算法Base-Delta-Immediate (B∆I) ，关键思想是：大多数cache line有一个特点，同一cache line中存储的数据差异很小。基于这一观察，cache line的数据可以用一个基值（Base）+ 一组差异值（Delta）来表示，所需存储空间必然会比原始cache line大小小得多。 背景为了缓解CPU和主存之间速度不匹配的问题，在主存与CPU之间插入一级或多级cache。然而cache并不是越大越好，虽然更大的cache通常会带来更少的cache miss，但是这种好处是以更长的访问延迟、更大的cache面积（昂贵）和更大的功耗为代价的。 基于这些限制，为了提高cache的利用率，可能会想到通过数据压缩来减少数据量，然而数据压缩并没有被现代商用微处理器作为一种提高有效缓存容量的方法，为什么？理想的缓存压缩技术应该是快速（压缩/解压延迟低）、简单（硬件复杂度低）、高效（高压缩率）的，而如果在商用微处理器中采用缓存压缩，会面临的最大障碍可能是解压延迟，解压与压缩不同，压缩是在缓存写入时(在提供关键字之后)在后台进行的，而解压缩位于cache hit的关键路径上，在此路径上最小化延迟对于性能非常重要。 因此，快速、简单、高效的缓存压缩方案，不可兼得，怎么办？只能权衡得到最佳方案，要么压缩率低、要么硬件复杂度高、要么解压延迟高，总会有缺陷，方案是否可行就看好处是否大于坏处，为了在降低硬件复杂度和解压缩延迟的同时达到显著的压缩比，本文提出了一种新的缓存压缩技术Base-Delta-Immediate(B∆I)压缩。 BASE + DELTA ENCODING: BASIC IDEA基于两个特点： 数据在内存中分配的规律性（相似的数据值和类型分组在一起）。 缓存/内存数据的动态范围较低（例如，同一cache line的数据差异很小）。 设计了Base+Delta 压缩方案，通过存储一个Base和一组Delta来减少冗余从而提高Cache line的利用率。接下来通过两个直观的例子来更好地理解。 应用程序h264ref的32-byte cache line利用Base+Delta 方案压缩如上图所示，该cache line包含一组（8个）以4字节整数形式存储的窄值。 1窄值是使用大数据类型存储的小值。例如，一个one-byte的值存储为一个four-byte整型数。程序员通常在各种数据结构中以最坏的情况为标准提供数据类型，即使大多数数值可能适合较小的数据类型。 从Figure 3我们看到，cache line通过一个全0的base+一组八个1-byte的差异值即可表示所有存储的数值，只要4+8*1共12 byte就能表示整个cache line，这样消除冗余之后相比原来节省了20 byte的空间。看到这里就很容易联想到一个问题，如果说base的byte数太大，差异值节省出来的空间不够多，那么压缩还不如不压缩对不对？这个问题作者在下文考虑到了，base数目、base字节数、差异值的字节数多少才最合适？选择哪个value做base效果会一样吗？不一样的话那如何确定呢？都是我们需要考虑权衡的点。 由Figure 4，在perlbench应用程序负载上，同样是一个32-byte的cache line，存储的是pointer，可以看到，同一cache line的pointer值依然具有很高的相似度。 注意：虽然这里例子使用的是32-byte的cache line，最后实验评估部分有考虑更常见的64-byte cache line。 Compression Algorithm关于该算法的具体描述，论文里面给出了公式（貌似有误，反了），也很容易理解，就是通过简单的向量减法得到Delta。 1∆i = Vi - B* ，其中V表示原始值的集合，∆表示差异值的集合，B*表示base值，若cache line的大小为C byte，其中每个value的大小为k byte，那么i的取值为1~C/k 这里有两个观察： 若存在任意一个Vi和所选base相似度为0，即Delta(i)的大小等于k，那么该缓存行不能压缩。因为本来引入base就加重了开销，压缩效果不好不如不压缩。 如何确定哪个value被选为base？要么Vi的最小值或最大值，要么中间值，被认为是最佳的。理论上是这样的，实际上的做法呢？ 我们除了确定base，还需要确定k，即每个value的大小，决定了一个cache line能容纳多少个value。 Determining kk在2、4、8之间选择最佳压缩率的k值。选择2、4、8是因为几乎所有由各种编程语言支持的基本数据类型都有这三种大小之一。 Determining B*B*可以依据上述观察2来选取，然而，用这种方式寻找base需要计算原始集合的最大value与最小value，这会大大增加硬件的逻辑复杂度，并且会明显增加压缩延迟。所以为了简单起见，选择第一个value作为base即可，并且实验表明，压缩率相比选择理论最优base降低仅仅0.4%，很微不足道了，并且还不会增加硬件复杂度以及压缩延迟。 Decompression Algorithm通过B*和∆的值能够计算得到V，实现解压： 1Vi = ∆i + B* 因此，cache line中的值可以使用SIMD-style的向量加法器并行计算得到。即使用一组简单的加法器，可以在执行整数向量加法所需的时间内解压缩整个cache line。 B∆I COMPRESSION前一部分介绍了Base + Delta，以此为基础怎样能够更完善我们的压缩算法呢？ 因为尽管B+∆被证明适用于大多数的应用程序，但是不可能所有的cache line都能用这种形式来表示，有一些基准测试压缩率就不见得好，比如mcf。这是因为有些应用程序在同一cache line中间可能混合有不同类型的数据，比如指针和1-byte的整数。这种情况下，很显然，如果我们选取多个base，一种类型一个base的话是不是压缩效果会好很多呢？ 如Figure 5所示，我们发现对于在同一cache line可能存储着不同类型的数据的应用程序，多个base压缩效果会更好，但是这会造成更大的base存储开销，所以，存在一个tradeoff，因为显然不是多个base一定会更好，那么选取多少个base才是最优的呢？ 光说都是没有依据的，通过实验来说话，作者设计了一个实验，评估了选择不同数量base(使用贪婪算法依次选择次优base)的有效压缩比，Figure 6展示了实验结果。 结果表明，就有效压缩比而言，经验上最优的base个数是2，虽然少数benchmark在1或3个base上也有最优，最后的结论还是B+∆在两个base的情况下，性能明显优于B+∆在base为1时(压缩比平均为1.51:1.40)，说明值得考虑实现。结果还表明有两个以上的base并不会为这些工作负载提供额外的压缩比改进，因为存储更多的base的开销要高于压缩更多cache line的好处。 注意：Figure 6中我们发现有0个base，这很必要，因为如果不考虑0个base，对于比如说最简单的全0数据，如果使用简单的压缩去冗余，不需要base，直接压缩到1byte，而base越多，显然，压缩率越低，并且增大存储开销。 那么，如何高效地找到两个base？不增加硬件的复杂度，或者说如何以最小的硬件复杂度寻找两个base来获得最大的压缩好处？下一节介绍 B∆I: Refining B+∆ with Two Bases and Minimal Complexity我们发现，第二个base直接设置为0能够和任意选取任何一个vaule作为第二个base一样，为什么会这样？因为大多数情况下，是动态范围较小的宽值（比如指针）与窄值（比如小整数）混合，那么第一个base可以使用base+delta编码压缩动态范围较低的宽值，而第二个0 base则可以有效地压缩窄值。基于这一观察，我们额外增加一个隐式（implicit）的0 base来改进B+∆，称为Base-Delta-Immediate或B∆I压缩。 那么两个base的B+∆好还是B∆I好呢？又存在tradeoff。显然，B∆I有一个base是隐式的0，存储开销更小，这意味着对于用这两种技术都可压缩的cache line，B∆I的平均压缩率可能更高。有两个base的B+∆需要更多的存储空间来存储第二个base，但是可以压缩更多的cache line，因为base可以是任何value，从中选择最佳。到底哪个好呢？可能取决于cache line的模式，甲之砒霜，乙之蜜糖。关键时刻依然还是得实验来说话 Figure 7表明，虽然有个别负载B+∆的表现比B∆I好，但是总体来说还是B∆I的压缩比（1.53）高于B+∆（1.51），虽然不是高太多，但是考虑到B+∆有两个base，那就有比B∆I更复杂的硬件机制，所以认为缓存压缩设计还是应该基于B∆I的思想。 DesignCompress在具体的设计中，所有的可能压缩大小是静态已知的，如Table 2。如果cache line有多个压缩选项可用(例如，8-byte base 1-byte ∆或者Zeros压缩)，则Compression Selection 选择压缩cache line大小最小的一个（即选择压缩率最高的）。基于Table 2选择合适的压缩大小，Figure 8中所有压缩单元可并发执行。 Figure 9展示了32-byte的cache line在8-byte-base 1-byte-∆时压缩单元的情况，每个V通过减法器进行运算之后，判断是否每个V的运算结果∆前七位均为0或者1，如果是的话，cache line能够以该种模式（8-byte-base 1-byte-∆）存储，否则，说明至少有一个∆不能用1-byte表示，那么不压缩该cache line。 Decompress解压的硬件设计很简单，如上文描述一样，就是一个减法器。如下图所示 关于实现的更多细节，以及实验部分，如果感兴趣的话可以阅读原文，本文的分析重在了解基本思想。","categories":[{"name":"论文阅读记录","slug":"论文阅读记录","permalink":"http://malizhen.github.io/categories/论文阅读记录/"}],"tags":[{"name":"compression algorithm","slug":"compression-algorithm","permalink":"http://malizhen.github.io/tags/compression-algorithm/"}],"keywords":[{"name":"论文阅读记录","slug":"论文阅读记录","permalink":"http://malizhen.github.io/categories/论文阅读记录/"}]},{"title":"重庆四人游","slug":"Chongqing","date":"2019-06-06T01:44:35.540Z","updated":"2019-06-10T13:22:21.820Z","comments":true,"path":"2019/06/06/Chongqing/","link":"","permalink":"http://malizhen.github.io/2019/06/06/Chongqing/","excerpt":"","text":"2018年5月1日的前一天，我的小Z突然问我想不想五一去重庆，距离我俩上次旅行已经过去快三年，贫穷的大学时期，只是在2015年八月底去了一趟凤凰，好在自从小Z毕业工作以来，似乎异地恋也不再受限于没钱见面，哈哈哈，虽然自从我读研以来科研才是他的情敌。于是有了这次说走就走的旅行。 前期准备出行方式的选择我们总共四个人，小姜和他女朋友都在湖南，小Z也是，我在武汉，所以最后我们决定长沙会合，然后坐飞机去重庆。买的五一当晚11点长沙到重庆的特价机票，票价不贵，500元左右，不同买票软件不一样，我发现的最实惠的是智行，比携程飞猪等少大概80。这里真的要吐槽一下西部航空，返程买的奥凯航空，对比起来简直一个天上一个地下，西部航空没有免费行李托运额度，奥凯航空有，而且有充饥曲奇饼和水，hhh，曲奇饼超好吃，可惜产地俄罗斯，淘宝没找到有卖的。 还有，第一次坐飞机我发现自己不仅晕车居然还晕机，所以晕车的小伙伴坐飞机的话一定记得吃药。话说不管哪个航空公司空姐都人美心善，因为晕机不舒服，下飞机的时候满脸不开心，得到了空乘小姐姐的大大的笑容问候。 关于住宿全程不到两个小时，所以看来比起火车虽然贵点，但是性价比真是不知道高多少。5月1日抵达重庆的时候已经是次日凌晨，所以当晚的住宿定在江北国际机场附近，首选有接机服务的酒店，1日晚的酒店很一般，而且由于五一价钱还不便宜，接近三百，就不说店名了。因为商圈附近住宿都很贵，两个男孩子不想住民宿，最后2日晚选择住宿在南坪，南坪轻轨站附近的金凯斯精品酒店，接近三百一晚，酒店有些陈旧，但是房间面积很大，虽然这并没什么用，卫生间很小，期间马桶还坏了，不过胜在位置很好，从机场坐轻轨到南坪，轻轨站一出来就能看到这家酒店。五一这个价钱只能说无功无过吧。 之后的两个晚上住在我们东道主煦煦家哈哈哈，这就有了接下来几天连续爆肝用生命没日没夜地浪的契机hhhh。 咳咳咳正文来了去重庆之前做的攻略，在有了李导（煦煦）加持之后都是浮云了，吃了超级正宗的重庆火锅，啊哈好像叫大队长火锅，晚上在路边摊吃的烧烤，虽然菜都从牵牵上弄下来变成了大锅菜的样子，卖相不太好，但是味道真的很棒。 去了各大网红景点，包括洪崖洞、解放碑、磁器口还有南山一棵树风景区。一个一个说吧，洪崖洞解放碑在一起，就晚上去夜景真的很棒，虽然洪崖洞不知道在地下多少层，当时人山人海，没有电梯，排队进入口，然后一层一层的楼梯走到腿快废了。 解放碑就是那种来了就必去拍张照的地方，hhh，我当时竟然有一种武汉大学校门口的错觉，永远好多人对着那个国立武汉大学咔擦咔擦。 磁器口吧，有点不是很推荐，在一个在武汉待了五年的人看来，它就是另一个户部巷，一条小吃街也卖一些小玩意，东西很难吃而且很贵，不过有个酒庄老板超好，免费尝了好多酒，要不是坐飞机不能带，当时超想买一小罐女儿红。以上地方总结起来就是五一真的超级多人，多到无法想象的那种，寸步难行。 4号晚去的南山一棵树，因为假期最后一天，人不多，打车过去的，晚上俯瞰重庆夜景很美，基本照片都在这拍的hhh，原本计划去川美涂鸦一条街拍照的，最后时间不够了。 5号租车去了奥陶纪，我们总共五个人，租车比跟团划算而且更方便，这里还是很推荐的，感觉像张家界和大型欢乐谷的结合体，有玻璃桥有很多高空项目，室内冰雪世界很美，虽然这个地方被抖音带火的，这两年才出名，还是去得很值。 最后记了一堆流水账，最后想要矫情一下，旅途中的情侣难免会有些小矛盾，不过和小Z在一起的六年以来，很感谢他每次包容我的小性子，有时候觉得，遇到一个三观相合而且三观超正的小奶狗，只想每天多爱对方一点点，也许这就是那啥操蛋的异地恋维持的新鲜感吧，hhhh！","categories":[{"name":"随笔","slug":"随笔","permalink":"http://malizhen.github.io/categories/随笔/"}],"tags":[{"name":"旅游","slug":"旅游","permalink":"http://malizhen.github.io/tags/旅游/"}],"keywords":[{"name":"随笔","slug":"随笔","permalink":"http://malizhen.github.io/categories/随笔/"}]}]}