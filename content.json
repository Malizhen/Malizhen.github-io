{"meta":{"title":"乌龙波霸七分甜","subtitle":"每一个不曾起舞的日子，都是对生命的辜负","description":null,"author":"malizhen","url":"http://malizhen.github.io"},"pages":[{"title":"about","date":"2019-06-10T07:49:26.000Z","updated":"2019-06-10T08:18:05.956Z","comments":true,"path":"about/index.html","permalink":"http://malizhen.github.io/about/index.html","excerpt":"","text":""},{"title":"tags","date":"2019-06-06T02:48:25.000Z","updated":"2019-06-06T02:49:08.153Z","comments":true,"path":"tags/index.html","permalink":"http://malizhen.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Github/码云的ssh免密连接","slug":"Github-码云的ssh免密连接","date":"2019-09-18T07:13:55.000Z","updated":"2019-09-18T08:06:45.843Z","comments":true,"path":"2019/09/18/Github-码云的ssh免密连接/","link":"","permalink":"http://malizhen.github.io/2019/09/18/Github-码云的ssh免密连接/","excerpt":"","text":"我的虚拟机上面有两个.ssh文件夹，第一个在/home/malizhen/.ssh目录，用于本机和虚拟机之间的通信，在VSCode中实现本地主机远程登录虚拟机，见搭建与配置下的【VSCode:Remote-SSH配置】博文记录。为方便后期管理，将gem5/nvmain项目部署到码云上，而git项目也基于ssh的原理，就有了我的第二个ssh在/root/.ssh目录，也就是很多博客中说的~/.ssh目录。 进入当前用户的家目录。 1$ cd ~ 查看当前目录下是否有.ssh文件，若有则删除。 1$ rm -rf .ssh 运行命令生成.ssh密钥目录，地址为你的github或码云的邮箱地址。 1$ ssh-keygen -t rsa -C \"123456@qq.com\" 上一步一路enter直到最后即可，中间记得确认一下密钥文件存放目录是否是你想要的。接下来cd .ssh进入目录查看公钥文件的内容。 1$ cat id_rsa.pub 复制公钥文件内容，登录码云，点击头像下设置-SSH公钥-添加公钥，标题随意，将公钥文件内容粘贴进去。 至此测试一下git服务器是否可达。 1$ ssh -T git@gitee.com 提示以下内容不用管，输入yes即可，这样操作之后会在.ssh目录下生成known_hosts文件，作用不详。 123The authenticity of host 'gitee.com (120.55.226.24)' can't be established.ECDSA key fingerprint is SHA256:FQGC9Kn/eye1W8icdBgrQp+KkGYoFgbVr17bmjey0Wc.Are you sure you want to continue connecting (yes/no)? 接下来可以回到想要存放git项目的文件夹下，最好新建一个空文件夹，在该文件夹路径下，将远程git项目pull下来，一定要复制项目的ssh地址而不是https。 1234567$ git init$ git remote add origin git@gitee.com:Malizhen/gem5.git$ git remote -v$ git pull origin master$ git add -A$ git commit -m \"备注信息提交\"$ git push origin master 整个过程中不需要输入密码说明配置成功。","categories":[{"name":"搭建与配置","slug":"搭建与配置","permalink":"http://malizhen.github.io/categories/搭建与配置/"}],"tags":[{"name":"github","slug":"github","permalink":"http://malizhen.github.io/tags/github/"}],"keywords":[{"name":"搭建与配置","slug":"搭建与配置","permalink":"http://malizhen.github.io/categories/搭建与配置/"}]},{"title":"FlipNWrite源码解析与修改","slug":"FlipNWrite源码解析与修改","date":"2019-07-25T12:48:22.000Z","updated":"2019-07-29T12:55:40.540Z","comments":true,"path":"2019/07/25/FlipNWrite源码解析与修改/","link":"","permalink":"http://malizhen.github.io/2019/07/25/FlipNWrite源码解析与修改/","excerpt":"","text":"在阅读nvmain源码的过程中，发现nvmain里面自带有FlipNWrite的实现方法，只是默认的编码方式并不是FlipNWrite而是default。这是我试着自己修改nvmain代码的第一步，在config配置文件中设置编码方式，这样有一个好处，不用去修改源码，不需要重新编译，方式为根据config文件语法直接设置：DataEncoder FlipNWrite。运行测试命令： 1./build/ARM/gem5.opt configs/example/se.py -c tests/test-progs/hello/bin/arm/linux/hello --cpu-type=detailed --caches --l2cache --mem-type=NVMainMemory --nvmain-config=./nvmain/Config/PCM_ISSCC_2012_4GB.config 不出所料，测试结果中多了三行输出，但是似乎是错误的，全为0？怎么可能。 什么原因导致的呢？ 因为执行的se测试，负载为hello程序，根本没有写操作，从输出结果中也可以看出： 写次数为0，那位翻转次数当然也是0咯。那怎么办呢？ （1）改写负载程序。 不使用自带的hello二进制程序负载进行测试，修改测试负载为有写操作的数组赋值操作，在/home/malizhen/Workspace文件夹下编写自己的hello.c如下： 12345678910111213141516#include&lt;stdio.h&gt;int main()&#123; int i=0; int j=0; long count=0; long temp[4096][8]; for(i=0;i&lt;4096;i++) &#123; for(j=0;j&lt;8;j++) &#123; temp[i][j]=count++; &#125; &#125;&#125; 在当前目录执行静态编译 1gcc -o hello hello.c -static 生成hello*二进制文件，然后用该文件作为负载测试文件，不出意外会有写操作了。在这里要注意，二进制负载文件不使用自带的（自带的helloc二进制文件都在使用的对应架构的文件夹目录下）而是使用自己编译生成的（可以在任意目录下），这时只能在X86架构下进行测试，发现ALPHA和ARM架构下都会出错（如果将自己编译生成的二进制文件放进ALPHA和ARM架构文件夹目录下，应该也不会出错吧），这是因为电脑是X86，如果想在别的架构下运行任意二进制程序必须配置交叉编译环境。 1./build/X86/gem5.opt configs/example/se.py -c ../../Workspace/hello --cpu-type=detailed --caches --l2cache --mem-type=NVMainMemory --nvmain-config=./nvmain/Config/PCM_ISSCC_2012_4GB.config 不幸的是，测试输出结果中写次数仍然为0，这就有点奇怪了。为什么呢？ （2）想过增加指令条数，但是增加至超级大了也不管用。 1./build/X86/gem5.opt configs/example/se.py -c ../../Workspace/hello --cpu-type=detailed --caches --l2cache 64 --mem-type=NVMainMemory --nvmain-config=./nvmain/Config/PCM_ISSCC_2012_4GB.config -I 10000000 （3）查看cache大小发现为64 B，太大了，设置更小的cache大小之后就搞定了，为啥呢？ 1./build/X86/gem5.opt configs/example/se.py --cpu-clock=3GHz -n 4 -c ../../Workspace/hello --cpu-type=detailed --caches --l1d_size=32kB --l1d_assoc=8 --l1i_size=32kB --l1i_assoc=8 --l2cache --l2_size=256kB --l2_assoc=8 --l3cache --l3_size=4MB --l3_assoc=16 --mem-type=NVMainMemory --nvmain-config=./nvmain/Config/PCM_ISSCC_2012_4GB.config 当时排查问题的时候，想要在函数里面直接cout，输出一些函数的中间值，进行查看分析。但是一旦修改了代码，就得重新编译，再进行测试，从测试的命令行输出结果能够查看中间值，这种方法因为要反复编译，不建议。那有没有更好更简洁的方式呢？可以参考网页gem5 Debug官方文档使用gdb进行调试。 另外可以在gem5/m5out/stats.txt文件中查看更加详细的输出结果，比如命令行窗口结果中的： 12i0.defaultMemory.totalReadRequests 4659i0.defaultMemory.totalWriteRequests 224 对应stats.txt文件中的: 源码解析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250#include \"DataEncoders/FlipNWrite/FlipNWrite.h\"#include &lt;iostream&gt;using namespace NVM;FlipNWrite::FlipNWrite( )&#123; flippedAddresses.clear( ); std::cout&lt;&lt;\"hahhahhahhaha\"&lt;&lt;std::endl; /* Clear statistics */ bitsFlipped = 0; bitCompareSwapWrites = 0;&#125;FlipNWrite::~FlipNWrite( )&#123; /* * Nothing to do here. We do not own the *config pointer, so * don't delete that. */&#125;void FlipNWrite::SetConfig( Config *config, bool /*createChildren*/ )&#123; Params *params = new Params( ); params-&gt;SetParams( config ); SetParams( params );//可以设置flipNWrite的粒度，论文中默认设置的就是一个word为32bit /* Cache granularity size. */ fpSize = config-&gt;GetValue( \"FlipNWriteGranularity\" ); /* Some default size if the parameter is not specified */ if( fpSize == -1 ) fpSize = 32; &#125;void FlipNWrite::RegisterStats( )&#123; AddStat(bitsFlipped); AddStat(bitCompareSwapWrites); AddUnitStat(flipNWriteReduction, \"%\");&#125;void FlipNWrite::InvertData( NVMDataBlock&amp; data, uint64_t startBit, uint64_t endBit )&#123; uint64_t wordSize; int startByte, endByte; //wordSize以Byte为单位，表示一次burst的数据量 wordSize = p-&gt;BusWidth; wordSize *= p-&gt;tBURST * p-&gt;RATE; wordSize /= 8;//除法int型为向下取整，去掉小数部分，startBit最小可以是0 startByte = (int)(startBit / 8); endByte = (int)((endBit - 1) / 8); for( int i = startByte; i &lt;= endByte; i++ ) &#123; uint8_t originalByte = data.GetByte( i ); uint8_t shiftByte = originalByte; uint8_t newByte = 0; for( int j = 0; j &lt; 8; j++ ) &#123; uint64_t currentBit = i * 8 + j; if( currentBit &lt; startBit || currentBit &gt;= endBit ) &#123; shiftByte = static_cast&lt;uint8_t&gt;(shiftByte &gt;&gt; 1); continue; &#125;//如果shiftByte为全0，newByte变为全1 if( !(shiftByte &amp; 0x1) ) &#123; newByte = static_cast&lt;uint8_t&gt;(newByte | (1 &lt;&lt; (7-j))); &#125; shiftByte = static_cast&lt;uint8_t&gt;(shiftByte &gt;&gt; 1); &#125; data.SetByte( i, newByte ); &#125;&#125;ncycle_t FlipNWrite::Read( NVMainRequest* /*request*/ )&#123; ncycle_t rv = 0; // TODO: Add some energy here return rv;&#125;ncycle_t FlipNWrite::Write( NVMainRequest *request ) &#123; NVMDataBlock&amp; newData = request-&gt;data; NVMDataBlock&amp; oldData = request-&gt;oldData; NVMAddress address = request-&gt;address; /* * The default life map is an stl map&lt; uint64_t, uint64_t &gt;. * You may map row and col to this map_key however you want. * It is up to you to ensure there are no collisions here. */ uint64_t row; uint64_t col; ncycle_t rv = 0; request-&gt;address.GetTranslatedAddress( &amp;row, &amp;col, NULL, NULL, NULL, NULL ); /* * If using the default life map, we can call the DecrementLife * function which will check if the map_key already exists. If so, * the life value is decremented (write count incremented). Otherwise * the map_key is inserted with a write count of 1. */ uint64_t rowSize; uint64_t wordSize; uint64_t currentBit; uint64_t flipPartitions; uint64_t rowPartitions; int *modifyCount; wordSize = p-&gt;BusWidth; wordSize *= p-&gt;tBURST * p-&gt;RATE; wordSize /= 8; rowSize = p-&gt;COLS * wordSize; rowPartitions = ( rowSize * 8 ) / fpSize; //flipPartitions即为可以分为多少个fpSize大小的word flipPartitions = ( wordSize * 8 ) / fpSize; //每个word设置一个modifyCount来记录该word的修改位数 modifyCount = new int[ flipPartitions ]; /* * Count the number of bits that are modified. If it is more than half, then we will invert the data then write. */ for( uint64_t i = 0; i &lt; flipPartitions; i++ ) modifyCount[i] = 0; currentBit = 0; /* Get what is currently in the memory (i.e., if it was previously flipped, get the flipped data. */ for( uint64_t i = 0; i &lt; flipPartitions; i++ ) &#123; uint64_t curAddr = row * rowPartitions + col * flipPartitions + i; if( flippedAddresses.count( curAddr ) ) &#123; InvertData( oldData, i*fpSize, (i+1)*fpSize ); &#125; &#125; /* Check each byte to see if it was modified */ for( uint64_t i = 0; i &lt; wordSize; ++i ) &#123; /* * If no bytes have changed we can just continue. Yes, I know this will check the byte 8 times, but i'd rather not change the iter. */ uint8_t oldByte, newByte; oldByte = oldData.GetByte( i ); newByte = newData.GetByte( i ); if( oldByte == newByte ) &#123; currentBit += 8; continue; &#125; /* * If the bytes are different, then at least one bit has changed. check each bit individually. */ for( int j = 0; j &lt; 8; j++ ) &#123; uint8_t oldBit, newBit; oldBit = ( oldByte &gt;&gt; j ) &amp; 0x1; newBit = ( newByte &gt;&gt; j ) &amp; 0x1; if( oldBit != newBit ) &#123; modifyCount[(int)(currentBit/fpSize)]++; &#125; currentBit++; &#125; &#125; /* * Flip any partitions as needed and mark them as inverted or not. */ for( uint64_t i = 0; i &lt; flipPartitions; i++ ) &#123; bitCompareSwapWrites += modifyCount[i]; uint64_t curAddr = row * rowPartitions + col * flipPartitions + i; /* Invert if more than half of the bits are modified. */ if( modifyCount[i] &gt; (fpSize / 2) ) &#123; InvertData( newData, i*fpSize, (i+1)*fpSize ); bitsFlipped += (fpSize - modifyCount[i]); /* * Mark this address as flipped. If the data was already inverted, it * should remain as inverted for the new data. */ if( !flippedAddresses.count( curAddr ) ) &#123; flippedAddresses.insert( curAddr ); &#125; &#125; else &#123; /* * This data is not inverted and should not be marked as such. */ if( flippedAddresses.count( curAddr ) ) &#123; flippedAddresses.erase( curAddr ); &#125; bitsFlipped += modifyCount[i]; &#125; &#125; delete modifyCount; return rv;&#125;void FlipNWrite::CalculateStats( )&#123; if( bitCompareSwapWrites != 0 ) flipNWriteReduction = (((double)bitsFlipped / (double)bitCompareSwapWrites)*100.0); else flipNWriteReduction = 100.0;&#125;","categories":[{"name":"源码分析","slug":"源码分析","permalink":"http://malizhen.github.io/categories/源码分析/"}],"tags":[{"name":"nvmain","slug":"nvmain","permalink":"http://malizhen.github.io/tags/nvmain/"}],"keywords":[{"name":"源码分析","slug":"源码分析","permalink":"http://malizhen.github.io/categories/源码分析/"}]},{"title":"PCM_ISSCC_2012_4GB配置文件参数解析","slug":"PCM-ISSCC-2012-4GB配置文件参数解析","date":"2019-07-23T10:50:55.000Z","updated":"2019-07-24T08:53:56.446Z","comments":true,"path":"2019/07/23/PCM-ISSCC-2012-4GB配置文件参数解析/","link":"","permalink":"http://malizhen.github.io/2019/07/23/PCM-ISSCC-2012-4GB配置文件参数解析/","excerpt":"","text":"本文的参考内容来自于MEMORY SYSTEMS Cache，DRAM，Disk这本书，作者为BRUCE JACOB，SPENCER W.NG，DAVID T.WANG。(链接) 首先了解几个概念，北桥称为系统总线，是内存传输的主要信道，因此速度比较快；南桥称为IO总线，主要联系硬盘、USB、网卡等设备。北桥支持的频率称为前端总线速度（每秒传输次数），而每次传送的bit数则是总线宽度，我们熟悉的总线带宽（总线速度x总线宽度）即为每秒可传送的最大数据量。 tBURST 4：数据burst的时间为4个周期 RATE 2：数据传输速率，每个周期两次传输 BusWidth 64：每次传输bit数，总线宽度(以bit为单位) 1234wordSize = p-&gt;BusWidth; wordSize *= p-&gt;tBURST * p-&gt;RATE;wordSize /= 8;/* wordSize以Byte为单位，表示每次burst传输的数据量 */ 使用数据burst来提高数据吞吐量，burst长度=tBURST*RATE=8。 tRCD 48: Row to Column command Delay. The time interval between row access and data ready at sense amplifiers. 在进行数据的读写前，Controller 需要先发送 Row Active Command，Row Active Command 通过地址总线指明需要打开DRAM Memory SubArray 中某一个 Bank 的某一个 Row。DRAM在接收到该Row Active Command 后，会打开指定 Row 的 Wordline，将其存储的数据从 DRAM cell 阵列移动到 Sense Amplifier（感知放大器）中，这一时间定义为 tRCD（RCD for Row Address to Column Address Delay）。之后，整行激活的数据被保存在Sense Amplifier中，随后的列读或列写命令可以通过数据总线在Sense Amplifier和内存控制器之间移动数据。如图一所示。 图一 Row access command and timing. tRAS 0: Row Access Strobe. The time interval between row access command and data restoration in a DRAM array. A DRAM bank cannot be precharged until at least tRAS time after the previous bank activation. 从Row Active Command的assertion开始的tRCD时间之后，数据在Sense Amplifier上可用，但尚未完全restored到DRAM cell。DRAM 从接收到 Row Active Command 到完成 Row restore 操作所需要的时间定义为 tRAS（the Row Access Strobe latency）。从Row Active Command的assertion开始的tRAS时间之后，假设感知放大器已完成对DRAM阵列的数据restore，然后可以对Sense Amplifier进行precharge，以便对DRAM阵列中同一bank的不同行进行访问。如图一所示。 tCAS 1: Column Access Strobe latency. The time interval between column access command and the start of data return by the DRAM device(s). Also known as tCL. Controller 在发送 Row Active Command后的tRCD时间之后，bank处于激活状态，Sense Amplifier中有完整的page内容，接着发送Column Read Commond进行数据读取。Column Read Command 通过数据总线指明需要读取的 Column 的起始地址。与列读取命令相关的三个基本计时参数是:tCAS、tCCD和tBURST。DRAM设备在发出列读取命令后将请求的数据放到数据总线上所需的时间，定义为tCAS（CAS for Column Address Strobe），也称为tCL。如图二所示。 图二 Column-read command and timing. tBURST 4: Data burst duration. The time period that data burst occupies on the data bus. Typically 4 or 8 beats of data. In DDR SDRAM, 4 beats of data occupy 2 full clock cycles. tCAS时间之后，紧接着就是数据burst阶段，数据从预取缓冲区逐个发往IO总线，经过四个时钟周期发送完毕。这一时间定义为tBURST，表示数据burst周期。对同一bank的后续读取必须至少间隔tBURST，因为至少需要tBURST才能将预取缓冲区中的burst数据传输到IO总线。 tCCD 2: 一般为2或4，不超过tBURST。是列操作之间的最小时间间隔。Column-to-Column Delay. The minimum column command timing, determined by internal burst (prefetch) length. Multiple internal bursts are used to form longer burst for column reads. tCCD is 2 beats (1 cycle) for DDR SDRAM, and 4 beats (2 cycles) for DDR2 SDRAM. 现代DRAM设备在短时间内连续不断地传输数据。如图二，DRAM设备在内部以两个短的burst时间段移动数据，而在一个较长、连续的burst时间段将数据放在数据总线上。DRAM设备的内部burst长度在图二中标记为tCCD，单个列读取命令在数据总线上的数据burst持续时间标记为tBURST。定时参数tCCD表示最小burst持续时间的timing，或最小column-to-column命令timing。最小burst时间由DRAM设备的预取长度决定。例如，DDR SDRAM设备的预取长度为2 beats数据，因此tCCD在DDR SDRAM设备中是一个完整的时钟周期;DDR2 SDRAM设备的预取长度为4 beats数据，因此tCCD是DDR2 SDRAM设备的两个完整时钟周期。 tCWD 4: Column Write Delay. The time interval between issuance of the column-write command and placement of data on the data bus by the DRAM controller. Controller 在发送 Row Active Command后的tRCD时间之后，接着发送Write Commond进行数据写入。Column Write Command 通过地址总线指明需要写入数据的 Column 的起始地址。Controller 在发送完 Write Command 后，需要等待 tCWD （CWD for Column Write Delay） 时间后，才可以发送待写入的数据。所以从发送完Write Commond到发送待写入数据这段时间定义为tCWD， 在一些描述中也称为 tCWL（CWL for Column Write Latency）。 tWR 0: Write Recovery time. The minimum time interval between the end of a write data burst and the start of a precharge command. Allows sense amplifiers to restore data to cells. DRAM接收完数据后，需要一定的时间将数据写入到 DRAM Cells 中，这个时间定义为 tWR（WR for Write Recovery）。也称为write-to-precharge, PCM中不需要？ tRP 1: Row Precharge. The time interval that it takes for a DRAM array to be precharged for another row access. 在DRAM中，Refresh命令之前，每个bank必须要先Precharged，然后处于idle状态，从发出Precharge命令到激活同一bank中不同行之间所需的最小时钟周期数，称为一个tRP时延。 tRFC 100: Refresh Cycle time. The time interval between Refresh and Activation commands. Refresh时间，不在PCM中使用，但同样在配置文件中为其分配有效的数字。在一个Refresh命令完成后，所有的bank处于precharge (idle)状态，在Refresh命令和下一个activate命令(ACT)之间cycles数目必须大于等于tRFC(the Row Refresh Cycle Time )。 CLK 400: CPU运行频率为400MHz，那么周期为1/400 us=2.5ns。 tCWD 4: 10ns。Column Write Delay. The time interval between issuance of the column-write command and placement of data on the data bus by the DRAM controller. 不同的内存访问协议对tCWD有不同的设置。如图三所示，在SDRAM设备中，写数据与column-write命令同时放在数据总线上，tCWD为零。在DDR SDRAM设备中，tCWD被指定为内存系统中的一个时钟周期。在DDR2 SDRAM内存访问协议中，tCWD指定为比tCAS小一个周期，而在DDR3 SDRAM内存访问协议中，tCWD具有5到8个周期之间的可编程性。 图三 Column-write command and timing for DDR SDRAM and DDR2 SDRAM devices.","categories":[{"name":"源码分析","slug":"源码分析","permalink":"http://malizhen.github.io/categories/源码分析/"}],"tags":[{"name":"nvmain","slug":"nvmain","permalink":"http://malizhen.github.io/tags/nvmain/"}],"keywords":[{"name":"源码分析","slug":"源码分析","permalink":"http://malizhen.github.io/categories/源码分析/"}]},{"title":"BDI源码分析","slug":"BDI源码分析","date":"2019-07-23T03:45:42.000Z","updated":"2019-07-23T06:38:26.298Z","comments":true,"path":"2019/07/23/BDI源码分析/","link":"","permalink":"http://malizhen.github.io/2019/07/23/BDI源码分析/","excerpt":"","text":"之前博客有记录BDI压缩算法以及FPC压缩算法的论文阅读记录，在github上面找到了对应的源码来源，基于对这两种压缩算法的理论理解，详细分析算法源码。 BDICompress12345678910111213141516171819202122232425262728293031323334//x最高位若为0，右移63位后的t为全0，x与t异或仍未x，减t也仍为x//x最高位若为1，右移63位后的t为全1，x与t异或结果为x取反，然后（x取反-t）=-（t-x取反）=-x//最高位为符号扩展位，负数绝对值等于它的相反数，正数绝对值等于本身//long long为8个字节，64位static unsigned long long my_llabs ( long long x )&#123; unsigned long long t = x &gt;&gt; 63; return (x ^ t) - t;&#125;//int为4个字节，32位，绝对值算法同上static unsigned my_abs ( int x )&#123; unsigned t = x &gt;&gt; 31; return (x ^ t) - t;&#125;long long unsigned * convertBuffer2Array (char * buffer, unsigned size, unsigned step)&#123;//size为缓冲区大小，除以step为values的大小，一个values包含step个buffer long long unsigned * values = (long long unsigned *) VG_(malloc)(\"cg.compress.ci.1\", sizeof(long long unsigned) * size/step); unsigned int i,j; for (i = 0; i &lt; size / step; i++) &#123; values[i] = 0; // Initialize all elements to zero. &#125;//values[0]=(buffre[0]&lt;&lt;0)+(buffre[1]&lt;&lt;8)+(buffre[2]&lt;&lt;16)+(buffre[3]&lt;&lt;24)//values[1]=(buffre[4]&lt;&lt;0)+(buffre[5]&lt;&lt;8)+(buffre[6]&lt;&lt;16)+(buffre[7]&lt;&lt;24) for (i = 0; i &lt; size; i += step )&#123; for (j = 0; j &lt; step; j++)&#123; values[i / step] += (long long unsigned)((unsigned char)buffer[i + j]) &lt;&lt; (8*j); &#125; &#125; return values;&#125;","categories":[{"name":"源码分析","slug":"源码分析","permalink":"http://malizhen.github.io/categories/源码分析/"}],"tags":[{"name":"compression","slug":"compression","permalink":"http://malizhen.github.io/tags/compression/"}],"keywords":[{"name":"源码分析","slug":"源码分析","permalink":"http://malizhen.github.io/categories/源码分析/"}]},{"title":"FPC源码分析","slug":"FPC源码分析","date":"2019-07-23T01:19:07.000Z","updated":"2019-07-23T06:37:31.864Z","comments":true,"path":"2019/07/23/FPC源码分析/","link":"","permalink":"http://malizhen.github.io/2019/07/23/FPC源码分析/","excerpt":"","text":"之前博客有记录BDI压缩算法以及FPC压缩算法的论文阅读记录，在github上面找到了对应的源码来源，基于对这两种压缩算法的理论理解，详细分析算法源码。 FPCCompress123456789101112131415161718192021222324252627282930313233//x最高位若为0，右移63位后的t为全0，x与t异或仍未x，减t也仍为x//x最高位若为1，右移63位后的t为全1，x与t异或结果为x取反，然后（x取反-t）=-（t-x取反）=-x//最高位为符号扩展位，负数绝对值等于它的相反数，正数绝对值等于本身//long long为8个字节，64位static unsigned long long my_llabs ( long long x )&#123; unsigned long long t = x &gt;&gt; 63; return (x ^ t) - t;&#125;//int为4个字节，32位，绝对值算法同上static unsigned my_abs ( int x )&#123; unsigned t = x &gt;&gt; 31; return (x ^ t) - t;&#125;long long unsigned * convertBuffer2Array (char * buffer, unsigned size, unsigned step)&#123;//size为缓冲区大小，除以step为values的大小，一个values包含step个buffer long long unsigned * values = (long long unsigned *) VG_(malloc)(\"cg.compress.ci.1\", sizeof(long long unsigned) * size/step); unsigned int i,j; for (i = 0; i &lt; size / step; i++) &#123; values[i] = 0; // Initialize all elements to zero. &#125;//values[0]=(buffre[0]&lt;&lt;0)+(buffre[1]&lt;&lt;8)+(buffre[2]&lt;&lt;16)+(buffre[3]&lt;&lt;24)//values[1]=(buffre[4]&lt;&lt;0)+(buffre[5]&lt;&lt;8)+(buffre[6]&lt;&lt;16)+(buffre[7]&lt;&lt;24) for (i = 0; i &lt; size; i += step )&#123; for (j = 0; j &lt; step; j++)&#123; values[i / step] += (long long unsigned)((unsigned char)buffer[i + j]) &lt;&lt; (8*j); &#125; &#125; return values;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051unsigned FPCCompress(char * buffer, unsigned size )&#123; long long unsigned * values = convertBuffer2Array(buffer, size*4, 4); unsigned compressable = 0; unsigned int i; for (i = 0; i &lt; size; i++) &#123; // 000 if(values[i] == 0)&#123; compressable += 1;//SIM_printf(\"000\\n \"); continue; &#125; // 001 010 if(my_abs((int)(values[i])) &lt;= 0xFF)&#123; compressable += 1;//SIM_printf(\"001\\n \"); continue; &#125; // 011 if(my_abs((int)(values[i])) &lt;= 0xFFFF)&#123; compressable += 2;//SIM_printf(\"011\\n \"); continue; &#125; //100 if(((values[i]) &amp; 0xFFFF) == 0 )&#123; compressable += 2;//SIM_printf(\"100\\n \"); continue; &#125; //101 if( my_abs((int)((values[i]) &amp; 0xFFFF)) &lt;= 0xFF &amp;&amp; my_abs((int)((values[i] &gt;&gt; 16) &amp; 0xFFFF)) &lt;= 0xFF)&#123; compressable += 2;//SIM_printf(\"101\\n \"); continue; &#125; //110 unsigned byte0 = (values[i]) &amp; 0xFF; unsigned byte1 = (values[i] &gt;&gt; 8) &amp; 0xFF; unsigned byte2 = (values[i] &gt;&gt; 16) &amp; 0xFF; unsigned byte3 = (values[i] &gt;&gt; 24) &amp; 0xFF; if(byte0 == byte1 &amp;&amp; byte0 == byte2 &amp;&amp; byte0 == byte3)&#123; compressable += 1; //SIM_printf(\"110\\n \"); continue; &#125; //111 compressable += 4; &#125; VG_(free)(values); //6 bytes for 3 bit per every 4-byte word in a 64 byte cache line unsigned compSize = compressable + size * 3 / 8; if(compSize &lt; size * 4) return compSize; else return size * 4;&#125;","categories":[{"name":"源码分析","slug":"源码分析","permalink":"http://malizhen.github.io/categories/源码分析/"}],"tags":[{"name":"compression","slug":"compression","permalink":"http://malizhen.github.io/tags/compression/"}],"keywords":[{"name":"源码分析","slug":"源码分析","permalink":"http://malizhen.github.io/categories/源码分析/"}]},{"title":"gem5主函数main.py","slug":"gem5主函数","date":"2019-07-18T07:38:54.000Z","updated":"2019-07-25T09:01:35.831Z","comments":true,"path":"2019/07/18/gem5主函数/","link":"","permalink":"http://malizhen.github.io/2019/07/18/gem5主函数/","excerpt":"","text":"根据gem5的fs测试结果，结合源码分析gem5执行模拟的过程。直接摘取出主函数分析并注释，涉及到的比较重要的其他函数也会在后面一并说明。 执行的fs测试命令如红框所示。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416import codeimport datetimeimport osimport socketimport sys__all__ = [ 'options', 'arguments', 'main' ]usage=\"%prog [gem5 options] script.py [script options]\"version=\"%prog 2.0\"brief_copyright=\\ \"gem5 is copyrighted software; use the --copyright option for details.\"#OptionParser(usage=\"%prog\",version=\"%prog 1.0\",description=\"hi\") #%prog 在这里会自动替换为程序名字 #usage 可以打印用法 #version 在使用%prog --version的时候输出版本信息 #description 描述信息def parse_options(): import config from options import OptionParser#使用OptionParser解析命令行参数，首先创建options实例 options = OptionParser(usage=usage, version=version, description=brief_copyright) #使用add_option添加要处理的命令行参数 option = options.add_option #对命令行参数进行分类别分组 group = options.set_group##action 指示optparser解析参数时候该如何处理。默认是'store'，表示将命令行参数值保存options对象里 。&lt;br&gt;action的值有：store,store_true,store_false,store_const,append,count,callback.#store store可以为store_true和store_false两种形式。用于处理命令行参数后面不带值的情况。如-v,-q等命令行参数。#type 默认是“string\",也可以是\"int\",\"float\"等#dest 如果没有指定dest参数，将用命令行参数名来对options对象的值进行存取。#default 设置默认值#help 指定帮助文档#metavar 提示用户期望参数 # Help options option('-B', \"--build-info\", action=\"store_true\", default=False, help=\"Show build information\") option('-C', \"--copyright\", action=\"store_true\", default=False, help=\"Show full copyright information\") option('-R', \"--readme\", action=\"store_true\", default=False, help=\"Show the readme\") # Options for configuring the base simulator option('-d', \"--outdir\", metavar=\"DIR\", default=\"m5out\", help=\"Set the output directory to DIR [Default: %default]\") option('-r', \"--redirect-stdout\", action=\"store_true\", default=False, help=\"Redirect stdout (&amp; stderr, without -e) to file\") option('-e', \"--redirect-stderr\", action=\"store_true\", default=False, help=\"Redirect stderr to file\") option(\"--stdout-file\", metavar=\"FILE\", default=\"simout\", help=\"Filename for -r redirection [Default: %default]\") option(\"--stderr-file\", metavar=\"FILE\", default=\"simerr\", help=\"Filename for -e redirection [Default: %default]\") option('-i', \"--interactive\", action=\"store_true\", default=False, help=\"Invoke the interactive interpreter after running the script\") option(\"--pdb\", action=\"store_true\", default=False, help=\"Invoke the python debugger before running the script\") #action=‘append’：保存为列表格式，将每个参数的值添加到这个列表。 option('-p', \"--path\", metavar=\"PATH[:PATH]\", action='append', split=':', help=\"Prepend PATH to the system path when invoking the script\") option('-q', \"--quiet\", action=\"count\", default=0, help=\"Reduce verbosity\") option('-v', \"--verbose\", action=\"count\", default=0, help=\"Increase verbosity\") # Statistics options group(\"Statistics Options\") option(\"--stats-file\", metavar=\"FILE\", default=\"stats.txt\", help=\"Sets the output file for statistics [Default: %default]\") # Configuration Options group(\"Configuration Options\") option(\"--dump-config\", metavar=\"FILE\", default=\"config.ini\", help=\"Dump configuration output file [Default: %default]\") option(\"--json-config\", metavar=\"FILE\", default=\"config.json\", help=\"Create JSON output of the configuration [Default: %default]\") option(\"--dot-config\", metavar=\"FILE\", default=\"config.dot\", help=\"Create DOT &amp; pdf outputs of the configuration [Default: %default]\") option(\"--dot-dvfs-config\", metavar=\"FILE\", default=None, help=\"Create DOT &amp; pdf outputs of the DVFS configuration\" + \\ \" [Default: %default]\") # Debugging options group(\"Debugging Options\") option(\"--debug-break\", metavar=\"TICK[,TICK]\", action='append', split=',', help=\"Create breakpoint(s) at TICK(s) \" \\ \"(kills process if no debugger attached)\") option(\"--debug-help\", action='store_true', help=\"Print help on debug flags\") option(\"--debug-flags\", metavar=\"FLAG[,FLAG]\", action='append', split=',', help=\"Sets the flags for debug output (-FLAG disables a flag)\") option(\"--debug-start\", metavar=\"TICK\", type='int', help=\"Start debug output at TICK\") option(\"--debug-end\", metavar=\"TICK\", type='int', help=\"End debug output at TICK\") option(\"--debug-file\", metavar=\"FILE\", default=\"cout\", help=\"Sets the output file for debug [Default: %default]\") option(\"--debug-ignore\", metavar=\"EXPR\", action='append', split=':', help=\"Ignore EXPR sim objects\") option(\"--remote-gdb-port\", type='int', default=7000, help=\"Remote gdb base port (set to 0 to disable listening)\") # Help options group(\"Help Options\") option(\"--list-sim-objects\", action='store_true', default=False, help=\"List all built-in SimObjects, their params and default values\") # load the options.py config file to allow people to set their own # default options options_file = config.get('options.py') if options_file: scope = &#123; 'options' : options &#125; execfile(options_file, scope)#调用parse_args()解析命令行形参#可以传递一个参数列表给parse_args(),否则，默认使用命令行参数（sysargv[1:])。#返回的arguments是一个由positional arguments组成的列表。 arguments = options.parse_args() return options,argumentsdef interact(scope): banner = \"gem5 Interactive Console\" ipshell = None prompt_in1 = \"gem5 \\\\#&gt; \" prompt_out = \"gem5 \\\\#: \" # Is IPython version 0.10 or earlier available? try: from IPython.Shell import IPShellEmbed ipshell = IPShellEmbed(argv=[\"-prompt_in1\", prompt_in1, \"-prompt_out\", prompt_out], banner=banner, user_ns=scope) except ImportError: pass # Is IPython version 0.11 or later available? if not ipshell: try: import IPython from IPython.config.loader import Config from IPython.terminal.embed import InteractiveShellEmbed cfg = Config() cfg.PromptManager.in_template = prompt_in1 cfg.PromptManager.out_template = prompt_out ipshell = InteractiveShellEmbed(config=cfg, user_ns=scope,banner1=banner) except ImportError: pass if ipshell: ipshell() else: # Use the Python shell in the standard library if IPython # isn't available. code.InteractiveConsole(scope).interact(banner)def main(*args): import m5 import core import debug import defines import event import info import stats import trace from util import fatal#options，它是一个对象（optpars.Values），保存有命令行参数值。只要知道命令行参数名，如 file，就可以访问其对应的值： options.file 。 if len(args) == 0: options, arguments = parse_options() elif len(args) == 2: options, arguments = args else: raise TypeError, \"main() takes 0 or 2 arguments (%d given)\" % len(args) m5.options = options def check_tracing(): if defines.TRACING_ON: return fatal(\"Tracing is not enabled. Compile with TRACING_ON\") # Set the main event queue for the main thread. event.mainq = event.getEventQueue(0) event.setEventQueue(event.mainq) if not os.path.isdir(options.outdir): os.makedirs(options.outdir)# These filenames are used only if the redirect_std* options are set#重定向文件路径 stdout_file = os.path.join(options.outdir, options.stdout_file) stderr_file = os.path.join(options.outdir, options.stderr_file) # Print redirection notices here before doing any redirection if options.redirect_stdout and not options.redirect_stderr: print \"Redirecting stdout and stderr to\", stdout_file else: if options.redirect_stdout: print \"Redirecting stdout to\", stdout_file if options.redirect_stderr: print \"Redirecting stderr to\", stderr_file # Now redirect stdout/stderr as desired # Redirecting stdout to stdout_file if options.redirect_stdout: redir_fd = os.open(stdout_file, os. O_WRONLY | os.O_CREAT | os.O_TRUNC) os.dup2(redir_fd, sys.stdout.fileno()) if not options.redirect_stderr: os.dup2(redir_fd, sys.stderr.fileno())# Redirecting stderr to stderr_file if options.redirect_stderr: redir_fd = os.open(stderr_file, os. O_WRONLY | os.O_CREAT | os.O_TRUNC) os.dup2(redir_fd, sys.stderr.fileno()) done = False if options.build_info: done = True print 'Build information:' print print 'compiled %s' % defines.compileDate; print 'build options:' keys = defines.buildEnv.keys() keys.sort() for key in keys: val = defines.buildEnv[key] print ' %s = %s' % (key, val) print if options.copyright: done = True print info.COPYING print if options.readme: done = True print 'Readme:' print print info.README print if options.debug_help: done = True check_tracing() debug.help() if options.list_sim_objects: import SimObject done = True print \"SimObjects:\" objects = SimObject.allClasses.keys() objects.sort() for name in objects: obj = SimObject.allClasses[name] print \" %s\" % obj params = obj._params.keys() params.sort() for pname in params: param = obj._params[pname] default = getattr(param, 'default', '') print \" %s\" % pname if default: print \" default: %s\" % default print \" desc: %s\" % param.desc print print if done: sys.exit(0) # setting verbose and quiet at the same time doesn't make sense if options.verbose &gt; 0 and options.quiet &gt; 0: options.usage(2) verbose = options.verbose - options.quiet if verbose &gt;= 0: print \"gem5 Simulator System. http://gem5.org\" print brief_copyright print print \"gem5 compiled %s\" % defines.compileDate; print \"gem5 started %s\" % \\ datetime.datetime.now().strftime(\"%b %e %Y %X\") print \"gem5 executing on %s, pid %d\" % \\ (socket.gethostname(), os.getpid()) # in Python 3 pipes.quote() is moved to shlex.quote() import pipes print \"command line:\", \" \".join(map(pipes.quote, sys.argv)) print # check to make sure we can find the listed script if not arguments or not os.path.isfile(arguments[0]): if arguments and not os.path.isfile(arguments[0]): print \"Script %s not found\" % arguments[0] options.usage(2) # tell C++ about output directory core.setOutputDir(options.outdir) # update the system path with elements from the -p option sys.path[0:0] = options.path # set stats options stats.initText(options.stats_file) # set debugging options debug.setRemoteGDBPort(options.remote_gdb_port) for when in options.debug_break: debug.schedBreak(int(when)) if options.debug_flags: check_tracing() on_flags = [] off_flags = [] for flag in options.debug_flags: off = False if flag.startswith('-'): flag = flag[1:] off = True if flag not in debug.flags: print &gt;&gt;sys.stderr, \"invalid debug flag '%s'\" % flag sys.exit(1) if off: debug.flags[flag].disable() else: debug.flags[flag].enable() if options.debug_start: check_tracing() e = event.create(trace.enable, event.Event.Debug_Enable_Pri) event.mainq.schedule(e, options.debug_start) else: trace.enable() if options.debug_end: check_tracing() e = event.create(trace.disable, event.Event.Debug_Enable_Pri) event.mainq.schedule(e, options.debug_end) trace.output(options.debug_file) for ignore in options.debug_ignore: check_tracing() trace.ignore(ignore) sys.argv = arguments sys.path = [ os.path.dirname(sys.argv[0]) ] + sys.path filename = sys.argv[0] filedata = file(filename, 'r').read() filecode = compile(filedata, filename, 'exec') scope = &#123; '__file__' : filename, '__name__' : '__m5_main__' &#125; # we want readline if we're doing anything interactive if options.interactive or options.pdb: exec \"import readline\" in scope # if pdb was requested, execfile the thing under pdb, otherwise, # just do the execfile normally if options.pdb: import pdb import traceback pdb = pdb.Pdb() try: pdb.run(filecode, scope) except SystemExit: print \"The program exited via sys.exit(). Exit status: \", print sys.exc_info()[1] except: traceback.print_exc() print \"Uncaught exception. Entering post mortem debugging\" t = sys.exc_info()[2] while t.tb_next is not None: t = t.tb_next pdb.interaction(t.tb_frame,t) else: exec filecode in scope # once the script is done if options.interactive: interact(scope)if __name__ == '__main__': from pprint import pprint options, arguments = parse_options() print 'opts:' pprint(options, indent=4) print print 'args:' pprint(arguments, indent=4)","categories":[{"name":"源码分析","slug":"源码分析","permalink":"http://malizhen.github.io/categories/源码分析/"}],"tags":[{"name":"gem5","slug":"gem5","permalink":"http://malizhen.github.io/tags/gem5/"}],"keywords":[{"name":"源码分析","slug":"源码分析","permalink":"http://malizhen.github.io/categories/源码分析/"}]},{"title":"SubArray.cpp分析","slug":"SubArray.cpp源码分析","date":"2019-07-11T07:07:55.000Z","updated":"2019-07-23T10:56:27.418Z","comments":true,"path":"2019/07/11/SubArray.cpp源码分析/","link":"","permalink":"http://malizhen.github.io/2019/07/11/SubArray.cpp源码分析/","excerpt":"","text":"在nvmain的源代码中，可以看到EnergyModel有两种，energy和current。 这可以在config文件中进行配置，比如说PCM_ISSCC_2012_4GB.config中这样配置： 1EnergyModel energy 同样的，在STTRAM以及RRAM等NVM存储器中也都是energy，如上配置，而在DRAM等易失性存储器中这样配置： 1EnergyModel current 源码中针对NVM存储器的EnergyModel，采用如下这样一种很简单的累加方式来计算能耗，其中Erd是单个mat的读能耗，在PCM_ISSCC_2012_4GB.config中设定值为0.081200，同时设定Ewr即写能耗（SET或者RESET）为1.684811： 12345else&#123; subArrayEnergy += p-&gt;Erd; activeEnergy += p-&gt;Erd; &#125; Write(NVMainRequest *request )首先搞清楚一些基本知识。 12345678enum SubArrayState &#123; SUBARRAY_UNKNOWN, /* Unknown state. Uh oh. */ SUBARRAY_OPEN, /* SubArray has an open row */ SUBARRAY_CLOSED, /* SubArray is idle. */ SUBARRAY_PRECHARGING, /* SubArray is precharging and return to SUBARRAY_CLOSED */ SUBARRAY_REFRESHING /* SubArray is refreshing and return to SUBARRAY_CLOSED */&#125;; SubArrayState有UNKNOWN、OPEN、CLOSED、PRECHARGING、REFRESHING五种状态： Precharge：对于处于打开状态（这儿打开是指把page内容放入到Sense Amplifier）的page，我们可以进行读写操作，如果不需要再对该page进行读写操作，可以关闭该page, 把该page内容写入bank的行列单元对应的page中，然后DRAM core才能够准备下一个数据访问，以便对其它page进行读写操作。这个关闭操作通过发射一个Precharge命令实现，precharge命令可以关闭某一个bank，也可以关闭rank中所有打开的bank。 Refreshing：DRAM（Dynamic Random Access Memory，即动态随机存取存储器）之所以称为DRAM，就是因为它要不断进行刷新（Refresh）才能保留住数据，因此它是DRAM最重要的操作。Refresh操作与Precharge中重写的操作一样，都是用S-AMP先读再写。但为什么有Precharge操作还要进行Refresh呢？因为Precharge是对一个或所有Bank中的工作行操作，并且是不定期的，而刷新则是有固定的周期，依次对所有行进行操作，以保留那些久久没经历重写的存储体中的数据。 123456enum WriteMode &#123; WRITE_BACK, /* only modify the row buffer */ WRITE_THROUGH, /* modify both row buffer and cell */ DELAYED_WRITE /* data is stored in a write buffer */&#125;; WriteMode有三种，WRITE_BACK、WRITE_THROUGH以及DELAYED_WRITE： WRITE_BACK：只更新行缓冲区； WRITE_THROUGH：更新行缓冲区和cell； DELAYED_WRITE：数据被存储在写缓冲区； Write函数分析这个函数很重要，大致写一下自己的理解。 12345678910void NVMAddress::GetTranslatedAddress( uint64_t *addrRow, uint64_t *addrCol, uint64_t *addrBank, uint64_t *addrRank, uint64_t *addrChannel, uint64_t *addrSA )&#123; if( addrRow ) *addrRow = row; if( addrCol ) *addrCol = col; if( addrBank ) *addrBank = bank; if( addrRank ) *addrRank = rank; if( addrChannel ) *addrChannel = channel; if( addrSA ) *addrSA = subarray;&#125; 首先进行sanity完整性检查，这一部分的完整性检查必不可少，不能完全信任IsIssuable()而缺少完整性检查。 若nextWrite大于事件队列的当前时钟周期，则Subarray违反写时序限制；若SubArrayState不等于SUBARRAY_OPEN，则试图对非active状态的subarray进行写入而报错；若writeRow不等于openRow，则试图对没有open的行进行写入而报错。 若writeMode为WRITE_THROUGH，则需要更新行缓冲区和cell。 12345678910111213141516171819202122232425262728 if( writeMode == WRITE_THROUGH ) &#123; encLat = (dataEncoder ? dataEncoder-&gt;Write( request ) : 0); endrLat = UpdateEndurance( request ); /* Count the number of bits modified. */ if( !p-&gt;WriteAllBits ) &#123; //声明一个一维数组bitCountData，大小和数据大小（byte）一致 uint8_t *bitCountData = new uint8_t[request-&gt;data.GetSize()];//对数组bitCountData赋值，新旧数据逐byte进行异或操作，结果存储在数组bitCountData中 for( uint64_t bitCountByte = 0; bitCountByte &lt; request-&gt;data.GetSize(); bitCountByte++ ) &#123; bitCountData[bitCountByte] = request-&gt;data.GetByte( bitCountByte ) ^ request-&gt;oldData.GetByte( bitCountByte ); &#125;//这里应该是和后面设计的Count32MLC1函数有关，该函数的操作对象是uint32_t的数据，所以定义bitCountWords为原数据byte数除以4。不过更有可能是因为很多论文比如FPC中指定一个word为4 byte，所以接下来的计算都是以word为操作单位 ncounter_t bitCountWords = request-&gt;data.GetSize()/4;//以32bit为单位计算bitCountData中1的个数，即为bit更新的数目，因为异或操作值不同则为1 ncounter_t numChangedBits = CountBitsMLC1( 1, (uint32_t*)bitCountData, bitCountWords );//若括号内条件为假，即原数据bit数小于计算所得的更新bit数，则打印错误信息，通过调用abort来终止程序运行 assert( request-&gt;data.GetSize()*8 &gt;= numChangedBits ); //未更新bit数目=总bit数-更新bit数目 numUnchangedBits = request-&gt;data.GetSize()*8 - numChangedBits; &#125; &#125; 1234567891011ncounter_t NO_OPT SubArray::Count32MLC1( uint32_t data )&#123; //使用神奇操作来计算这个data中1的个数。这个操作够神奇的看不懂，不过以后如果要计算一串32bit二进制数据中1的个数可以照搬 uint32_t count = data; count = count - ((count &gt;&gt; 1) &amp; 0x55555555); count = (count &amp; 0x33333333) + ((count &gt;&gt; 2) &amp; 0x33333333); count = (((count + (count &gt;&gt; 4)) &amp; 0x0f0f0f0f) * 0x01010101) &gt;&gt; 24; return static_cast&lt;ncounter_t&gt;(count);&#125; 123456789101112ncounter_t NO_OPT SubArray::CountBitsMLC1( uint8_t value, uint32_t *data, ncounter_t words ) &#123; ncounter_t count = 0; //计算每个word中间新旧数据不同bit数目，并累加得到整个data中间需要更新的bit数 for( ncounter_t i = 0; i &lt; words; i++ ) &#123; count += Count32MLC1( data[i] ); &#125; //如果value=1，count=count，否则count=words*32-count count = (value == 1) ? count : (words*32 - count); return count; &#125; EnergyModel能耗优化计算方案基于NVM的主存储器设计一种延迟和能量优化写方案。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899/* Calculate energy. */ if( p-&gt;EnergyModel == \"current\" ) &#123; /* DRAM Model. */ subArrayEnergy += ( ( p-&gt;EIDD4W - p-&gt;EIDD3N ) * (double)(p-&gt;tBURST) ) / (double)(p-&gt;BANKS); burstEnergy += ( ( p-&gt;EIDD4W - p-&gt;EIDD3N ) * (double)(p-&gt;tBURST) ) / (double)(p-&gt;BANKS); &#125; else &#123; /* Flat energy model. */ //subArrayEnergy += p-&gt;Ewr - p-&gt;Ewrpb * numUnchangedBits; uint32_t *rawData; uint32_t *oldData; ncounter_t memoryWordSize = 64 * 8 ; ncounter_t size = 0; if(request-&gt;data.IsCompressed()) &#123; rawData = reinterpret_cast&lt;uint32_t*&gt;(request-&gt;data.comData); memoryWordSize = request-&gt;data.GetComSize()*8; &#125; else &#123; rawData = reinterpret_cast&lt;uint32_t*&gt;(request-&gt;data.rawData); &#125; if(request-&gt;oldData.IsCompressed()) &#123; oldData = reinterpret_cast&lt;uint32_t*&gt;(request-&gt;oldData.comData); &#125; else &#123; oldData = reinterpret_cast&lt;uint32_t*&gt;(request-&gt;oldData.rawData); &#125; size = memoryWordSize / 32; double energy = 0; unsigned int i = 0; ncounter_t i_pos = 0; uint32_t word; uint32_t oldWord; uint32_t mask = 0x00000007; uint32_t byte; uint32_t oldByte; ncounter_t writeCount[8]; ncounter_t EwrTLC[8]; EwrTLC[0] = p-&gt;Ewr000; EwrTLC[1] = p-&gt;Ewr001; EwrTLC[2] = p-&gt;Ewr010; EwrTLC[3] = p-&gt;Ewr011; EwrTLC[4] = p-&gt;Ewr100; EwrTLC[5] = p-&gt;Ewr101; EwrTLC[6] = p-&gt;Ewr110; EwrTLC[7] = p-&gt;Ewr111; for(i_pos = 0; i_pos &lt; 8; i_pos++) writeCount[i_pos] = 0; for(i = 0; i &lt; size; i++) &#123; word = rawData[i]; oldWord = oldData[i]; for(i_pos = 0; i_pos &lt; 11; i_pos++) &#123; byte = word &amp; mask; oldByte = oldWord &amp; mask; if(byte != oldByte) writeCount[byte]++; word = word &gt;&gt; 3; oldWord = oldWord &gt;&gt; 3; &#125; &#125; size = memoryWordSize % 32; if(size != 0) &#123; word = rawData[i]; oldWord = oldData[i]; ncounter_t nums_r = size / 3; if(size % 3 != 0) nums_r++; for(i_pos = 0; i_pos &lt; (11-nums_r); i_pos++) &#123; word = word &gt;&gt; 3; oldWord = oldWord &gt;&gt; 3; &#125; for(; i_pos &lt; 11; i_pos++) &#123; byte = word &amp; mask; oldByte = oldWord &amp; mask; if(byte != oldByte) writeCount[byte]++; word = word &gt;&gt; 3; oldWord = oldWord &gt;&gt; 3; &#125; &#125; for(i_pos = 0; i_pos &lt; 8; i_pos++) &#123; energy += writeCount[i_pos] * EwrTLC[i_pos]; &#125; subArrayEnergy += energy; burstEnergy += p-&gt;Ewr; &#125;","categories":[{"name":"源码分析","slug":"源码分析","permalink":"http://malizhen.github.io/categories/源码分析/"}],"tags":[{"name":"nvmain","slug":"nvmain","permalink":"http://malizhen.github.io/tags/nvmain/"}],"keywords":[{"name":"源码分析","slug":"源码分析","permalink":"http://malizhen.github.io/categories/源码分析/"}]},{"title":"Compression Architecture for Bit-write Reduction","slug":"Compression Architecture for Bit-write Reduction","date":"2019-07-04T13:20:22.000Z","updated":"2019-07-05T08:34:02.767Z","comments":true,"path":"2019/07/04/Compression Architecture for Bit-write Reduction/","link":"","permalink":"http://malizhen.github.io/2019/07/04/Compression Architecture for Bit-write Reduction/","excerpt":"","text":"Compression Architecture for Bit-write Reduction in Non-volatile Memory Technologies（原文链接）。本文提出了一个基于压缩的架构，实现位写减少。位写减少有很多的好处，包括降低写延迟、降低动态功耗、提高耐受力。提出一个集成进NVM模块的架构，包括（i）一个频繁模式压缩-解压引擎；（ii）和一个比较器协同工作实现减少位写；（iii）一个投机取巧的磨损均衡方案，通过减少部分cell位反复写，平衡分布写，提高内存的耐受力。 Compression-based NVM本文描述的压缩架构的核心思想是内存中word被一个new word重写的时候，利用一个简单的压缩方案来减少位写。目前最先进的针对这部分的研究有DCW和FNW。与DRAM不同，DRAM在每次读写操作期间，所在的整个内存行需要被写回。而在NVM中，刷新没有发生变化的位没有必要。 Write集成了本文架构的NVM模块如何处理写请求？首先，直接集成在NVM模块中的CDE（Compression-Decompression Engine）尝试压缩写入的新数据，CDE实现了基于FPC（见上篇博客）的压缩方法。然后，当CDE尝试压缩数据的同时，NVM模块控制器读取NVM数组中目标地址的数据（旧数据）。一旦压缩完成，旧数据和新数据逐位比较找不同位，否则，直接写入未压缩数据。基于逐位比较结果，只更新写入新旧数据之间对应不同的位（差分写）。最后，系统更新压缩tag位，来表明该地址的数据是否被压缩。 Read在读访问过程中，执行步骤和写数据相反。首先，CDE从NVM数组读取word及其对应的tag位。检查tag位确定读取的word是否被压缩，若被压缩，该word经过CDE，解压结果直接转发到处理器。否则，该word略过CDE组件，直接被转发到处理器。 Architecture如下图所示，CDE直接集成到NVM模块，实现数据在写操作期间的无缝压缩与解压。添加额外的电路，实现新数据经过CDE，允许未压缩的数据在读操作期间绕过CDE被读取。NVM阵列也相应地修改，以支持tag位标记是否压缩和磨损均衡。NVM阵列中每个32-bit word，添加两个tag位，一个tag用于表示内存中数据是否被压缩，另一个tag用于磨损均衡技术中表示“normal”写还是“flip”写。这里的tag位带来的额外存储开销与FNW方案中一样，FNW中每16-bit要求1个tag。 Frequent Pattern Compression(FPC)写访问期间，CDE压缩写入的新数据时，利用基于FPC的压缩方法，首先检查word的内容，确定是否匹配FPC模式表中的某种模式，如果匹配，CDE添加相应前缀压缩编码该word。读访问期间，这个3-bit的前缀用来确定匹配的模式，CDE可以根据模式表反向解码该word。 如下图写入新数据，对应上图模式表中001的4-bit符号扩展模式，因此新数据压缩编码为前缀+数据，即0011001，若从左往右逐位与旧数据进行比对，翻转写不同位，如图所示标红有两bit翻转写。到这里很容易考虑到一个问题，如果每次写入新数据的时候都这样操作，那么位翻转全部集中在word的左侧bit，会造成写入不均衡的问题，怎么解决？很简单，适当地从右往左写，但是这样的话，同样会有问题，对于利用FPC压缩效果不佳（大部分word压缩率不足50%）的应用，比如32-bit压缩至加上前缀共19bit，那么中间有6-bit重叠，无论从左还是从右写都一样，中间6bit都会受到磨损，这会造成word中间部分bit的重复写，最终导致word中间部分bit最先磨损。同样，若压缩效果太好的话，中间bit位无论从哪边开始写都不被磨损，会造成word的中间部分bit翻转写次数极少。 这个问题带来的影响本文没有很好地解决！！！ Wear Leveling针对以上磨损均衡方案，CDE和NVM阵列需要做必要的修改。 Write每个word添加第二个“position” tag位，表示当前将数据存储到NVM阵列的哪一侧。与此同时，NVM模块添加电路，来决定压缩数据应该正常写还是翻转写，tag为0表示正常写（从左往右），tag为1表示翻转方向对称写（从右往左）。此外，如果被写入的新数据没有匹配上任何模式，即未被压缩，那么position tag位为0，因为对于未压缩数据，数据从哪一侧写都一样。 Read读访问期间，如果数据是压缩的，CDE读取position tag位，确认数据在NVM阵列的哪一侧。如果position tag位表示数据被写入NVM word的右半部分，那么CDE读取的数据将被翻转，以将前缀恢复到正确的形式，并将数据传递给CDE对应模式表进行解压缩。 Write orientation那依据什么来决定在NVM阵列中新数据到底是从左向右写还是从右向左写呢？本文提出有两个方法; 利用一个写访问计数器，一旦计数器超过某一固定阈值，写访问指示器由”normal”（即position tag为0）变为”flipped“（即position tag为1），转换写方向，并且重置计数器。 那么阈值怎么确定呢？本文没说阈值的设定方式，本人感觉这个阈值应该小一点磨损均衡效果会更好，相当于更加频繁地在两个方向写之间切换，阈值越小，不会导致有一个方向的写入多一轮而多出的写次数比较多。 使用翻转位写的数量来确定写的方向，实现一个更加投机取巧的磨损均衡方案。CDE中的附加电路比较新数据和旧数据，从两个方向进行比较。CDE基于这种比较，分别针对两个方向写计算出位翻转的数目，有更少位翻转的方向被选择，按该方向写入数据，同时正确设置position tag位。 但是第二种方法与其说是一种磨损均衡，似乎更像是一种翻转位写减少优化方案。同时也许可能有磨损均衡的作用，效果视数据类型而定吧。因为某些应用程序可能始终选择从左往右写，会得到更少的位翻转，这根本不能达到磨损均衡的目的。 Evaluation and Result实验评估显示有几个负载翻转位写数量相比FNW反而增多，为什么？ 实验发现，这些负载同时对应有较低的压缩率或者有很大比例的line不压缩，那么本文的方法由于增加的两个tag位也会带来额外的位翻转，可能会造成这种结果。","categories":[{"name":"论文阅读记录","slug":"论文阅读记录","permalink":"http://malizhen.github.io/categories/论文阅读记录/"}],"tags":[{"name":"compression algorithm","slug":"compression-algorithm","permalink":"http://malizhen.github.io/tags/compression-algorithm/"}],"keywords":[{"name":"论文阅读记录","slug":"论文阅读记录","permalink":"http://malizhen.github.io/categories/论文阅读记录/"}]},{"title":"Frequent Pattern Compression","slug":"Frequent Pattern Compression","date":"2019-07-01T12:39:37.000Z","updated":"2019-07-04T07:47:38.432Z","comments":true,"path":"2019/07/01/Frequent Pattern Compression/","link":"","permalink":"http://malizhen.github.io/2019/07/01/Frequent Pattern Compression/","excerpt":"","text":"Frequent Pattern Compression: A Significance-Based Compression Scheme for L2 Caches（ 原文链接）。随着处理器和内存速度之间差距的扩大，内存系统设计人员可能会发现缓存压缩有利于增加缓存容量和减少片外带宽。大多数硬件压缩算法都属于基于字典的类别，这依赖于构建字典并使用其条目对重复数据值进行编码，在压缩大数据块和文件时非常有效。然而，cache line通常为32-256 bytes，每行字典的开销很大，这限制了这种算法的可压缩性，并增加了解压缩延迟。对于这样的短行，基于重要性的压缩可以考虑。 本文提出并评估一种简单的基于重要性的压缩方案，该方案具有较低的压缩和解压缩开销。该方案使用带适当前缀的压缩格式存储常见的word模式，从而按word逐行压缩cache line。提出一种压缩缓存设计，其中数据以压缩形式存储在L2中，但在L1中未压缩。L2被压缩到预先确定的大小，以减少解压开销。 基于重要性的压缩基于这样的观察：大多数数据类型(例如，32位整数)可以存储在比允许的最大位数更少的位中。即窄值与0值大量存在。与基于字典的压缩方案相比，基于重要性的压缩不会产生每行字典开销，这使得它更适用于典型的短缓存行。此外，压缩和解压硬件比基于字典的编码和解码要快。然而，对于长缓存行，可压缩性可能会显著降低。 Frequent Pattern Compression每个cache line被分成一些32-bit大小的word(例如，64-byte的cache line分成16个word)。表1显示了每个前缀对应的不同模式。这些模式是根据许多商业基准测试中的高频模式选择的。每个32-bit的word都根据模式表被编码为一个3-bit前缀加上数据的压缩格式。 与这些模式都不匹配的word以其原始的32位格式存储。如果某个word与表1前七行中的任一模式匹配，则将其编码为压缩格式。 Segmented Frequent Pattern Compression与未压缩相比，L2 cache必须能够在相同的空间中容纳更多的压缩cache line。这就会导致原本的线性映射被破坏，或者产生碎片可利用空间。最常见的解决这一问题的办法是解耦缓存访问，在address tag与data storage之间添加间接层。 理论上，cache line可以压缩成任意数量的bit。然而，这种设计增加了缓存管理的复杂性。本文的压缩缓存设计中，每个缓存行存储为一组8-byte segemnt。例如，64-byte的cache line一定能够被存储为1-8个segment，未压缩为8个8-byte segment。压缩的cache line，填充0，直到其大小变为段大小(8 byte)的倍数，这些额外的0(与任何tag不对应)在解压缩期间被忽略。虽然这种方法可能在某些模式下不具有高压缩比，比如，全0的情况下，但是它能够更快地实现缓存访问。 Compression and Decompression本文提出了一种压缩缓存设计，其中未压缩数据存储在L1中，压缩数据存储在L2中。这有助于减少许多阻碍性能的L2缓存缺失，同时不影响L1缓存的命中。然而，这样的设计增加了在两个级别缓存之间移动时压缩或解压的开销。而FPC能够尽可能降低压缩与解压开销。 Compressioncache line压缩发生在数据从L1写到L2时。使用一个简单的电路(并行地)检查每个word的模式匹配，如果一个word匹配七个可压缩模式中的任何一个，就使用一个简单的编码电路将word编码成最紧凑的形式。如果没有找到匹配项，则将整个word存储为前缀“111”。对于zero run，需要检测连续运行的零，并递增第一次出现的数据值来表示它们的计数。由于本文的设计中zero run被限制为8个零，这可以在一个循环中使用一个简单的多路复用器/加法器电路来实现。cache line压缩可以在内存管道中实现，方法是在L1到L2的写路径上分配三个管道阶段(一个用于模式匹配，一个用于zero run编码，一个用于收集压缩行)。一个包含少量压缩和非压缩形式条目的小受害者缓存可以用来隐藏L1写回时的压缩延迟。 Decompression当数据从L2读取到L1时，会发生cache line解压缩。解压延迟非常重要，因为它被直接添加到L2 hit延迟中。解压缩比压缩慢，因为cache line中所有word的前缀都必须按顺序访问，因为每个前缀用于确定其对应的编码word的长度，从而确定所有后续压缩word的起始位置。 下图展示了一种可用于解压64-byte cache line的五阶段硬件管道。","categories":[{"name":"论文阅读记录","slug":"论文阅读记录","permalink":"http://malizhen.github.io/categories/论文阅读记录/"}],"tags":[{"name":"compression algorithm","slug":"compression-algorithm","permalink":"http://malizhen.github.io/tags/compression-algorithm/"}],"keywords":[{"name":"论文阅读记录","slug":"论文阅读记录","permalink":"http://malizhen.github.io/categories/论文阅读记录/"}]},{"title":"Gem5简介","slug":"Gem5简介","date":"2019-06-28T06:51:26.000Z","updated":"2019-06-28T07:07:08.096Z","comments":true,"path":"2019/06/28/Gem5简介/","link":"","permalink":"http://malizhen.github.io/2019/06/28/Gem5简介/","excerpt":"","text":"Gem5是一款模块化的离散事件驱动全系统模拟器，它结合了M5和GEMS中最优秀的部分，M5提供了高度可配置的模拟框架，支持多种ISAs和CPU模型；GEMS补充了M5的特性，提供了详细而灵活的内存系统，包括多种cache 一致性协议和互连模型，是一款高度可配置、集成多种ISA，多种CPU模型的体系结构模拟器。 gem5模拟器目前支持多种ISAs，包括Alpha、ARM、MIPS、Power、SPARC和x86。模拟器的模块性允许这些不同的ISAs插入到通用CPU模型和内存系统中，而不需要为每一种ISAs设置一种专用的CPU模型和存储模型，这使得模拟器模块化程度较高且易于在不同CPU之间切换。 M5是由Michigan大学开发的一款开源的多处理机模拟器，受到了业内的广泛关注，很多高水平论文都采用M5作为研究工具。另一方面，Wisconsin推出的GEMS能够对储存层次进行详细而灵活的模拟，包括对多种不同的cache一致性协议和互联模型的支持。目前的GEM5是M5和GEMS的一个紧耦合版本。 1.总体目标gem5模拟器的目标是成为一个用于体系结构建模的优秀工具。这一目标的三个关键方面是灵活性，可用性，高度可协作性。 图一 Speed vs. Accuracy 1.1 灵活性灵活性是一个好的模拟器的基础。当一个想法从概念落地到一个特定的设计时，程序员需要一个工具来评估系统，平衡仿真速度和准确性。不同类型的实验可能有不同的模拟要求。例如，某些实验可能需要一个精细的CPU模型，但是没有必要进行多核建模。而某些实验可能需要多个CPU，但是这些CPU不需要太多的细节。所以模拟器的灵活性必不可少，使得程序员能够以更少的开销更快地完成更多的工作。 gem5模拟器就是这样一个工具，提供了各种各样的功能和组件，涵盖了仿真速度和精度之间的权衡。如图1所示。 CPU模型gem5模拟器目前提供了四种不同的CPU模型：AtomicSimple、TimingSimple、InOrder和O3。AtomicSimple和TimingSimple是非流水线CPU模型，AtomicSimple是一种最小的单IPC CPU模型，适用于快速功能模拟；TimingSimple与之类似，但是使用了存储器访问时序模型，用以统计存储器访问延迟；InOrder是一个按序流水线CPU模型，该模式下，可以配置硬件支持的线程数量；O3是一个乱序流水线CPU模型，可以支持超标量结构和SMT。InOrder与O3都是execute-in-execute（指令的执行只在执行阶段）的设计。 系统模式gem5支持两种执行模式：System-call Emulation（SE）和Full-System（FS）。 SE模式中，当程序执行系统调用时，gem5会捕捉到，同时模拟调用，通常是传递给主机操作系统。通过模拟大部分的系统调用，避免了对外设和OS进行建模的需要。SE模式下，没有线程调度器，线程必须静态的映射到cores，因此会限制多线程应用。SPEC CPU基准测试通常在SE模式下运行。FS（全系统）模式对一个完整系统，包括OS和外设，进行了建模，支持执行用户和内核指令。FS模式中，gem5提供了一个适合运行操作系统的裸机环境，包括中断，异常等，并不是所有ISAs都支持此模式。FS相对于SE，精度更高，可以执行更多类型的负载。虽然SPEC CPU基准测试通常在SE模式下运行，但是在FS模式下运行它们将提供与OS更实际的交互。因此需要许多OS服务或I/O设备的工作负载可能只在FS模式下运行。 存储系统支持两种存储系统模型：Classic和Ruby。Classic模型（来自M5）提供了一个快速且易于配置的内存系统；Ruby模型（来自GEMS）提供了一种灵活且能够精确模拟的内存系统，支持cache一致性。Ruby内存模型支持大量的互连拓扑结构，同时包括两种不同的网络模型。组件之间的链接使用一个简单的python文件声明，然后通过最短路径分析创建路由表。在确定链接和路由表后，根据不同的网络模型进行实现。两种网络模型为： 1、Simple网络模型：只对链接，路由延迟和链路带宽，并没有对路由器资源争用和流量控制建模。 2、Garnet网络模型：对路由建立了详细的模型，包括相关的资源竞争和流量控制。 1.2 可用性gem5用户有几种类型，每个人都有不同的目标和需求。这些人包括学术和企业研究人员、工业工程师、本科生和研究生。Gem5的开发者们希望gem5模拟器能够广泛地提供给所有这些类型的用户。gem5许可证(基于BSD)对企业用户和学术界都很友好。gem5社区非常活跃，有很多协作技术可以促进gem5的使用和开发。 2.设计特点本节重点介绍gem5实现的几个关键方面：面向对象的设计、Python集成、特定领域的语言和标准化接口的使用。 2.1 面向对象灵活性是gem5模拟器的一个重要目标，也是其成功的关键方面。灵活性主要是通过面向对象的设计来实现的。gem5模拟器中的每个主要仿真组件都是SimObjects，它们共享配置、初始化、统计和序列化(检查点)的公共行为。SimObjects包括了具体的硬件组件(如处理器内核、缓存、互连元素和外设)以及更抽象的实体(如用于系统调用仿真的工作负载及其关联的流程上下文)。这里的外设包括简单的定时器到复杂的网络接口控制器，通过使用基类来封装公共设备接口，以避免代码重复，简化实现。所有的SimObject对象都由两种类表示，python类和c++类。Python类的定义指定了SimObject的参数，并且可以在配置脚本文件中使用。公共Python基类为实例化、命名和设置参数值提供了统一的机制。C++类包含了SimObject的状态和其它行为，同时包括了关键性能的仿真模型。 2.2 Python集成gem5中的代码85%是用C++写成的，15%的Python代码主要负责SimObject的初始化、配置和模拟控制。模拟器在启动时立即开始执行Python代码，标准的main函数使用python编写，所有的命令行处理和启动代码都是python代码。 2.3 领域特定语言gem5提供了两种特定领域的语言，一种用于描述ISA（继承自M5），另一种用于描述cache的一致性协议（继承自GEMS）。 ISA DSL用于统一二进制指令的解码和它们的语义规范。gem5通过使用一个通用的C++基类来描述指令，从而实现了ISA的独立。每种ISA会重新基类中继承的方法，例如execute()。ISA描述语言允许用户简洁地指定所需的c++代码。 Cache Coherence DSLSLICC是一种DSL，用于灵活的实现cache一致性协议。SLICC目前支持AMD Opteron的基于广播的一致性协议和CMP的目录协议。SLICC将cache，mem，DMA控制器定义为单独的per-memory-block的状态机，这些状态机组合称为整个的协议。gem5中的SLICC将协议定义为一组状态、事件、转换和操作，同时将状态机特定的逻辑和协议无关的组件（例如cache）绑定在一起。gem5的SLICC会自动生成python和c++文件，同时也支持局部变量，以简化编程提高性能 2.4 标准化接口标准化接口是面向对象的基础。有两个核心的接口，端口（port）接口和消息缓冲（message buffer）接口。 1、端口接口：连接内存对象，包括cpu和caches，caches到总线，总线到外设和内存。该接口支持三种机制来访问数据，1) timing模式，用来建模带有详细时序的内存访问，会有request和response的消息机制；2) atomic模式，用来获取时序信息，但是没有消息机制，状态会直接发生变化；3) 功能模式，存储操作不会改变时序信息。 2、消息缓冲接口：Ruby使用端口接口来连接cpu和外设，同时使用消息缓冲接口连接Ruby内部对象。两个接口非常类似。 3.用户资源所有gem5模拟器的文档和信息都可以在网站http://www.gem5.org上找到。该网站包括如何检查、构建和运行gem5模拟器的说明，以及如何下载OS二进制文件和磁盘映像等补充支持文件。","categories":[{"name":"模拟器","slug":"模拟器","permalink":"http://malizhen.github.io/categories/模拟器/"}],"tags":[{"name":"gem5","slug":"gem5","permalink":"http://malizhen.github.io/tags/gem5/"}],"keywords":[{"name":"模拟器","slug":"模拟器","permalink":"http://malizhen.github.io/categories/模拟器/"}]},{"title":"Data Compression Techniques","slug":"Data Compression Techniques总结","date":"2019-06-26T06:57:53.000Z","updated":"2019-07-04T13:20:54.525Z","comments":true,"path":"2019/06/26/Data Compression Techniques总结/","link":"","permalink":"http://malizhen.github.io/2019/06/26/Data Compression Techniques总结/","excerpt":"","text":"最近读了比较多的关于数据压缩的论文，具体的论文阅读记录后续会慢慢抽时间写出来，本文先对最近所读简单地进行一个归纳与总结。主要按照以下目录分几个方面来进行总结。 Motivation 现在的应用程序多为数据密集型； 内存需求近些年一直在增加； 而DRAM作为最常见的系统内存，存储密度低，简单来说就是，目前单个DRAM芯片的集成度已经接近极限，远不能满足大数据对内存容量TB级甚至PB级的需求。显然，数据压缩技术对于未来的系统是必不可少的。 Benefits of Data Compression为什么研究数据压缩，肯定是因为有好处，有前景，那么有哪些好处呢？ 不增加内存大小，就能获得更多的有效容量； 避免内存溢出：尤其适用于嵌入式系统； 减少缺失率和带宽占用； 节省能耗，在能耗相同的情况下，能够做更多的计算。 此外，在NVM和3D内存中尤其适用，能够： 减少写数据量和写能耗； 减轻NVM的耐力问题； Storage Compression(例如，缓存压缩)：减少数据存储能耗 Bandwidth Compression：减少数据移动能耗 Opportunities for Compression就目前研究来看，什么情况下什么类型的数据经常被压缩？ 常量、数据复制和赋值 使用公共值初始化 较大的数据类型用于存储较小的数据 特殊值的大量出现，如0,1 以上情况下的数据有很大的冗余，能够考虑利用压缩来消除冗余，具体是什么类型的数据用下图程序段来举例说明。 图片 目前有很多利用图片中相邻像素点值差异很小这一特点来进行的相关研究。 针对以上前四种数据类型，很多论文中有专业的名词来表示它们，分别是Other Patterns、Repeated Values、Narrow Values、Zero Values。 Challenge in using Compression任何一种技术都不可能十全十美，那么压缩有啥坏处呢？ 有压缩那就对应地有解压缩，而压缩和解压缩都会产生额外的延迟和能耗，压缩延迟不在关键路径上，但是解压缩延迟位于缓存命中的关键路径上，对性能影响很大。 往往现有的压缩率高的压缩算法，对应的就会有复杂的硬件设计，同时有很高的解压延迟开销。 压缩仅在最后一级cache和main memory中有用，因为在L1 cache中存储压缩数据，由于解压缩带来的延迟开销无法接受。 由于压缩是变长的，使得不同cache line的压缩不能并行。 有些技术单独存储未压缩的line，由于复杂的硬件设计会造成很重的开销。 存在某些不可压缩的数据(如加密数据)或低效的压缩算法。 压缩块大小不是固定的，这会使得后续寻址变得困难，因为压缩前原有的线性映射会发生变化，或者由于压缩产生碎片可用空间。 删除和插入数据的大小可能不同，导致替换策略变得复杂。 最重要的一个问题，会或多或少产生额外的元数据，带来额外的存储开销。 如果应用程序内存占用已经很小，压缩没有多大用处，如果内存占用较大，则压缩提供的额外容量也不够，这样来看怎么压缩好像显得有点鸡肋？ Need of Carefully Choosing Data-Block Size如何选择压缩数据块的大小，即压缩粒度怎么决定？越大越好or越小越好？ 大的数据块大小作为压缩粒度：大块内会有更高的冗余，似乎还能够获得更高的压缩比，而且元数据存储开销也会比较低。但是即使只访问大块（例如，2KB）之中的某一个子块（例如，64B），也需要解压整个大块，产生无谓的解压开销，而这很影响性能。此外，在大块内想要找到特殊的模式（例如全为零）比较困难。 小的数据块大小作为压缩粒度：与以上相反，此优点为彼缺点吧！值得注意的是，tag元数据存储开销会大大增加。 因此可以看出，压缩粒度的选择需要根据不同类型应用程序动态选择。 Some Compression Algorithm Huffman coding Lempel-Ziv (LZ) algorithm (and derivatives) X-match and X-RL Frequent value compression (FVC) Frequent pattern compression (FPC) C-PACK Base delta immediate (BDI) compression Zero-value and narrow-value detection … Granularity of Exploiting Redundancy Across different blocks of the whole cache (also called deduplication) Across different words of a cache block Across different bytes of a cache word","categories":[{"name":"论文阅读记录","slug":"论文阅读记录","permalink":"http://malizhen.github.io/categories/论文阅读记录/"}],"tags":[{"name":"compression algorithm","slug":"compression-algorithm","permalink":"http://malizhen.github.io/tags/compression-algorithm/"}],"keywords":[{"name":"论文阅读记录","slug":"论文阅读记录","permalink":"http://malizhen.github.io/categories/论文阅读记录/"}]},{"title":"DRAM层次结构","slug":"DRAM层次结构","date":"2019-06-12T13:14:01.000Z","updated":"2019-06-13T01:19:17.334Z","comments":true,"path":"2019/06/12/DRAM层次结构/","link":"","permalink":"http://malizhen.github.io/2019/06/12/DRAM层次结构/","excerpt":"","text":"DRAM（Dynamic Random Access Memory），即动态随机存取存储器，最为常见的系统内存。DRAM 只能将数据保持很短的时间。为了保持数据，DRAM使用电容存储，所以必须隔一段时间刷新（refresh）一次，如果存储单元没有被刷新，存储的信息就会丢失。设备关机也会丢失数据，不像磁盘硬盘等存储介质，类似于我们平时笔记本电脑的内存条。 本文对DRAM系统的层次结构，做出了比较清晰直观的解读。 DRAM系统的层次结构 该图为DRAM系统的层次结构图，从顶层到底层包含Rank、Chip、Bank、Sub-array、MAT、Cell。一个Rank由多个Chip并列组成，同步工作，共同驱动内存总线，一个Chip内部包含多个Bank，它们包含独立的行地址译码器和感应放大器，可以并发访问。通常认为，Bank是DRAM完成独立操作的最小单元。但事实上，每个Bank又可以进一步分割为很多的Sub-array（纵向），每个Sub-array包含很多MAT（横向）。每个MAT有独立的局部感应放大器。一个典型的MAT包含512*512个Cell，即存储单元。每个存储单元由一个电容和一个晶体管组成：电容的电荷多少表示数字0或1，晶体管的栅极与字线相连，由字线控制晶体管的导通；晶体管的漏极与位线相连，导通时由位线表示单元里存储的数据。 存储单元cellDRAM的内部结构可以说是PC芯片中最简单的，是由许多重复的“单元”——cell组成，每一个cell由一个电容和一个晶体管（一般是N沟道MOSFET）构成，电容可储存1bit数据量，充放电后电荷的多少（电势高低）分别对应二进制数据0和1。由于电容会有漏电现象，因此过一段时间之后电荷会丢失，导致电势不足而丢失数据，因此必须经常进行充电保持电势，这个充电的动作叫做刷新（Refresh），因此动态存储器具有刷新特性，这个刷新的操作一直要持续到数据改变或者断电。而MOSFET则是控制电容充放电的开关。DRAM由于结构简单，可以做到面积很小，存储容量很大。放大cell的结构，对cell进行分析，了解DRAM是如何通过电容存取数据的。 1、写入数据如图，向cell中写入数据时，将WL设置为高电平，使晶体管M处于导通状态。此时，Cs和Bitline共享电荷，对Cs进行充电，电压升高到Vs，Bitline处于高电平，写入1；对Cs进行放电，电压降到0，Bitline处于低电平，写入0。 2、读取数据从cell中读取数据时，同样，首先将WL设为高电平，使晶体管M处于导通状态，逻辑电路通过Bitline感知Cs电荷的重新分配，从而读取数据。具体过程如下：首先，对Bitline进行Precharge，即将Bitline上的电压升到Vs/2，这样的话一旦M处于导通状态，如果cell中保存了1，那么Cs中电压为Vs，与Bitline上电压存在电压差，电荷会从Cs流出到Bitline，使Bitline上的电压升高。cell之外的一个逻辑电路块可以感知这种变化，从而读出数据1。同理，若cell保存的是数据0，那么Cs中电压为0，则Bitline中电荷流出，电压降低，电路感知到这种变化，读出数据0。 注意：由于这种读取操作造成电荷的流入流出，是破坏性的。因此，读操作之后需要Refresh操作，恢复Cs的电荷状态。","categories":[{"name":"存储","slug":"存储","permalink":"http://malizhen.github.io/categories/存储/"}],"tags":[{"name":"DRAM","slug":"DRAM","permalink":"http://malizhen.github.io/tags/DRAM/"}],"keywords":[{"name":"存储","slug":"存储","permalink":"http://malizhen.github.io/categories/存储/"}]},{"title":"VSCode:Remote-SSH配置","slug":"VSCodeRemote-SSH配置","date":"2019-06-10T01:54:25.000Z","updated":"2019-06-10T13:05:58.565Z","comments":true,"path":"2019/06/10/VSCodeRemote-SSH配置/","link":"","permalink":"http://malizhen.github.io/2019/06/10/VSCodeRemote-SSH配置/","excerpt":"","text":"最近VScode发布了远程编程与调试的插件Remote Development，使用这个插件可以在很多情况下代替vim直接远程修改与调试服务器上的代码，就和在本地使用VScode一样。终于不用在服务器端翻来覆去的配置vim插件了，同时服务器端的比如tmux配置可以原封不动地在本地VScode使用。本文介绍配置的过程以及如何在本地通过ssh的方法连接到远程机器上。 配置过程安装VScode原本Remote-SSH这个插件仅支持VSCode的Insider版本（2019.5.8发布），所以你需要下载VSCode的Insider版本 安装过程很简单，直接下一步直到完成，然后在扩展搜索remote ssh点击安装。 安装完成后侧边栏会出现新的图标。 客户端服务器端SSH配置在本地机器（我这里是自己的windows宿主机），后文称为客户端，安装的vmware虚拟机称为服务器端（Linux）。 1、首先在客户端安装ssh 打开计算机设置页面 选择应用-应用和功能-管理可选功能，安装OpenSSH客户端 在客户端左下角搜索输入cmd，命令行输入ssh-keygen -t rsa，输入你想要放置SSH密钥对的目录，这里一般不更改，一直enter直到结束即可，最后在`c:\\user目录下生成密钥文件id-rsa和id-rsa.pub，第一个是私钥文件，第二个是公钥文件。 2、接下来将客户端的公钥内容添加到服务器端，步骤如下： 首先检测ssh服务是否启动 ： netstat -ntlp | grep ssh 如果ssh服务没有启动 ：/etc/init.d/ssh resart 方法一： 手动创建.ssh文件夹如下所示，我这里已经建好了，只是截图展示一下文件位置，并在.ssh文件夹下创建文件authorized_keys，将客户端公钥复制进去。这里注意文件权限可能需要修改。 1) .ssh目录的权限必须是700 2) .ssh/authorized_keys文件权限必须是600 下图第一列就是文件权限。 修改配置文件：vim /etc/ssh/sshd_config，把PubkeyAuthentication配置为 yes ，允许使用基于密钥认证的方式登录。 方法二： 也可以通过ssh-copy-id的方式，需要在客户端安装bash，cmd无法识别linux命令。可以将公钥复制到远程机器。 1$ ssh-copy-id -i .ssh/id_rsa.pub 用户名@192.168.x.xxx 远程连接如图选择文件目录，这是让你选择你的config文件放在哪里，必须放在客户端密钥文件夹下 配置文件内容很简单，就两行 123$ Host alias $ HostName 1.1.1.1 #服务器的ip，服务器终端输入ifconfig命令查看inet地址 $ User username #远程服务器的用户名，其实就是你的虚拟机终端前面显示的用户名 配置完成，选择在当前窗口开启连接 连接成功，左下角会如下图所示 接下来可以导入服务器端的项目，选择编辑栏File-Open Workspace，成功导入项目 VSCode更新一个功能如果只能针对特定版本可用，那就谈不上任何方便了。因此不到一个月VSCode版本发布了更新，目前的VSCode 1.35支持Remote SSH配置，需要可官网下载下载链接，若已下载老版本，点击菜单栏Help-Check for Updates进行更新，重启即可生效，然后同样的安装Remote - SSH，密钥已经配置好了，只需再选择Config文件，就能够远程连接上服务器，配置完成之后，每次开启服务器之后，在客户端开启VSCode就会自动连接上服务器，很方便。","categories":[{"name":"搭建与配置","slug":"搭建与配置","permalink":"http://malizhen.github.io/categories/搭建与配置/"}],"tags":[{"name":"VSCode","slug":"VSCode","permalink":"http://malizhen.github.io/tags/VSCode/"}],"keywords":[{"name":"搭建与配置","slug":"搭建与配置","permalink":"http://malizhen.github.io/categories/搭建与配置/"}]},{"title":"Base-Delta-Immediate Compression","slug":"Base-Delta-Immediate Compression","date":"2019-06-06T01:56:23.000Z","updated":"2019-06-13T13:50:47.451Z","comments":true,"path":"2019/06/06/Base-Delta-Immediate Compression/","link":"","permalink":"http://malizhen.github.io/2019/06/06/Base-Delta-Immediate Compression/","excerpt":"","text":"Base-Delta-Immediate Compression:Practical Data Compression for On-Chip Caches。原文链接很多基于软件的缓存压缩算法主要有两大缺点：造成很高的硬件复杂度；无法接受的解压延迟。本文提出了一种新的压缩算法Base-Delta-Immediate (B∆I) ，关键思想是：大多数cache line有一个特点，同一cache line中存储的数据差异很小。基于这一观察，cache line的数据可以用一个基值（Base）+ 一组差异值（Delta）来表示，所需存储空间必然会比原始cache line大小小得多。 背景为了缓解CPU和主存之间速度不匹配的问题，在主存与CPU之间插入一级或多级cache。然而cache并不是越大越好，虽然更大的cache通常会带来更少的cache miss，但是这种好处是以更长的访问延迟、更大的cache面积（昂贵）和更大的功耗为代价的。 基于这些限制，为了提高cache的利用率，可能会想到通过数据压缩来减少数据量，然而数据压缩并没有被现代商用微处理器作为一种提高有效缓存容量的方法，为什么？理想的缓存压缩技术应该是快速（压缩/解压延迟低）、简单（硬件复杂度低）、高效（高压缩率）的，而如果在商用微处理器中采用缓存压缩，会面临的最大障碍可能是解压延迟，解压与压缩不同，压缩是在缓存写入时(在提供关键字之后)在后台进行的，而解压缩位于cache hit的关键路径上，在此路径上最小化延迟对于性能非常重要。 因此，快速、简单、高效的缓存压缩方案，不可兼得，怎么办？只能权衡得到最佳方案，要么压缩率低、要么硬件复杂度高、要么解压延迟高，总会有缺陷，方案是否可行就看好处是否大于坏处，为了在降低硬件复杂度和解压缩延迟的同时达到显著的压缩比，本文提出了一种新的缓存压缩技术Base-Delta-Immediate(B∆I)压缩。 BASE + DELTA ENCODING: BASIC IDEA基于两个特点： 数据在内存中分配的规律性（相似的数据值和类型分组在一起）。 缓存/内存数据的动态范围较低（例如，同一cache line的数据差异很小）。 设计了Base+Delta 压缩方案，通过存储一个Base和一组Delta来减少冗余从而提高Cache line的利用率。接下来通过两个直观的例子来更好地理解。 应用程序h264ref的32-byte cache line利用Base+Delta 方案压缩如上图所示，该cache line包含一组（8个）以4字节整数形式存储的窄值。 1窄值是使用大数据类型存储的小值。例如，一个one-byte的值存储为一个four-byte整型数。程序员通常在各种数据结构中以最坏的情况为标准提供数据类型，即使大多数数值可能适合较小的数据类型。 从Figure 3我们看到，cache line通过一个全0的base+一组八个1-byte的差异值即可表示所有存储的数值，只要4+8*1共12 byte就能表示整个cache line，这样消除冗余之后相比原来节省了20 byte的空间。看到这里就很容易联想到一个问题，如果说base的byte数太大，差异值节省出来的空间不够多，那么压缩还不如不压缩对不对？这个问题作者在下文考虑到了，base数目、base字节数、差异值的字节数多少才最合适？选择哪个value做base效果会一样吗？不一样的话那如何确定呢？都是我们需要考虑权衡的点。 由Figure 4，在perlbench应用程序负载上，同样是一个32-byte的cache line，存储的是pointer，可以看到，同一cache line的pointer值依然具有很高的相似度。 注意：虽然这里例子使用的是32-byte的cache line，最后实验评估部分有考虑更常见的64-byte cache line。 Compression Algorithm关于该算法的具体描述，论文里面给出了公式（貌似有误，反了），也很容易理解，就是通过简单的向量减法得到Delta。 1∆i = Vi - B* ，其中V表示原始值的集合，∆表示差异值的集合，B*表示base值，若cache line的大小为C byte，其中每个value的大小为k byte，那么i的取值为1~C/k 这里有两个观察： 若存在任意一个Vi和所选base相似度为0，即Delta(i)的大小等于k，那么该缓存行不能压缩。因为本来引入base就加重了开销，压缩效果不好不如不压缩。 如何确定哪个value被选为base？要么Vi的最小值或最大值，要么中间值，被认为是最佳的。理论上是这样的，实际上的做法呢？ 我们除了确定base，还需要确定k，即每个value的大小，决定了一个cache line能容纳多少个value。 Determining kk在2、4、8之间选择最佳压缩率的k值。选择2、4、8是因为几乎所有由各种编程语言支持的基本数据类型都有这三种大小之一。 Determining B*B*可以依据上述观察2来选取，然而，用这种方式寻找base需要计算原始集合的最大value与最小value，这会大大增加硬件的逻辑复杂度，并且会明显增加压缩延迟。所以为了简单起见，选择第一个value作为base即可，并且实验表明，压缩率相比选择理论最优base降低仅仅0.4%，很微不足道了，并且还不会增加硬件复杂度以及压缩延迟。 Decompression Algorithm通过B*和∆的值能够计算得到V，实现解压： 1Vi = ∆i + B* 因此，cache line中的值可以使用SIMD-style的向量加法器并行计算得到。即使用一组简单的加法器，可以在执行整数向量加法所需的时间内解压缩整个cache line。 B∆I COMPRESSION前一部分介绍了Base + Delta，以此为基础怎样能够更完善我们的压缩算法呢？ 因为尽管B+∆被证明适用于大多数的应用程序，但是不可能所有的cache line都能用这种形式来表示，有一些基准测试压缩率就不见得好，比如mcf。这是因为有些应用程序在同一cache line中间可能混合有不同类型的数据，比如指针和1-byte的整数。这种情况下，很显然，如果我们选取多个base，一种类型一个base的话是不是压缩效果会好很多呢？ 如Figure 5所示，我们发现对于在同一cache line可能存储着不同类型的数据的应用程序，多个base压缩效果会更好，但是这会造成更大的base存储开销，所以，存在一个tradeoff，因为显然不是多个base一定会更好，那么选取多少个base才是最优的呢？ 光说都是没有依据的，通过实验来说话，作者设计了一个实验，评估了选择不同数量base(使用贪婪算法依次选择次优base)的有效压缩比，Figure 6展示了实验结果。 结果表明，就有效压缩比而言，经验上最优的base个数是2，虽然少数benchmark在1或3个base上也有最优，最后的结论还是B+∆在两个base的情况下，性能明显优于B+∆在base为1时(压缩比平均为1.51:1.40)，说明值得考虑实现。结果还表明有两个以上的base并不会为这些工作负载提供额外的压缩比改进，因为存储更多的base的开销要高于压缩更多cache line的好处。 注意：Figure 6中我们发现有0个base，这很必要，因为如果不考虑0个base，对于比如说最简单的全0数据，如果使用简单的压缩去冗余，不需要base，直接压缩到1byte，而base越多，显然，压缩率越低，并且增大存储开销。 那么，如何高效地找到两个base？不增加硬件的复杂度，或者说如何以最小的硬件复杂度寻找两个base来获得最大的压缩好处？下一节介绍 B∆I: Refining B+∆ with Two Bases and Minimal Complexity我们发现，第二个base直接设置为0能够和任意选取任何一个vaule作为第二个base一样，为什么会这样？因为大多数情况下，是动态范围较小的宽值（比如指针）与窄值（比如小整数）混合，那么第一个base可以使用base+delta编码压缩动态范围较低的宽值，而第二个0 base则可以有效地压缩窄值。基于这一观察，我们额外增加一个隐式（implicit）的0 base来改进B+∆，称为Base-Delta-Immediate或B∆I压缩。 那么两个base的B+∆好还是B∆I好呢？又存在tradeoff。显然，B∆I有一个base是隐式的0，存储开销更小，这意味着对于用这两种技术都可压缩的cache line，B∆I的平均压缩率可能更高。有两个base的B+∆需要更多的存储空间来存储第二个base，但是可以压缩更多的cache line，因为base可以是任何value，从中选择最佳。到底哪个好呢？可能取决于cache line的模式，甲之砒霜，乙之蜜糖。关键时刻依然还是得实验来说话 Figure 7表明，虽然有个别负载B+∆的表现比B∆I好，但是总体来说还是B∆I的压缩比（1.53）高于B+∆（1.51），虽然不是高太多，但是考虑到B+∆有两个base，那就有比B∆I更复杂的硬件机制，所以认为缓存压缩设计还是应该基于B∆I的思想。 DesignCompress在具体的设计中，所有的可能压缩大小是静态已知的，如Table 2。如果cache line有多个压缩选项可用(例如，8-byte base 1-byte ∆或者Zeros压缩)，则Compression Selection 选择压缩cache line大小最小的一个（即选择压缩率最高的）。基于Table 2选择合适的压缩大小，Figure 8中所有压缩单元可并发执行。 Figure 9展示了32-byte的cache line在8-byte-base 1-byte-∆时压缩单元的情况，每个V通过减法器进行运算之后，判断是否每个V的运算结果∆前七位均为0或者1，如果是的话，cache line能够以该种模式（8-byte-base 1-byte-∆）存储，否则，说明至少有一个∆不能用1-byte表示，那么不压缩该cache line。 Decompress解压的硬件设计很简单，如上文描述一样，就是一个减法器。如下图所示 关于实现的更多细节，以及实验部分，如果感兴趣的话可以阅读原文，本文的分析重在了解基本思想。","categories":[{"name":"论文阅读记录","slug":"论文阅读记录","permalink":"http://malizhen.github.io/categories/论文阅读记录/"}],"tags":[{"name":"compression algorithm","slug":"compression-algorithm","permalink":"http://malizhen.github.io/tags/compression-algorithm/"}],"keywords":[{"name":"论文阅读记录","slug":"论文阅读记录","permalink":"http://malizhen.github.io/categories/论文阅读记录/"}]},{"title":"重庆四人游","slug":"重庆四人游","date":"2019-06-06T01:44:35.540Z","updated":"2019-06-10T13:22:21.820Z","comments":true,"path":"2019/06/06/重庆四人游/","link":"","permalink":"http://malizhen.github.io/2019/06/06/重庆四人游/","excerpt":"","text":"2018年5月1日的前一天，我的小Z突然问我想不想五一去重庆，距离我俩上次旅行已经过去快三年，贫穷的大学时期，只是在2015年八月底去了一趟凤凰，好在自从小Z毕业工作以来，似乎异地恋也不再受限于没钱见面，哈哈哈，虽然自从我读研以来科研才是他的情敌。于是有了这次说走就走的旅行。 前期准备出行方式的选择我们总共四个人，小姜和他女朋友都在湖南，小Z也是，我在武汉，所以最后我们决定长沙会合，然后坐飞机去重庆。买的五一当晚11点长沙到重庆的特价机票，票价不贵，500元左右，不同买票软件不一样，我发现的最实惠的是智行，比携程飞猪等少大概80。这里真的要吐槽一下西部航空，返程买的奥凯航空，对比起来简直一个天上一个地下，西部航空没有免费行李托运额度，奥凯航空有，而且有充饥曲奇饼和水，hhh，曲奇饼超好吃，可惜产地俄罗斯，淘宝没找到有卖的。 还有，第一次坐飞机我发现自己不仅晕车居然还晕机，所以晕车的小伙伴坐飞机的话一定记得吃药。话说不管哪个航空公司空姐都人美心善，因为晕机不舒服，下飞机的时候满脸不开心，得到了空乘小姐姐的大大的笑容问候。 关于住宿全程不到两个小时，所以看来比起火车虽然贵点，但是性价比真是不知道高多少。5月1日抵达重庆的时候已经是次日凌晨，所以当晚的住宿定在江北国际机场附近，首选有接机服务的酒店，1日晚的酒店很一般，而且由于五一价钱还不便宜，接近三百，就不说店名了。因为商圈附近住宿都很贵，两个男孩子不想住民宿，最后2日晚选择住宿在南坪，南坪轻轨站附近的金凯斯精品酒店，接近三百一晚，酒店有些陈旧，但是房间面积很大，虽然这并没什么用，卫生间很小，期间马桶还坏了，不过胜在位置很好，从机场坐轻轨到南坪，轻轨站一出来就能看到这家酒店。五一这个价钱只能说无功无过吧。 之后的两个晚上住在我们东道主煦煦家哈哈哈，这就有了接下来几天连续爆肝用生命没日没夜地浪的契机hhhh。 咳咳咳正文来了去重庆之前做的攻略，在有了李导（煦煦）加持之后都是浮云了，吃了超级正宗的重庆火锅，啊哈好像叫大队长火锅，晚上在路边摊吃的烧烤，虽然菜都从牵牵上弄下来变成了大锅菜的样子，卖相不太好，但是味道真的很棒。 去了各大网红景点，包括洪崖洞、解放碑、磁器口还有南山一棵树风景区。一个一个说吧，洪崖洞解放碑在一起，就晚上去夜景真的很棒，虽然洪崖洞不知道在地下多少层，当时人山人海，没有电梯，排队进入口，然后一层一层的楼梯走到腿快废了。 解放碑就是那种来了就必去拍张照的地方，hhh，我当时竟然有一种武汉大学校门口的错觉，永远好多人对着那个国立武汉大学咔擦咔擦。 磁器口吧，有点不是很推荐，在一个在武汉待了五年的人看来，它就是另一个户部巷，一条小吃街也卖一些小玩意，东西很难吃而且很贵，不过有个酒庄老板超好，免费尝了好多酒，要不是坐飞机不能带，当时超想买一小罐女儿红。以上地方总结起来就是五一真的超级多人，多到无法想象的那种，寸步难行。 4号晚去的南山一棵树，因为假期最后一天，人不多，打车过去的，晚上俯瞰重庆夜景很美，基本照片都在这拍的hhh，原本计划去川美涂鸦一条街拍照的，最后时间不够了。 5号租车去了奥陶纪，我们总共五个人，租车比跟团划算而且更方便，这里还是很推荐的，感觉像张家界和大型欢乐谷的结合体，有玻璃桥有很多高空项目，室内冰雪世界很美，虽然这个地方被抖音带火的，这两年才出名，还是去得很值。 最后记了一堆流水账，最后想要矫情一下，旅途中的情侣难免会有些小矛盾，不过和小Z在一起的六年以来，很感谢他每次包容我的小性子，有时候觉得，遇到一个三观相合而且三观超正的小奶狗，只想每天多爱对方一点点，也许这就是那啥操蛋的异地恋维持的新鲜感吧，hhhh！","categories":[{"name":"随笔","slug":"随笔","permalink":"http://malizhen.github.io/categories/随笔/"}],"tags":[{"name":"旅游","slug":"旅游","permalink":"http://malizhen.github.io/tags/旅游/"}],"keywords":[{"name":"随笔","slug":"随笔","permalink":"http://malizhen.github.io/categories/随笔/"}]}]}