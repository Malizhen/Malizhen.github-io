<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>乌龙波霸七分甜</title>
  
  <subtitle>每一个不曾起舞的日子，都是对生命的辜负</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://malizhen.github.io/"/>
  <updated>2019-07-18T07:38:54.689Z</updated>
  <id>http://malizhen.github.io/</id>
  
  <author>
    <name>malizhen</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>阶段总结</title>
    <link href="http://malizhen.github.io/2019/07/18/%E9%98%B6%E6%AE%B5%E6%80%BB%E7%BB%93/"/>
    <id>http://malizhen.github.io/2019/07/18/阶段总结/</id>
    <published>2019-07-18T07:38:54.000Z</published>
    <updated>2019-07-18T07:38:54.689Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>SubArray.cpp分析</title>
    <link href="http://malizhen.github.io/2019/07/11/SubArray-Write/"/>
    <id>http://malizhen.github.io/2019/07/11/SubArray-Write/</id>
    <published>2019-07-11T07:07:55.000Z</published>
    <updated>2019-07-22T02:39:17.633Z</updated>
    
    <content type="html"><![CDATA[<p>在nvmain的源代码中，可以看到EnergyModel有两种，energy和current。</p><p>这可以在config文件中进行配置，比如说PCM_ISSCC_2012_4GB.config中这样配置：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EnergyModel energy</span><br></pre></td></tr></table></figure><p>同样的，在STTRAM以及RRAM等NVM存储器中也都是energy，如上配置，而在DRAM等易失性存储器中这样配置：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EnergyModel current</span><br></pre></td></tr></table></figure><p>源码中针对NVM存储器的EnergyModel，采用如下这样一种很简单的累加方式来计算能耗，其中Erd是单个mat的读能耗，在PCM_ISSCC_2012_4GB.config中设定值为0.081200，同时设定Ewr即写能耗（SET或者RESET）为1.684811：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">else</span></span><br><span class="line">&#123;</span><br><span class="line">   subArrayEnergy += p-&gt;Erd;</span><br><span class="line">   activeEnergy += p-&gt;Erd; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>下面介绍一下nvmain源代码中涉及到的一些常用参数的意义以及在PCM_ISSCC_2012_4GB.config中设定的值。</p><h2 id="PCM-ISSCC-2012-4GB配置文件参数解析"><a href="#PCM-ISSCC-2012-4GB配置文件参数解析" class="headerlink" title="PCM_ISSCC_2012_4GB配置文件参数解析"></a>PCM_ISSCC_2012_4GB配置文件参数解析</h2><p>首先了解几个概念，<strong>北桥</strong>称为系统总线，是内存传输的主要信道，因此速度比较快；<strong>南桥</strong>称为IO总线，主要联系硬盘、USB、网卡等设备。北桥支持的频率称为<strong>前端总线速度</strong>（每秒传输次数），而每次传送的bit数则是<strong>总线宽度</strong>，我们熟悉的<strong>总线带宽</strong>（总线速度x总线宽度）即为每秒可传送的最大数据量。</p><ol><li><p>tBURST 4：数据burst的时间为4个周期</p></li><li><p>RATE 2：数据传输速率，每个周期两次传输</p></li><li><p>BusWidth 64：每次传输bit数，总线宽度(以bit为单位)</p></li></ol><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">wordSize = p-&gt;BusWidth; </span><br><span class="line">wordSize *= p-&gt;tBURST * p-&gt;RATE;</span><br><span class="line">wordSize /= <span class="number">8</span>;</span><br><span class="line"><span class="comment">/* wordSize以Byte为单位，表示每次burst传输的数据量 */</span></span><br></pre></td></tr></table></figure><p>使用数据burst来提高数据吞吐量，burst长度=tBURST*RATE=8。</p><ol><li><p>tRCD 48：在进行数据的读写前，Controller 需要先发送 Row Active Command，Row Active Command 通过地址总线指明需要打开DRAM Memory SubArray 中某一个 Bank 的某一个 Row。DRAM在接收到该 Command 后，会打开该 Row 的 Wordline，将其存储的数据读取到 Sense Amplifier（感知放大器）中，这一时间定义为 tRCD（RCD for Row Address to Column Address Delay）。</p></li><li><p>tRAS 0：在DRAM中需要进行Restore的操作，PCM中tRAS 0表示不需要Restore操作。DRAM中，Restore操作可以和数据的读取同时进行，即在这个阶段，Controller 可能发送了 Read Command 进行数据读取。DRAM 接收到 Row Active Command 到完成 Row Restore 操作所需要的时间定义为 tRAS（RAS for Row Address Strobe）。</p></li><li><p>tCAS 1：Controller 在发送 Row Active Command后的tRCD时间之后，bank处于激活状态，Sense Amplifier中有完整的page内容，接着发送Read Commond进行数据读取。Column Read Command 通过地址总线指明需要读取的 Column 的起始地址。从某个激活的page(放在Sense Amplifier中)中读取一个byte数据，加载到预取缓冲区，这一时间定义为tCAS（CAS for Column Address Strobe），也称为tCL。</p></li><li><p>tBURST 4：tCAS时间之后，紧接着就是数据burst阶段，数据从预取缓冲区逐个发往IO总线，经过四个时钟周期发送完毕。这一时间定义为tBURST，表示数据burst周期。对同一bank的后续读取必须至少间隔tBURST，因为至少需要tBURST才能将预取缓冲区中的burst数据传输到IO总线。</p></li><li><p>tCWD 4: 10ns，CWD for Column Write Delay。Controller 在发送 Row Active Command后的tRCD时间之后，接着发送Write Commond进行数据写入。Column Write Command 通过地址总线指明需要写入数据的 Column 的起始地址。Controller 在发送完 Write Command 后，需要等待 tCWD （CWD for Column Write Delay） 时间后，才可以发送待写入的数据。所以从发送完Write Commond到发送待写入数据这段时间定义为tCWD， 在一些描述中也称为 tCWL（CWL for Column Write Latency）。</p></li><li><p>tWR 0：DRAM接收完数据后，需要一定的时间将数据写入到 DRAM Cells 中，这个时间定义为 tWR（WR for Write Recovery）。也称为write-to-precharge, PCM中不需要。</p></li><li><p>tRP 1：在DRAM中，Refresh命令之前，每个bank必须要先Precharged，然后处于idle状态，从发出Precharge命令到激活同一bank中不同行之间所需的最小时钟周期数，称为一个tRP时延。</p></li><li><p>tRFC 100：Refresh时间，不在PCM中使用，但同样在配置文件中为其分配有效的数字。在一个Refresh命令完成后，所有的bank处于precharge (idle)状态，在Refresh命令和下一个activate命令(ACT)之间cycles数目必须大于等于tRFC(the Row Refresh Cycle Time )。</p></li><li><p>CLK 400：CPU运行频率为400MHz，那么周期为1/400 us=2.5ns。</p></li><li><p>tCWD 4: 10ns</p></li><li><p>tCCD 2：一般为2或4，不超过tBURST。是列操作之间的最小时间间隔</p></li></ol><h2 id="Write-NVMainRequest-request"><a href="#Write-NVMainRequest-request" class="headerlink" title="Write(NVMainRequest *request )"></a>Write(NVMainRequest *request )</h2><p>首先搞清楚一些基本知识。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">enum</span> SubArrayState </span><br><span class="line">&#123; </span><br><span class="line">    SUBARRAY_UNKNOWN,     <span class="comment">/* Unknown state. Uh oh. */</span></span><br><span class="line">    SUBARRAY_OPEN,        <span class="comment">/* SubArray has an open row */</span></span><br><span class="line">    SUBARRAY_CLOSED,      <span class="comment">/* SubArray is idle. */</span></span><br><span class="line">    SUBARRAY_PRECHARGING, <span class="comment">/* SubArray is precharging and return to SUBARRAY_CLOSED */</span></span><br><span class="line">    SUBARRAY_REFRESHING   <span class="comment">/* SubArray is refreshing and return to SUBARRAY_CLOSED */</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>SubArrayState有UNKNOWN、OPEN、CLOSED、PRECHARGING、REFRESHING五种状态：</p><ol><li><p>Precharge：对于处于打开状态（这儿打开是指把page内容放入到Sense Amplifier）的page，我们可以进行读写操作，如果不需要再对该page进行读写操作，可以关闭该page, 把该page内容写入bank的行列单元对应的page中，然后DRAM core才能够准备下一个数据访问，以便对其它page进行读写操作。这个关闭操作通过发射一个Precharge命令实现，precharge命令可以关闭某一个bank，也可以关闭rank中所有打开的bank。</p></li><li><p>Refreshing：DRAM（Dynamic Random Access Memory，即动态随机存取存储器）之所以称为DRAM，就是因为它要不断进行刷新（Refresh）才能保留住数据，因此它是DRAM最重要的操作。Refresh操作与Precharge中重写的操作一样，都是用S-AMP先读再写。但为什么有Precharge操作还要进行Refresh呢？因为Precharge是对一个或所有Bank中的工作行操作，并且是不定期的，而刷新则是有固定的周期，依次对所有行进行操作，以保留那些久久没经历重写的存储体中的数据。</p></li></ol><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">enum</span> WriteMode </span><br><span class="line">&#123;</span><br><span class="line">    WRITE_BACK, <span class="comment">/* only modify the row buffer */</span></span><br><span class="line">    WRITE_THROUGH, <span class="comment">/* modify both row buffer and cell */</span></span><br><span class="line">    DELAYED_WRITE <span class="comment">/* data is stored in a write buffer */</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>WriteMode有三种，WRITE_BACK、WRITE_THROUGH以及DELAYED_WRITE：</p><ol><li><p>WRITE_BACK：只更新行缓冲区；</p></li><li><p>WRITE_THROUGH：更新行缓冲区和cell；</p></li><li><p>DELAYED_WRITE：数据被存储在写缓冲区；</p></li></ol><h3 id="Write函数分析"><a href="#Write函数分析" class="headerlink" title="Write函数分析"></a>Write函数分析</h3><p>这个函数很重要，大致写一下自己的理解。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> NVMAddress::GetTranslatedAddress( <span class="keyword">uint64_t</span> *addrRow, <span class="keyword">uint64_t</span> *addrCol, <span class="keyword">uint64_t</span> *addrBank, <span class="keyword">uint64_t</span> *addrRank, <span class="keyword">uint64_t</span> *addrChannel, <span class="keyword">uint64_t</span> *addrSA )</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">if</span>( addrRow ) *addrRow = row;</span><br><span class="line">    <span class="keyword">if</span>( addrCol ) *addrCol = col;</span><br><span class="line">    <span class="keyword">if</span>( addrBank ) *addrBank = bank;</span><br><span class="line">    <span class="keyword">if</span>( addrRank ) *addrRank = rank;</span><br><span class="line">    <span class="keyword">if</span>( addrChannel ) *addrChannel = channel;</span><br><span class="line">    <span class="keyword">if</span>( addrSA ) *addrSA = subarray;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>首先进行sanity完整性检查，这一部分的完整性检查必不可少，不能完全信任IsIssuable()而缺少完整性检查。</p><p>若nextWrite大于事件队列的当前时钟周期，则Subarray违反写时序限制；若SubArrayState不等于SUBARRAY_OPEN，则试图对非active状态的subarray进行写入而报错；若writeRow不等于openRow，则试图对没有open的行进行写入而报错。</p><p>若writeMode为WRITE_THROUGH，则需要更新行缓冲区和cell。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"> <span class="keyword">if</span>( writeMode == WRITE_THROUGH )</span><br><span class="line">    &#123;</span><br><span class="line">        encLat = (dataEncoder ? dataEncoder-&gt;Write( request ) : <span class="number">0</span>);</span><br><span class="line">        endrLat = UpdateEndurance( request );</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* Count the number of bits modified. */</span></span><br><span class="line">        <span class="keyword">if</span>( !p-&gt;WriteAllBits )</span><br><span class="line">        &#123;</span><br><span class="line">        <span class="comment">//声明一个一维数组bitCountData，大小和数据大小（byte）一致</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">uint8_t</span> *bitCountData = <span class="keyword">new</span> <span class="keyword">uint8_t</span>[request-&gt;data.GetSize()];</span><br><span class="line"><span class="comment">//对数组bitCountData赋值，新旧数据逐byte进行异或操作，结果存储在数组bitCountData中</span></span><br><span class="line">            <span class="keyword">for</span>( <span class="keyword">uint64_t</span> bitCountByte = <span class="number">0</span>; bitCountByte &lt; request-&gt;data.GetSize(); bitCountByte++ )</span><br><span class="line">            &#123;</span><br><span class="line">                bitCountData[bitCountByte] = request-&gt;data.GetByte( bitCountByte ) ^ request-&gt;oldData.GetByte( bitCountByte );</span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line"><span class="comment">//这里应该是和后面设计的Count32MLC1函数有关，该函数的操作对象是uint32_t的数据，所以定义bitCountWords为原数据byte数除以4。不过更有可能是因为很多论文比如FPC中指定一个word为4 byte，所以接下来的计算都是以word为操作单位</span></span><br><span class="line">            <span class="keyword">ncounter_t</span> bitCountWords = request-&gt;data.GetSize()/<span class="number">4</span>;</span><br><span class="line"><span class="comment">//以32bit为单位计算bitCountData中1的个数，即为bit更新的数目，因为异或操作值不同则为1</span></span><br><span class="line">            <span class="keyword">ncounter_t</span> numChangedBits = CountBitsMLC1( <span class="number">1</span>, (<span class="keyword">uint32_t</span>*)bitCountData, bitCountWords );</span><br><span class="line"><span class="comment">//若括号内条件为假，即原数据bit数小于计算所得的更新bit数，则打印错误信息，通过调用abort来终止程序运行</span></span><br><span class="line">            assert( request-&gt;data.GetSize()*<span class="number">8</span> &gt;= numChangedBits );</span><br><span class="line">            <span class="comment">//未更新bit数目=总bit数-更新bit数目</span></span><br><span class="line"></span><br><span class="line">            numUnchangedBits = request-&gt;data.GetSize()*<span class="number">8</span> - numChangedBits;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ncounter_t</span> NO_OPT SubArray::Count32MLC1( <span class="keyword">uint32_t</span> data )</span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment">//使用神奇操作来计算这个data中1的个数。这个操作够神奇的看不懂，不过以后如果要计算一串32bit二进制数据中1的个数可以照搬</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">uint32_t</span> count = data;</span><br><span class="line">    count = count - ((count &gt;&gt; <span class="number">1</span>) &amp; <span class="number">0x55555555</span>);</span><br><span class="line">    count = (count &amp; <span class="number">0x33333333</span>) + ((count &gt;&gt; <span class="number">2</span>) &amp; <span class="number">0x33333333</span>);</span><br><span class="line">    count = (((count + (count &gt;&gt; <span class="number">4</span>)) &amp; <span class="number">0x0f0f0f0f</span>) * <span class="number">0x01010101</span>) &gt;&gt; <span class="number">24</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">static_cast</span>&lt;<span class="keyword">ncounter_t</span>&gt;(count);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ncounter_t</span> NO_OPT SubArray::CountBitsMLC1( <span class="keyword">uint8_t</span> value, <span class="keyword">uint32_t</span> *data, <span class="keyword">ncounter_t</span> words )</span><br><span class="line"> &#123;</span><br><span class="line"> <span class="keyword">ncounter_t</span> count = <span class="number">0</span>;</span><br><span class="line"> <span class="comment">//计算每个word中间新旧数据不同bit数目，并累加得到整个data中间需要更新的bit数</span></span><br><span class="line"> <span class="keyword">for</span>( <span class="keyword">ncounter_t</span> i = <span class="number">0</span>; i &lt; words; i++ )</span><br><span class="line"> &#123;</span><br><span class="line"> count += Count32MLC1( data[i] );</span><br><span class="line"> &#125;</span><br><span class="line"> <span class="comment">//如果value=1，count=count，否则count=words*32-count</span></span><br><span class="line"> count = (value == <span class="number">1</span>) ? count : (words*<span class="number">32</span> - count);</span><br><span class="line"> <span class="keyword">return</span> count;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><h2 id="EnergyModel能耗优化计算方案"><a href="#EnergyModel能耗优化计算方案" class="headerlink" title="EnergyModel能耗优化计算方案"></a>EnergyModel能耗优化计算方案</h2><p>基于NVM的主存储器设计一种延迟和能量优化写方案。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* Calculate energy. */</span></span><br><span class="line"> <span class="keyword">if</span>( p-&gt;EnergyModel == <span class="string">"current"</span> )</span><br><span class="line"> &#123;</span><br><span class="line"> <span class="comment">/* DRAM Model. */</span></span><br><span class="line"> subArrayEnergy += ( ( p-&gt;EIDD4W - p-&gt;EIDD3N ) </span><br><span class="line"> * (<span class="keyword">double</span>)(p-&gt;tBURST) ) / (<span class="keyword">double</span>)(p-&gt;BANKS);</span><br><span class="line"> burstEnergy += ( ( p-&gt;EIDD4W - p-&gt;EIDD3N ) * </span><br><span class="line"> (<span class="keyword">double</span>)(p-&gt;tBURST) ) / (<span class="keyword">double</span>)(p-&gt;BANKS);</span><br><span class="line"> &#125;</span><br><span class="line"> <span class="keyword">else</span></span><br><span class="line"> &#123;</span><br><span class="line"> <span class="comment">/* Flat energy model. */</span></span><br><span class="line"> <span class="comment">//subArrayEnergy += p-&gt;Ewr - p-&gt;Ewrpb * numUnchangedBits;</span></span><br><span class="line"> <span class="keyword">uint32_t</span> *rawData;</span><br><span class="line"> <span class="keyword">uint32_t</span> *oldData;</span><br><span class="line"> <span class="keyword">ncounter_t</span> memoryWordSize = <span class="number">64</span> * <span class="number">8</span> ;</span><br><span class="line"> <span class="keyword">ncounter_t</span> size = <span class="number">0</span>;</span><br><span class="line"> <span class="keyword">if</span>(request-&gt;data.IsCompressed())</span><br><span class="line"> &#123;</span><br><span class="line"> rawData = <span class="keyword">reinterpret_cast</span>&lt;<span class="keyword">uint32_t</span>*&gt;(request-&gt;data.comData);</span><br><span class="line"> memoryWordSize = request-&gt;data.GetComSize()*<span class="number">8</span>;</span><br><span class="line"> &#125;</span><br><span class="line"> <span class="keyword">else</span></span><br><span class="line"> &#123;</span><br><span class="line"> rawData = <span class="keyword">reinterpret_cast</span>&lt;<span class="keyword">uint32_t</span>*&gt;(request-&gt;data.rawData);</span><br><span class="line"> &#125;</span><br><span class="line"> <span class="keyword">if</span>(request-&gt;oldData.IsCompressed())</span><br><span class="line"> &#123;</span><br><span class="line"> oldData = <span class="keyword">reinterpret_cast</span>&lt;<span class="keyword">uint32_t</span>*&gt;(request-&gt;oldData.comData);</span><br><span class="line"> &#125;</span><br><span class="line"> <span class="keyword">else</span></span><br><span class="line"> &#123;</span><br><span class="line"> oldData = <span class="keyword">reinterpret_cast</span>&lt;<span class="keyword">uint32_t</span>*&gt;(request-&gt;oldData.rawData);</span><br><span class="line"> &#125;</span><br><span class="line"> size = memoryWordSize / <span class="number">32</span>;</span><br><span class="line"> <span class="keyword">double</span> energy = <span class="number">0</span>;</span><br><span class="line"> <span class="keyword">unsigned</span> <span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line"> <span class="keyword">ncounter_t</span> i_pos = <span class="number">0</span>;</span><br><span class="line"> <span class="keyword">uint32_t</span> word;</span><br><span class="line"> <span class="keyword">uint32_t</span> oldWord;</span><br><span class="line"> <span class="keyword">uint32_t</span> mask = <span class="number">0x00000007</span>;</span><br><span class="line"> <span class="keyword">uint32_t</span> byte;</span><br><span class="line"> <span class="keyword">uint32_t</span> oldByte;</span><br><span class="line"> <span class="keyword">ncounter_t</span> writeCount[<span class="number">8</span>];</span><br><span class="line"> <span class="keyword">ncounter_t</span> EwrTLC[<span class="number">8</span>];</span><br><span class="line"> EwrTLC[<span class="number">0</span>] = p-&gt;Ewr000;</span><br><span class="line"> EwrTLC[<span class="number">1</span>] = p-&gt;Ewr001;</span><br><span class="line"> EwrTLC[<span class="number">2</span>] = p-&gt;Ewr010;</span><br><span class="line"> EwrTLC[<span class="number">3</span>] = p-&gt;Ewr011;</span><br><span class="line"> EwrTLC[<span class="number">4</span>] = p-&gt;Ewr100;</span><br><span class="line"> EwrTLC[<span class="number">5</span>] = p-&gt;Ewr101;</span><br><span class="line"> EwrTLC[<span class="number">6</span>] = p-&gt;Ewr110;</span><br><span class="line"> EwrTLC[<span class="number">7</span>] = p-&gt;Ewr111;</span><br><span class="line"> <span class="keyword">for</span>(i_pos = <span class="number">0</span>; i_pos &lt; <span class="number">8</span>; i_pos++)</span><br><span class="line"> writeCount[i_pos] = <span class="number">0</span>;</span><br><span class="line"> <span class="keyword">for</span>(i = <span class="number">0</span>; i &lt; size; i++)</span><br><span class="line"> &#123;</span><br><span class="line"> word = rawData[i];</span><br><span class="line"> oldWord = oldData[i];</span><br><span class="line"> <span class="keyword">for</span>(i_pos = <span class="number">0</span>; i_pos &lt; <span class="number">11</span>; i_pos++)</span><br><span class="line"> &#123;</span><br><span class="line"> byte = word &amp; mask;</span><br><span class="line"> oldByte = oldWord &amp; mask;</span><br><span class="line"> <span class="keyword">if</span>(byte != oldByte)</span><br><span class="line"> writeCount[byte]++;</span><br><span class="line"> word = word &gt;&gt; <span class="number">3</span>;</span><br><span class="line"> oldWord = oldWord &gt;&gt; <span class="number">3</span>;</span><br><span class="line"> &#125;</span><br><span class="line"> &#125;</span><br><span class="line"> size = memoryWordSize % <span class="number">32</span>;</span><br><span class="line"> <span class="keyword">if</span>(size != <span class="number">0</span>)</span><br><span class="line"> &#123;</span><br><span class="line"> word = rawData[i];</span><br><span class="line"> oldWord = oldData[i];</span><br><span class="line"> <span class="keyword">ncounter_t</span> nums_r = size / <span class="number">3</span>;</span><br><span class="line"> <span class="keyword">if</span>(size % <span class="number">3</span> != <span class="number">0</span>)</span><br><span class="line"> nums_r++;</span><br><span class="line"> <span class="keyword">for</span>(i_pos = <span class="number">0</span>; i_pos &lt; (<span class="number">11</span>-nums_r); i_pos++)</span><br><span class="line"> &#123;</span><br><span class="line"> word = word &gt;&gt; <span class="number">3</span>;</span><br><span class="line"> oldWord = oldWord &gt;&gt; <span class="number">3</span>;</span><br><span class="line"> &#125;</span><br><span class="line"> <span class="keyword">for</span>(; i_pos &lt; <span class="number">11</span>; i_pos++)</span><br><span class="line"> &#123;</span><br><span class="line"> byte = word &amp; mask;</span><br><span class="line"> oldByte = oldWord &amp; mask;</span><br><span class="line"> <span class="keyword">if</span>(byte != oldByte)</span><br><span class="line"> writeCount[byte]++;</span><br><span class="line"> word = word &gt;&gt; <span class="number">3</span>;</span><br><span class="line"> oldWord = oldWord &gt;&gt; <span class="number">3</span>;</span><br><span class="line"> &#125;</span><br><span class="line"> &#125;</span><br><span class="line"> <span class="keyword">for</span>(i_pos = <span class="number">0</span>; i_pos &lt; <span class="number">8</span>; i_pos++)</span><br><span class="line"> &#123;</span><br><span class="line"> energy += writeCount[i_pos] * EwrTLC[i_pos];</span><br><span class="line"> &#125;</span><br><span class="line"> subArrayEnergy += energy;</span><br><span class="line"> burstEnergy += p-&gt;Ewr;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在nvmain的源代码中，可以看到EnergyModel有两种，energy和current。&lt;/p&gt;
&lt;p&gt;这可以在config文件中进行配置，比如说PCM_ISSCC_2012_4GB.config中这样配置：&lt;/p&gt;
&lt;figure class=&quot;highlight 
      
    
    </summary>
    
      <category term="源码分析" scheme="http://malizhen.github.io/categories/%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
    
    
      <category term="nvmain" scheme="http://malizhen.github.io/tags/nvmain/"/>
    
  </entry>
  
  <entry>
    <title>Compression Architecture for Bit-write Reduction</title>
    <link href="http://malizhen.github.io/2019/07/04/FPC-flip_write/"/>
    <id>http://malizhen.github.io/2019/07/04/FPC-flip_write/</id>
    <published>2019-07-04T13:20:22.000Z</published>
    <updated>2019-07-05T08:34:02.767Z</updated>
    
    <content type="html"><![CDATA[<p>Compression Architecture for Bit-write Reduction in Non-volatile Memory Technologies（<a href="http://delivery.acm.org/10.1145/2780000/2770300/p51-dgien.pdf?ip=222.20.77.178&id=2770300&acc=ACTIVE%20SERVICE&key=BF85BBA5741FDC6E%2ECC932049E1B2BA72%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&__acm__=1562247519_a0ff70170b7d28f7d9da26e6ca5db2c3" target="_blank" rel="noopener">原文链接</a>）。本文提出了一个基于压缩的架构，实现位写减少。位写减少有很多的好处，包括降低写延迟、降低动态功耗、提高耐受力。提出一个集成进NVM模块的架构，包括（i）一个频繁模式压缩-解压引擎；（ii）和一个比较器协同工作实现减少位写；（iii）一个投机取巧的磨损均衡方案，通过减少部分cell位反复写，平衡分布写，提高内存的耐受力。</p><h2 id="Compression-based-NVM"><a href="#Compression-based-NVM" class="headerlink" title="Compression-based NVM"></a>Compression-based NVM</h2><p>本文描述的压缩架构的核心思想是内存中word被一个new word重写的时候，利用一个简单的压缩方案来减少位写。目前最先进的针对这部分的研究有<a href="https://ieeexplore.ieee.org/document/4253313" target="_blank" rel="noopener">DCW</a>和<a href="https://dl.acm.org/citation.cfm?id=1669157" target="_blank" rel="noopener">FNW</a>。与DRAM不同，DRAM在每次读写操作期间，所在的整个内存行需要被写回。而在NVM中，刷新没有发生变化的位没有必要。</p><h4 id="Write"><a href="#Write" class="headerlink" title="Write"></a>Write</h4><p>集成了本文架构的NVM模块如何处理写请求？首先，直接集成在NVM模块中的CDE（Compression-Decompression Engine）尝试压缩写入的新数据，CDE实现了基于FPC（见上篇博客）的压缩方法。然后，当CDE尝试压缩数据的同时，NVM模块控制器读取NVM数组中目标地址的数据（旧数据）。一旦压缩完成，旧数据和新数据逐位比较找不同位，否则，直接写入未压缩数据。基于逐位比较结果，只更新写入新旧数据之间对应不同的位（差分写）。最后，系统更新压缩tag位，来表明该地址的数据是否被压缩。</p><h4 id="Read"><a href="#Read" class="headerlink" title="Read"></a>Read</h4><p>在读访问过程中，执行步骤和写数据相反。首先，CDE从NVM数组读取word及其对应的tag位。检查tag位确定读取的word是否被压缩，若被压缩，该word经过CDE，解压结果直接转发到处理器。否则，该word略过CDE组件，直接被转发到处理器。</p><h4 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h4><p>如下图所示，CDE直接集成到NVM模块，实现数据在写操作期间的无缝压缩与解压。添加额外的电路，实现新数据经过CDE，允许未压缩的数据在读操作期间绕过CDE被读取。NVM阵列也相应地修改，以支持tag位标记是否压缩和磨损均衡。NVM阵列中每个32-bit word，添加两个tag位，一个tag用于表示内存中数据是否被压缩，另一个tag用于磨损均衡技术中表示“normal”写还是“flip”写。这里的tag位带来的额外存储开销与FNW方案中一样，FNW中每16-bit要求1个tag。</p><p><img src="https://github.com/Malizhen/Malizhen.github.io/blob/master/images/FPC-flip_write/2.png?raw=true" alt="images"></p><h3 id="Frequent-Pattern-Compression-FPC"><a href="#Frequent-Pattern-Compression-FPC" class="headerlink" title="Frequent Pattern Compression(FPC)"></a>Frequent Pattern Compression(FPC)</h3><p>写访问期间，CDE压缩写入的新数据时，利用基于FPC的压缩方法，首先检查word的内容，确定是否匹配FPC模式表中的某种模式，如果匹配，CDE添加相应前缀压缩编码该word。读访问期间，这个3-bit的前缀用来确定匹配的模式，CDE可以根据模式表反向解码该word。</p><p><img src="https://github.com/Malizhen/Malizhen.github.io/blob/master/images/FPC-flip_write/1.png?raw=true" alt="images"></p><p>如下图写入新数据，对应上图模式表中001的4-bit符号扩展模式，因此新数据压缩编码为前缀+数据，即0011001，若从左往右逐位与旧数据进行比对，翻转写不同位，如图所示标红有两bit翻转写。到这里很容易考虑到一个问题，如果每次写入新数据的时候都这样操作，那么位翻转全部集中在word的左侧bit，会造成写入不均衡的问题，怎么解决？很简单，适当地从右往左写，但是这样的话，同样会有问题，对于利用FPC压缩效果不佳（大部分word压缩率不足50%）的应用，比如32-bit压缩至加上前缀共19bit，那么中间有6-bit重叠，无论从左还是从右写都一样，中间6bit都会受到磨损，这会造成word中间部分bit的重复写，最终导致word中间部分bit最先磨损。同样，若压缩效果太好的话，中间bit位无论从哪边开始写都不被磨损，会造成word的中间部分bit翻转写次数极少。</p><p><strong>这个问题带来的影响本文没有很好地解决！！！</strong></p><p><img src="https://github.com/Malizhen/Malizhen.github.io/blob/master/images/FPC-flip_write/3.png?raw=true" alt="images"></p><h3 id="Wear-Leveling"><a href="#Wear-Leveling" class="headerlink" title="Wear Leveling"></a>Wear Leveling</h3><p>针对以上磨损均衡方案，CDE和NVM阵列需要做必要的修改。</p><h4 id="Write-1"><a href="#Write-1" class="headerlink" title="Write"></a>Write</h4><p>每个word添加第二个“position” tag位，表示当前将数据存储到NVM阵列的哪一侧。与此同时，NVM模块添加电路，来决定压缩数据应该正常写还是翻转写，tag为0表示正常写（从左往右），tag为1表示翻转方向对称写（从右往左）。此外，如果被写入的新数据没有匹配上任何模式，即未被压缩，那么position tag位为0，因为对于未压缩数据，数据从哪一侧写都一样。</p><h4 id="Read-1"><a href="#Read-1" class="headerlink" title="Read"></a>Read</h4><p>读访问期间，如果数据是压缩的，CDE读取position tag位，确认数据在NVM阵列的哪一侧。如果position tag位表示数据被写入NVM word的右半部分，那么CDE读取的数据将被翻转，以将前缀恢复到正确的形式，并将数据传递给CDE对应模式表进行解压缩。</p><h4 id="Write-orientation"><a href="#Write-orientation" class="headerlink" title="Write orientation"></a>Write orientation</h4><p>那依据什么来决定在NVM阵列中新数据到底是从左向右写还是从右向左写呢？<br>本文提出有两个方法;</p><ol><li><p>利用一个写访问计数器，一旦计数器超过<strong>某一固定阈值</strong>，写访问指示器由”normal”（即position tag为0）变为”flipped“（即position tag为1），转换写方向，并且重置计数器。</p><p>那么阈值怎么确定呢？<br>本文没说阈值的设定方式，本人感觉这个阈值应该小一点磨损均衡效果会更好，相当于更加频繁地在两个方向写之间切换，阈值越小，不会导致有一个方向的写入多一轮而多出的写次数比较多。</p></li><li><p>使用翻转位写的数量来确定写的方向，实现一个更加投机取巧的磨损均衡方案。CDE中的附加电路比较新数据和旧数据，从两个方向进行比较。CDE基于这种比较，分别针对两个方向写计算出位翻转的数目，有更少位翻转的方向被选择，按该方向写入数据，同时正确设置position tag位。</p></li></ol><p>但是第二种方法与其说是一种磨损均衡，似乎更像是一种翻转位写减少优化方案。同时也许可能有磨损均衡的作用，效果视数据类型而定吧。因为某些应用程序可能始终选择从左往右写，会得到更少的位翻转，这根本不能达到磨损均衡的目的。</p><h2 id="Evaluation-and-Result"><a href="#Evaluation-and-Result" class="headerlink" title="Evaluation and Result"></a>Evaluation and Result</h2><p>实验评估显示有几个负载翻转位写数量相比FNW反而增多，为什么？</p><p>实验发现，这些负载同时对应有较低的压缩率或者有很大比例的line不压缩，那么本文的方法由于增加的两个tag位也会带来额外的位翻转，可能会造成这种结果。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Compression Architecture for Bit-write Reduction in Non-volatile Memory Technologies（&lt;a href=&quot;http://delivery.acm.org/10.1145/2780000/277
      
    
    </summary>
    
      <category term="论文阅读记录" scheme="http://malizhen.github.io/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E8%AE%B0%E5%BD%95/"/>
    
    
      <category term="compression algorithm" scheme="http://malizhen.github.io/tags/compression-algorithm/"/>
    
  </entry>
  
  <entry>
    <title>Frequent Pattern Compression</title>
    <link href="http://malizhen.github.io/2019/07/01/FPC/"/>
    <id>http://malizhen.github.io/2019/07/01/FPC/</id>
    <published>2019-07-01T12:39:37.000Z</published>
    <updated>2019-07-04T07:47:38.432Z</updated>
    
    <content type="html"><![CDATA[<p>Frequent Pattern Compression: A Significance-Based Compression Scheme for L2 Caches（ <a href="https://pdfs.semanticscholar.org/e7c6/f67a70b5cf0842a7a2fc497131a79b6ee2c5.pdf" target="_blank" rel="noopener">原文链接</a>）。随着处理器和内存速度之间差距的扩大，内存系统设计人员可能会发现缓存压缩有利于增加缓存容量和减少片外带宽。大多数硬件压缩算法都属于基于字典的类别，这依赖于构建字典并使用其条目对重复数据值进行编码，在压缩大数据块和文件时非常有效。然而，cache line通常为32-256 bytes，每行字典的开销很大，这限制了这种算法的可压缩性，并增加了解压缩延迟。对于这样的短行，基于重要性的压缩可以考虑。</p><p>本文提出并评估一种简单的基于重要性的压缩方案，该方案具有较低的压缩和解压缩开销。该方案使用带适当前缀的压缩格式<strong>存储常见的word模式</strong>，从而按word逐行压缩cache line。提出一种压缩缓存设计，其中数据以压缩形式存储在L2中，但在L1中未压缩。<strong>L2被压缩到预先确定的大小</strong>，以减少解压开销。</p><p><strong>基于重要性的压缩基于这样的观察：大多数数据类型(例如，32位整数)可以存储在比允许的最大位数更少的位中。即窄值与0值大量存在。</strong>与基于字典的压缩方案相比，基于重要性的压缩不会产生每行字典开销，这使得它更适用于典型的短缓存行。此外，压缩和解压硬件比基于字典的编码和解码要快。然而，对于长缓存行，可压缩性可能会显著降低。</p><h2 id="Frequent-Pattern-Compression"><a href="#Frequent-Pattern-Compression" class="headerlink" title="Frequent Pattern Compression"></a>Frequent Pattern Compression</h2><p>每个cache line被分成一些32-bit大小的word(例如，64-byte的cache line分成16个word)。表1显示了每个前缀对应的不同模式。这些模式是根据许多商业基准测试中的高频模式选择的。每个32-bit的word都根据模式表被编码为一个3-bit前缀加上数据的压缩格式。 与这些模式都不匹配的word以其原始的32位格式存储。如果某个word与表1前七行中的任一模式匹配，则将其编码为压缩格式。</p><p><img src="https://github.com/Malizhen/Malizhen.github.io/blob/master/images/FPC/1.png?raw=true" alt="images"></p><h3 id="Segmented-Frequent-Pattern-Compression"><a href="#Segmented-Frequent-Pattern-Compression" class="headerlink" title="Segmented Frequent Pattern Compression"></a>Segmented Frequent Pattern Compression</h3><p>与未压缩相比，L2 cache必须能够在相同的空间中容纳更多的压缩cache line。这就会导致原本的线性映射被破坏，或者产生碎片可利用空间。最常见的解决这一问题的办法是解耦缓存访问，在address tag与data storage之间添加间接层。</p><p>理论上，cache line可以压缩成任意数量的bit。然而，这种设计增加了缓存管理的复杂性。本文的压缩缓存设计中，每个缓存行存储为一组8-byte segemnt。例如，64-byte的cache line一定能够被存储为1-8个segment，未压缩为8个8-byte segment。压缩的cache line，填充0，直到其大小变为段大小(8 byte)的倍数，这些额外的0(与任何tag不对应)在解压缩期间被忽略。虽然这种方法可能在某些模式下不具有高压缩比，比如，全0的情况下，但是它能够更快地实现缓存访问。</p><h2 id="Compression-and-Decompression"><a href="#Compression-and-Decompression" class="headerlink" title="Compression and Decompression"></a>Compression and Decompression</h2><p>本文提出了一种压缩缓存设计，其中未压缩数据存储在L1中，压缩数据存储在L2中。这有助于减少许多阻碍性能的L2缓存缺失，同时不影响L1缓存的命中。然而，这样的设计增加了在两个级别缓存之间移动时压缩或解压的开销。而FPC能够尽可能降低压缩与解压开销。</p><h3 id="Compression"><a href="#Compression" class="headerlink" title="Compression"></a>Compression</h3><p>cache line压缩发生在数据从L1写到L2时。使用一个简单的电路(并行地)检查每个word的模式匹配，如果一个word匹配七个可压缩模式中的任何一个，就使用一个简单的编码电路将word编码成最紧凑的形式。如果没有找到匹配项，则将整个word存储为前缀“111”。对于zero run，需要检测连续运行的零，并递增第一次出现的数据值来表示它们的计数。由于本文的设计中zero run被限制为8个零，这可以在一个循环中使用一个简单的多路复用器/加法器电路来实现。cache line压缩可以在内存管道中实现，方法是在L1到L2的写路径上分配三个管道阶段(一个用于模式匹配，一个用于zero run编码，一个用于收集压缩行)。一个包含少量压缩和非压缩形式条目的小受害者缓存可以用来隐藏L1写回时的压缩延迟。</p><h3 id="Decompression"><a href="#Decompression" class="headerlink" title="Decompression"></a>Decompression</h3><p>当数据从L2读取到L1时，会发生cache line解压缩。解压延迟非常重要，因为它被直接添加到L2 hit延迟中。解压缩比压缩慢，因为cache line中所有word的前缀都必须按顺序访问，因为每个前缀用于确定其对应的编码word的长度，从而确定所有后续压缩word的起始位置。</p><p>下图展示了一种可用于解压64-byte cache line的五阶段硬件管道。</p><p><img src="https://github.com/Malizhen/Malizhen.github.io/blob/master/images/FPC/2.png?raw=true" alt="images"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Frequent Pattern Compression: A Significance-Based Compression Scheme for L2 Caches（ &lt;a href=&quot;https://pdfs.semanticscholar.org/e7c6/f67a7
      
    
    </summary>
    
      <category term="论文阅读记录" scheme="http://malizhen.github.io/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E8%AE%B0%E5%BD%95/"/>
    
    
      <category term="compression algorithm" scheme="http://malizhen.github.io/tags/compression-algorithm/"/>
    
  </entry>
  
  <entry>
    <title>Gem5简介</title>
    <link href="http://malizhen.github.io/2019/06/28/Gem5/"/>
    <id>http://malizhen.github.io/2019/06/28/Gem5/</id>
    <published>2019-06-28T06:51:26.000Z</published>
    <updated>2019-06-28T07:07:08.096Z</updated>
    
    <content type="html"><![CDATA[<p>Gem5是一款模块化的离散事件驱动全系统模拟器，它结合了M5和GEMS中最优秀的部分，M5提供了高度可配置的模拟框架，支持多种ISAs和CPU模型；GEMS补充了M5的特性，提供了详细而灵活的内存系统，包括多种cache 一致性协议和互连模型，是一款高度可配置、集成多种ISA，多种CPU模型的体系结构模拟器。</p><p>gem5模拟器目前支持多种ISAs，包括Alpha、ARM、MIPS、Power、SPARC和x86。模拟器的模块性允许这些不同的ISAs插入到通用CPU模型和内存系统中，而不需要为每一种ISAs设置一种专用的CPU模型和存储模型，这使得模拟器模块化程度较高且易于在不同CPU之间切换。</p><p>M5是由Michigan大学开发的一款开源的多处理机模拟器，受到了业内的广泛关注，很多高水平论文都采用M5作为研究工具。另一方面，Wisconsin推出的GEMS能够对储存层次进行详细而灵活的模拟，包括对多种不同的cache一致性协议和互联模型的支持。目前的GEM5是M5和GEMS的一个紧耦合版本。</p><h2 id="1-总体目标"><a href="#1-总体目标" class="headerlink" title="1.总体目标"></a>1.总体目标</h2><p>gem5模拟器的目标是成为一个用于体系结构建模的优秀工具。这一目标的三个关键方面是灵活性，可用性，高度可协作性。</p><p><img src="https://github.com/Malizhen/Malizhen.github.io/blob/master/images/gem5/1.png?raw=true" alt="images"><center>图一   Speed vs. Accuracy</center></p><h3 id="1-1-灵活性"><a href="#1-1-灵活性" class="headerlink" title="1.1 灵活性"></a>1.1 灵活性</h3><p>灵活性是一个好的模拟器的基础。当一个想法从概念落地到一个特定的设计时，程序员需要一个工具来评估系统，平衡仿真速度和准确性。不同类型的实验可能有不同的模拟要求。例如，某些实验可能需要一个精细的CPU模型，但是没有必要进行多核建模。而某些实验可能需要多个CPU，但是这些CPU不需要太多的细节。所以模拟器的灵活性必不可少，使得程序员能够以更少的开销更快地完成更多的工作。</p><p>gem5模拟器就是这样一个工具，提供了各种各样的功能和组件，涵盖了仿真速度和精度之间的权衡。如图1所示。</p><h4 id="CPU模型"><a href="#CPU模型" class="headerlink" title="CPU模型"></a>CPU模型</h4><p>gem5模拟器目前提供了四种不同的CPU模型：AtomicSimple、TimingSimple、InOrder和O3。AtomicSimple和TimingSimple是非流水线CPU模型，AtomicSimple是一种最小的单IPC CPU模型，适用于快速功能模拟；TimingSimple与之类似，但是使用了存储器访问时序模型，用以统计存储器访问延迟；InOrder是一个按序流水线CPU模型，该模式下，可以配置硬件支持的线程数量；O3是一个乱序流水线CPU模型，可以支持超标量结构和SMT。InOrder与O3都是execute-in-execute（指令的执行只在执行阶段）的设计。</p><h4 id="系统模式"><a href="#系统模式" class="headerlink" title="系统模式"></a>系统模式</h4><p>gem5支持两种执行模式：System-call Emulation（SE）和Full-System（FS）。</p><p>SE模式中，当程序执行系统调用时，gem5会捕捉到，同时模拟调用，通常是传递给主机操作系统。通过模拟大部分的系统调用，避免了对外设和OS进行建模的需要。SE模式下，没有线程调度器，线程必须静态的映射到cores，因此会限制多线程应用。SPEC CPU基准测试通常在SE模式下运行。FS（全系统）模式对一个完整系统，包括OS和外设，进行了建模，支持执行用户和内核指令。FS模式中，gem5提供了一个适合运行操作系统的裸机环境，包括中断，异常等，并不是所有ISAs都支持此模式。FS相对于SE，精度更高，可以执行更多类型的负载。虽然SPEC CPU基准测试通常在SE模式下运行，但是在FS模式下运行它们将提供与OS更实际的交互。因此需要许多OS服务或I/O设备的工作负载可能只在FS模式下运行。</p><h4 id="存储系统"><a href="#存储系统" class="headerlink" title="存储系统"></a>存储系统</h4><p>支持两种存储系统模型：Classic和Ruby。Classic模型（来自M5）提供了一个快速且易于配置的内存系统；Ruby模型（来自GEMS）提供了一种灵活且能够精确模拟的内存系统，支持cache一致性。Ruby内存模型支持大量的互连拓扑结构，同时包括两种不同的网络模型。组件之间的链接使用一个简单的python文件声明，然后通过最短路径分析创建路由表。在确定链接和路由表后，根据不同的网络模型进行实现。两种网络模型为：</p><p>1、Simple网络模型：只对链接，路由延迟和链路带宽，并没有对路由器资源争用和流量控制建模。</p><p>2、Garnet网络模型：对路由建立了详细的模型，包括相关的资源竞争和流量控制。</p><h3 id="1-2-可用性"><a href="#1-2-可用性" class="headerlink" title="1.2 可用性"></a>1.2 可用性</h3><p>gem5用户有几种类型，每个人都有不同的目标和需求。这些人包括学术和企业研究人员、工业工程师、本科生和研究生。Gem5的开发者们希望gem5模拟器能够广泛地提供给所有这些类型的用户。gem5许可证(基于BSD)对企业用户和学术界都很友好。gem5社区非常活跃，有很多协作技术可以促进gem5的使用和开发。</p><h2 id="2-设计特点"><a href="#2-设计特点" class="headerlink" title="2.设计特点"></a>2.设计特点</h2><p>本节重点介绍gem5实现的几个关键方面：面向对象的设计、Python集成、特定领域的语言和标准化接口的使用。</p><h3 id="2-1-面向对象"><a href="#2-1-面向对象" class="headerlink" title="2.1 面向对象"></a>2.1 面向对象</h3><p>灵活性是gem5模拟器的一个重要目标，也是其成功的关键方面。灵活性主要是通过面向对象的设计来实现的。gem5模拟器中的每个主要仿真组件都是SimObjects，它们共享配置、初始化、统计和序列化(检查点)的公共行为。SimObjects包括了具体的硬件组件(如处理器内核、缓存、互连元素和外设)以及更抽象的实体(如用于系统调用仿真的工作负载及其关联的流程上下文)。这里的外设包括简单的定时器到复杂的网络接口控制器，通过使用基类来封装公共设备接口，以避免代码重复，简化实现。所有的SimObject对象都由两种类表示，python类和c++类。Python类的定义指定了SimObject的参数，并且可以在配置脚本文件中使用。公共Python基类为实例化、命名和设置参数值提供了统一的机制。C++类包含了SimObject的状态和其它行为，同时包括了关键性能的仿真模型。</p><h3 id="2-2-Python集成"><a href="#2-2-Python集成" class="headerlink" title="2.2 Python集成"></a>2.2 Python集成</h3><p>gem5中的代码85%是用C++写成的，15%的Python代码主要负责SimObject的初始化、配置和模拟控制。模拟器在启动时立即开始执行Python代码，标准的main函数使用python编写，所有的命令行处理和启动代码都是python代码。</p><h3 id="2-3-领域特定语言"><a href="#2-3-领域特定语言" class="headerlink" title="2.3 领域特定语言"></a>2.3 领域特定语言</h3><p>gem5提供了两种特定领域的语言，一种用于描述ISA（继承自M5），另一种用于描述cache的一致性协议（继承自GEMS）。</p><h4 id="ISA-DSL"><a href="#ISA-DSL" class="headerlink" title="ISA DSL"></a>ISA DSL</h4><p>用于统一二进制指令的解码和它们的语义规范。gem5通过使用一个通用的C++基类来描述指令，从而实现了ISA的独立。每种ISA会重新基类中继承的方法，例如execute()。ISA描述语言允许用户简洁地指定所需的c++代码。</p><h4 id="Cache-Coherence-DSL"><a href="#Cache-Coherence-DSL" class="headerlink" title="Cache Coherence DSL"></a>Cache Coherence DSL</h4><p>SLICC是一种DSL，用于灵活的实现cache一致性协议。SLICC目前支持AMD Opteron的基于广播的一致性协议和CMP的目录协议。SLICC将cache，mem，DMA控制器定义为单独的per-memory-block的状态机，这些状态机组合称为整个的协议。gem5中的SLICC将协议定义为一组状态、事件、转换和操作，同时将状态机特定的逻辑和协议无关的组件（例如cache）绑定在一起。gem5的SLICC会自动生成python和c++文件，同时也支持局部变量，以简化编程提高性能</p><h3 id="2-4-标准化接口"><a href="#2-4-标准化接口" class="headerlink" title="2.4 标准化接口"></a>2.4 标准化接口</h3><p>标准化接口是面向对象的基础。有两个核心的接口，端口（port）接口和消息缓冲（message buffer）接口。</p><p>1、端口接口：连接内存对象，包括cpu和caches，caches到总线，总线到外设和内存。该接口支持三种机制来访问数据，1) timing模式，用来建模带有详细时序的内存访问，会有request和response的消息机制；2) atomic模式，用来获取时序信息，但是没有消息机制，状态会直接发生变化；3) 功能模式，存储操作不会改变时序信息。</p><p>2、消息缓冲接口：Ruby使用端口接口来连接cpu和外设，同时使用消息缓冲接口连接Ruby内部对象。两个接口非常类似。</p><h2 id="3-用户资源"><a href="#3-用户资源" class="headerlink" title="3.用户资源"></a>3.用户资源</h2><p>所有gem5模拟器的文档和信息都可以在网站<a href="http://www.gem5.org" target="_blank" rel="noopener">http://www.gem5.org</a>上找到。该网站包括如何检查、构建和运行gem5模拟器的说明，以及如何下载OS二进制文件和磁盘映像等补充支持文件。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Gem5是一款模块化的离散事件驱动全系统模拟器，它结合了M5和GEMS中最优秀的部分，M5提供了高度可配置的模拟框架，支持多种ISAs和CPU模型；GEMS补充了M5的特性，提供了详细而灵活的内存系统，包括多种cache 一致性协议和互连模型，是一款高度可配置、集成多种IS
      
    
    </summary>
    
      <category term="模拟器" scheme="http://malizhen.github.io/categories/%E6%A8%A1%E6%8B%9F%E5%99%A8/"/>
    
    
      <category term="gem5" scheme="http://malizhen.github.io/tags/gem5/"/>
    
  </entry>
  
  <entry>
    <title>Data Compression Techniques</title>
    <link href="http://malizhen.github.io/2019/06/26/Compression/"/>
    <id>http://malizhen.github.io/2019/06/26/Compression/</id>
    <published>2019-06-26T06:57:53.000Z</published>
    <updated>2019-07-04T13:20:54.525Z</updated>
    
    <content type="html"><![CDATA[<p>最近读了比较多的关于数据压缩的论文，具体的论文阅读记录后续会慢慢抽时间写出来，本文先对最近所读简单地进行一个归纳与总结。主要按照以下目录分几个方面来进行总结。</p><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><ol><li><p>现在的应用程序多为数据密集型；</p></li><li><p>内存需求近些年一直在增加；</p></li></ol><p>而DRAM作为最常见的系统内存，存储密度低，简单来说就是，目前单个DRAM芯片的集成度已经接近极限，远不能满足大数据对内存容量TB级甚至PB级的需求。显然，数据压缩技术对于未来的系统是必不可少的。</p><h2 id="Benefits-of-Data-Compression"><a href="#Benefits-of-Data-Compression" class="headerlink" title="Benefits of Data Compression"></a>Benefits of Data Compression</h2><p>为什么研究数据压缩，肯定是因为有好处，有前景，那么有哪些好处呢？</p><ol><li><p>不增加内存大小，就能获得更多的有效容量；</p></li><li><p>避免内存溢出：尤其适用于嵌入式系统；</p></li><li><p>减少缺失率和带宽占用；</p></li><li><p>节省能耗，在能耗相同的情况下，能够做更多的计算。</p></li></ol><p>此外，在NVM和3D内存中尤其适用，能够：</p><ol><li><p>减少写数据量和写能耗；</p></li><li><p>减轻NVM的耐力问题；</p></li></ol><p><strong>Storage Compression</strong>(例如，缓存压缩)：减少数据存储能耗</p><p><strong>Bandwidth Compression</strong>：减少数据移动能耗</p><h2 id="Opportunities-for-Compression"><a href="#Opportunities-for-Compression" class="headerlink" title="Opportunities for Compression"></a>Opportunities for Compression</h2><p>就目前研究来看，什么情况下什么类型的数据经常被压缩？</p><ol><li><p>常量、数据复制和赋值  </p></li><li><p>使用公共值初始化  </p></li><li><p>较大的数据类型用于存储较小的数据  </p></li><li><p>特殊值的大量出现，如0,1</p></li></ol><p>以上情况下的数据有很大的冗余，能够考虑利用压缩来消除冗余，具体是什么类型的数据用下图程序段来举例说明。</p><p><img src="https://github.com/Malizhen/Malizhen.github.io/blob/master/images/Compression/1.png?raw=true" alt="images"></p><ol start="5"><li>图片</li></ol><p>目前有很多利用图片中相邻像素点值差异很小这一特点来进行的相关研究。</p><p><img src="https://github.com/Malizhen/Malizhen.github.io/blob/master/images/Compression/2.png?raw=true" alt="images"></p><p>针对以上前四种数据类型，很多论文中有专业的名词来表示它们，分别是Other Patterns、Repeated Values、Narrow Values、Zero Values。</p><p><img src="https://github.com/Malizhen/Malizhen.github.io/blob/master/images/Compression/3.png?raw=true" alt="images"></p><h2 id="Challenge-in-using-Compression"><a href="#Challenge-in-using-Compression" class="headerlink" title="Challenge in using Compression"></a>Challenge in using Compression</h2><p>任何一种技术都不可能十全十美，那么压缩有啥坏处呢？</p><ol><li><p>有压缩那就对应地有解压缩，而压缩和解压缩都会产生额外的延迟和能耗，压缩延迟不在关键路径上，但是解压缩延迟位于缓存命中的关键路径上，对性能影响很大。</p></li><li><p>往往现有的压缩率高的压缩算法，对应的就会有复杂的硬件设计，同时有很高的解压延迟开销。</p></li><li><p>压缩仅在最后一级cache和main memory中有用，因为在L1 cache中存储压缩数据，由于解压缩带来的延迟开销无法接受。</p></li><li><p>由于压缩是变长的，使得不同cache line的压缩不能并行。</p></li><li><p>有些技术单独存储未压缩的line，由于复杂的硬件设计会造成很重的开销。</p></li><li><p>存在某些不可压缩的数据(如加密数据)或低效的压缩算法。</p></li><li><p>压缩块大小不是固定的，这会使得后续寻址变得困难，因为压缩前原有的线性映射会发生变化，或者由于压缩产生碎片可用空间。</p></li></ol><p><img src="https://github.com/Malizhen/Malizhen.github.io/blob/master/images/Compression/4.png?raw=true" alt="images"></p><ol start="8"><li><p>删除和插入数据的大小可能不同，导致替换策略变得复杂。</p></li><li><p>最重要的一个问题，会或多或少产生额外的元数据，带来额外的存储开销。</p></li><li><p>如果应用程序内存占用已经很小，压缩没有多大用处，如果内存占用较大，则压缩提供的额外容量也不够，这样来看怎么压缩好像显得有点鸡肋？</p></li></ol><h2 id="Need-of-Carefully-Choosing-Data-Block-Size"><a href="#Need-of-Carefully-Choosing-Data-Block-Size" class="headerlink" title="Need of Carefully Choosing Data-Block Size"></a>Need of Carefully Choosing Data-Block Size</h2><p>如何选择压缩数据块的大小，即压缩粒度怎么决定？越大越好or越小越好？</p><ol><li><p><strong>大的数据块大小作为压缩粒度</strong>：大块内会有更高的冗余，似乎还能够获得更高的压缩比，而且元数据存储开销也会比较低。但是即使只访问大块（例如，2KB）之中的某一个子块（例如，64B），也需要解压整个大块，产生无谓的解压开销，而这很影响性能。此外，在大块内想要找到特殊的模式（例如全为零）比较困难。</p></li><li><p><strong>小的数据块大小作为压缩粒度</strong>：与以上相反，此优点为彼缺点吧！值得注意的是，tag元数据存储开销会大大增加。</p></li></ol><p>因此可以看出，压缩粒度的选择需要根据不同类型应用程序动态选择。</p><h2 id="Some-Compression-Algorithm"><a href="#Some-Compression-Algorithm" class="headerlink" title="Some Compression Algorithm"></a>Some Compression Algorithm</h2><ol><li><p>Huffman coding</p></li><li><p>Lempel-Ziv (LZ) algorithm (and  derivatives)</p></li><li><p>X-match and X-RL</p></li><li><p>Frequent value compression  (FVC)</p></li><li><p>Frequent pattern compression  (FPC)</p></li><li><p>C-PACK</p></li><li><p>Base delta immediate (BDI)  compression</p></li><li><p>Zero-value and narrow-value  detection</p><p>… </p></li></ol><h2 id="Granularity-of-Exploiting-Redundancy"><a href="#Granularity-of-Exploiting-Redundancy" class="headerlink" title="Granularity of Exploiting  Redundancy"></a>Granularity of Exploiting  Redundancy</h2><ol><li><p>Across different blocks of the whole cache (also called deduplication)</p><p> <img src="https://github.com/Malizhen/Malizhen.github.io/blob/master/images/Compression/5.png?raw=true" alt="images"></p></li><li><p>Across different words of a cache  block</p><p><img src="https://github.com/Malizhen/Malizhen.github.io/blob/master/images/Compression/6.png?raw=true" alt="images"></p></li><li><p>Across different bytes of a cache  word</p><p><img src="https://github.com/Malizhen/Malizhen.github.io/blob/master/images/Compression/7.png?raw=true" alt="images"></p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;最近读了比较多的关于数据压缩的论文，具体的论文阅读记录后续会慢慢抽时间写出来，本文先对最近所读简单地进行一个归纳与总结。主要按照以下目录分几个方面来进行总结。&lt;/p&gt;
&lt;h2 id=&quot;Motivation&quot;&gt;&lt;a href=&quot;#Motivation&quot; class=&quot;head
      
    
    </summary>
    
      <category term="论文阅读记录" scheme="http://malizhen.github.io/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E8%AE%B0%E5%BD%95/"/>
    
    
      <category term="compression algorithm" scheme="http://malizhen.github.io/tags/compression-algorithm/"/>
    
  </entry>
  
  <entry>
    <title>DRAM层次结构</title>
    <link href="http://malizhen.github.io/2019/06/12/DRAM-Hierarchy/"/>
    <id>http://malizhen.github.io/2019/06/12/DRAM-Hierarchy/</id>
    <published>2019-06-12T13:14:01.000Z</published>
    <updated>2019-06-13T01:19:17.334Z</updated>
    
    <content type="html"><![CDATA[<p>DRAM（Dynamic Random Access Memory），即动态随机存取存储器，最为常见的系统内存。DRAM 只能将数据保持很短的时间。为了保持数据，DRAM使用电容存储，所以必须隔一段时间刷新（refresh）一次，如果存储单元没有被刷新，存储的信息就会丢失。设备关机也会丢失数据，不像磁盘硬盘等存储介质，类似于我们平时笔记本电脑的内存条。</p><p>本文对DRAM系统的层次结构，做出了比较清晰直观的解读。</p><h2 id="DRAM系统的层次结构"><a href="#DRAM系统的层次结构" class="headerlink" title="DRAM系统的层次结构"></a>DRAM系统的层次结构</h2><p><img src="https://github.com/Malizhen/Malizhen.github.io/blob/master/images/DRAM-Hierarchy/1.png?raw=true" alt="images"></p><p>该图为DRAM系统的层次结构图，从顶层到底层包含Rank、Chip、Bank、Sub-array、MAT、Cell。一个Rank由多个Chip并列组成，同步工作，共同驱动内存总线，一个Chip内部包含多个Bank，它们包含独立的行地址译码器和感应放大器，可以并发访问。通常认为，Bank是DRAM完成独立操作的最小单元。但事实上，每个Bank又可以进一步分割为很多的Sub-array（纵向），每个Sub-array包含很多MAT（横向）。每个MAT有独立的局部感应放大器。一个典型的MAT包含512*512个Cell，即存储单元。每个存储单元由一个电容和一个晶体管组成：电容的电荷多少表示数字0或1，晶体管的栅极与字线相连，由字线控制晶体管的导通；晶体管的漏极与位线相连，导通时由位线表示单元里存储的数据。</p><h3 id="存储单元cell"><a href="#存储单元cell" class="headerlink" title="存储单元cell"></a>存储单元cell</h3><p>DRAM的内部结构可以说是PC芯片中最简单的，是由许多重复的“单元”——cell组成，每一个cell由一个电容和一个晶体管（一般是N沟道MOSFET）构成，电容可储存1bit数据量，充放电后电荷的多少（电势高低）分别对应二进制数据0和1。由于电容会有漏电现象，因此过一段时间之后电荷会丢失，导致电势不足而丢失数据，因此必须经常进行充电保持电势，这个充电的动作叫做刷新（Refresh），因此动态存储器具有刷新特性，这个刷新的操作一直要持续到数据改变或者断电。而MOSFET则是控制电容充放电的开关。DRAM由于结构简单，可以做到面积很小，存储容量很大。放大cell的结构，对cell进行分析，了解DRAM是如何通过电容存取数据的。</p><p><img src="https://github.com/Malizhen/Malizhen.github.io/blob/master/images/DRAM-Hierarchy/2.png?raw=true" alt="images"></p><h4 id="1、写入数据"><a href="#1、写入数据" class="headerlink" title="1、写入数据"></a>1、写入数据</h4><p>如图，向cell中写入数据时，将WL设置为高电平，使晶体管M处于导通状态。此时，Cs和Bitline共享电荷，对Cs进行充电，电压升高到Vs，Bitline处于高电平，写入1；对Cs进行放电，电压降到0，Bitline处于低电平，写入0。</p><h4 id="2、读取数据"><a href="#2、读取数据" class="headerlink" title="2、读取数据"></a>2、读取数据</h4><p>从cell中读取数据时，同样，首先将WL设为高电平，使晶体管M处于导通状态，逻辑电路通过Bitline感知Cs电荷的重新分配，从而读取数据。具体过程如下：首先，对Bitline进行Precharge，即将Bitline上的电压升到Vs/2，这样的话一旦M处于导通状态，如果cell中保存了1，那么Cs中电压为Vs，与Bitline上电压存在电压差，电荷会从Cs流出到Bitline，使Bitline上的电压升高。cell之外的一个逻辑电路块可以感知这种变化，从而读出数据1。同理，若cell保存的是数据0，那么Cs中电压为0，则Bitline中电荷流出，电压降低，电路感知到这种变化，读出数据0。</p><p>注意：由于这种读取操作造成电荷的流入流出，是破坏性的。因此，读操作之后需要Refresh操作，恢复Cs的电荷状态。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;DRAM（Dynamic Random Access Memory），即动态随机存取存储器，最为常见的系统内存。DRAM 只能将数据保持很短的时间。为了保持数据，DRAM使用电容存储，所以必须隔一段时间刷新（refresh）一次，如果存储单元没有被刷新，存储的信息就会丢失。
      
    
    </summary>
    
      <category term="存储" scheme="http://malizhen.github.io/categories/%E5%AD%98%E5%82%A8/"/>
    
    
      <category term="DRAM" scheme="http://malizhen.github.io/tags/DRAM/"/>
    
  </entry>
  
  <entry>
    <title>VSCode:Remote-SSH配置</title>
    <link href="http://malizhen.github.io/2019/06/10/VsCode/"/>
    <id>http://malizhen.github.io/2019/06/10/VsCode/</id>
    <published>2019-06-10T01:54:25.000Z</published>
    <updated>2019-06-10T13:05:58.565Z</updated>
    
    <content type="html"><![CDATA[<p>最近VScode发布了远程编程与调试的插件Remote Development，使用这个插件可以在很多情况下代替vim直接远程修改与调试服务器上的代码，就和在本地使用VScode一样。终于不用在服务器端翻来覆去的配置vim插件了，同时服务器端的比如tmux配置可以原封不动地在本地VScode使用。本文介绍配置的过程以及如何在本地通过ssh的方法连接到远程机器上。</p><h2 id="配置过程"><a href="#配置过程" class="headerlink" title="配置过程"></a>配置过程</h2><h3 id="安装VScode"><a href="#安装VScode" class="headerlink" title="安装VScode"></a>安装VScode</h3><p>原本Remote-SSH这个插件仅支持VSCode的Insider版本（2019.5.8发布），所以你需要下载<a href="https://code.visualstudio.com/insiders/" target="_blank" rel="noopener">VSCode的Insider版本</a></p><p>安装过程很简单，直接下一步直到完成，然后在扩展搜索remote ssh点击安装。</p><p><img src="/images/VSCode/1.png" alt="avatar"></p><p>安装完成后侧边栏会出现新的图标。</p><p><img src="/images/VSCode/2.png" alt="avatar"></p><h3 id="客户端服务器端SSH配置"><a href="#客户端服务器端SSH配置" class="headerlink" title="客户端服务器端SSH配置"></a>客户端服务器端SSH配置</h3><p>在本地机器（我这里是自己的windows宿主机），后文称为客户端，安装的vmware虚拟机称为服务器端（Linux）。</p><p>1、首先在客户端安装ssh</p><p>打开计算机设置页面</p><p><img src="/images/VSCode/3.png" alt="avatar"></p><p>选择应用-应用和功能-管理可选功能，安装OpenSSH客户端</p><p><img src="/images/VSCode/4.png" alt="avatar"></p><p>在客户端左下角搜索输入cmd，命令行输入ssh-keygen -t rsa，输入你想要放置SSH密钥对的目录，这里一般不更改，一直enter直到结束即可，最后在`c:\user目录下生成密钥文件id-rsa和id-rsa.pub，第一个是私钥文件，第二个是公钥文件。</p><p><img src="/images/VSCode/5.png" alt="avatar"></p><p>2、接下来将客户端的公钥内容添加到服务器端，步骤如下：</p><p>首先检测ssh服务是否启动 ： netstat -ntlp | grep ssh </p><p>如果ssh服务没有启动 ：/etc/init.d/ssh resart</p><p>方法一：</p><p>手动创建.ssh文件夹如下所示，我这里已经建好了，只是截图展示一下文件位置，并在.ssh文件夹下创建文件authorized_keys，将客户端公钥复制进去。这里注意文件权限可能需要修改。</p><p>1) .ssh目录的权限必须是700</p><p>2) .ssh/authorized_keys文件权限必须是600</p><p>   下图第一列就是文件权限。</p><p><img src="/images/VSCode/6.png" alt="avatar"></p><p>修改配置文件：<code>vim /etc/ssh/sshd_config，把</code>PubkeyAuthentication配置为 yes ，允许使用基于密钥认证的方式登录。</p><p>方法二：</p><p>也可以通过ssh-copy-id的方式，需要在客户端安装bash，cmd无法识别linux命令。可以将公钥复制到远程机器。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ssh-copy-id -i .ssh/id_rsa.pub 用户名@192.168.x.xxx</span><br></pre></td></tr></table></figure><h3 id="远程连接"><a href="#远程连接" class="headerlink" title="远程连接"></a>远程连接</h3><p>如图选择文件目录，这是让你选择你的config文件放在哪里，必须放在客户端密钥文件夹下</p><p><img src="/images/VSCode/7.png" alt="avatar"></p><p>配置文件内容很简单，就两行</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ Host <span class="built_in">alias</span></span><br><span class="line">  $ HostName 1.1.1.1 <span class="comment">#服务器的ip，服务器终端输入ifconfig命令查看inet地址</span></span><br><span class="line">  $ User username <span class="comment">#远程服务器的用户名，其实就是你的虚拟机终端前面显示的用户名</span></span><br></pre></td></tr></table></figure><p>配置完成，选择在当前窗口开启连接</p><p><img src="/images/VSCode/8.png" alt="avatar"></p><hr><p>连接成功，左下角会如下图所示</p><p><img src="/images/VSCode/9.png" alt="avatar"></p><p>接下来可以导入服务器端的项目，选择编辑栏File-Open Workspace，成功导入项目</p><p><img src="/images/VSCode/10.png" alt="avatar"></p><h3 id="VSCode更新"><a href="#VSCode更新" class="headerlink" title="VSCode更新"></a>VSCode更新</h3><p>一个功能如果只能针对特定版本可用，那就谈不上任何方便了。因此不到一个月VSCode版本发布了更新，目前的VSCode 1.35支持Remote SSH配置，需要可官网下载<a href="https://code.visualstudio.com/updates/v1_35" target="_blank" rel="noopener">下载链接</a>，若已下载老版本，点击菜单栏Help-Check for Updates进行更新，重启即可生效，然后同样的安装Remote - SSH，密钥已经配置好了，只需再选择Config文件，就能够远程连接上服务器，配置完成之后，每次开启服务器之后，在客户端开启VSCode就会自动连接上服务器，很方便。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;最近VScode发布了远程编程与调试的插件Remote Development，使用这个插件可以在很多情况下代替vim直接远程修改与调试服务器上的代码，就和在本地使用VScode一样。终于不用在服务器端翻来覆去的配置vim插件了，同时服务器端的比如tmux配置可以原封不动地
      
    
    </summary>
    
      <category term="搭建与配置" scheme="http://malizhen.github.io/categories/%E6%90%AD%E5%BB%BA%E4%B8%8E%E9%85%8D%E7%BD%AE/"/>
    
    
      <category term="VSCode" scheme="http://malizhen.github.io/tags/VSCode/"/>
    
  </entry>
  
  <entry>
    <title>Base-Delta-Immediate Compression</title>
    <link href="http://malizhen.github.io/2019/06/06/Base-Delta-Immediate%20Compression/"/>
    <id>http://malizhen.github.io/2019/06/06/Base-Delta-Immediate Compression/</id>
    <published>2019-06-06T01:56:23.000Z</published>
    <updated>2019-06-13T13:50:47.451Z</updated>
    
    <content type="html"><![CDATA[<p>Base-Delta-Immediate Compression:Practical Data Compression for On-Chip Caches。<a href="https://dl.acm.org/citation.cfm?id=2370870" target="_blank" rel="noopener">原文链接</a>很多基于软件的缓存压缩算法主要有两大缺点：造成很高的硬件复杂度；无法接受的解压延迟。本文提出了一种新的压缩算法Base-Delta-Immediate (B∆I) ，关键思想是：大多数cache line有一个特点，同一cache line中存储的数据差异很小。基于这一观察，cache line的数据可以用一个基值（Base）+ 一组差异值（Delta）来表示，所需存储空间必然会比原始cache line大小小得多。</p><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>为了缓解CPU和主存之间速度不匹配的问题，在主存与CPU之间插入一级或多级cache。然而cache并不是越大越好，虽然更大的cache通常会带来更少的cache miss，但是这种好处是以更长的访问延迟、更大的cache面积（昂贵）和更大的功耗为代价的。</p><p>基于这些限制，为了提高cache的利用率，可能会想到通过数据压缩来减少数据量，然而数据压缩并没有被现代商用微处理器作为一种提高有效缓存容量的方法，为什么？理想的缓存压缩技术应该是快速（压缩/解压延迟低）、简单（硬件复杂度低）、高效（高压缩率）的，而如果在商用微处理器中采用缓存压缩，会面临的最大障碍可能是解压延迟，解压与压缩不同，压缩是在缓存写入时(在提供关键字之后)在后台进行的，而解压缩位于cache hit的关键路径上，在此路径上最小化延迟对于性能非常重要。</p><p>因此，快速、简单、高效的缓存压缩方案，不可兼得，怎么办？只能权衡得到最佳方案，要么压缩率低、要么硬件复杂度高、要么解压延迟高，总会有缺陷，方案是否可行就看好处是否大于坏处，为了在降低硬件复杂度和解压缩延迟的同时达到显著的压缩比，本文提出了一种新的缓存压缩技术Base-Delta-Immediate(B∆I)压缩。</p><h2 id="BASE-DELTA-ENCODING-BASIC-IDEA"><a href="#BASE-DELTA-ENCODING-BASIC-IDEA" class="headerlink" title="BASE + DELTA ENCODING: BASIC IDEA"></a>BASE + DELTA ENCODING: BASIC IDEA</h2><p>基于两个特点：</p><ol><li><p>数据在内存中分配的规律性（相似的数据值和类型分组在一起）。</p></li><li><p>缓存/内存数据的动态范围较低（例如，同一cache line的数据差异很小）。</p></li></ol><p>设计了Base+Delta 压缩方案，通过存储一个Base和一组Delta来减少冗余从而提高Cache line的利用率。接下来通过两个直观的例子来更好地理解。</p><p><img src="https://github.com/Malizhen/Malizhen.github.io/blob/master/images/BDI%EF%BC%9ABase-Delta-Immediate%20Compression/1.png?raw=true" alt="images"></p><p> 应用程序h264ref的32-byte cache line利用Base+Delta 方案压缩如上图所示，该cache line包含一组（8个）以4字节整数形式存储的窄值。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">窄值是使用大数据类型存储的小值。例如，一个one-byte的值存储为一个four-byte整型数。程序员通常在各种数据结构中以最坏的情况为标准提供数据类型，即使大多数数值可能适合较小的数据类型。</span><br></pre></td></tr></table></figure><p>从Figure 3我们看到，cache line通过一个全0的base+一组八个1-byte的差异值即可表示所有存储的数值，只要4+8*1共12 byte就能表示整个cache line，这样消除冗余之后相比原来节省了20 byte的空间。看到这里就很容易联想到一个问题，如果说base的byte数太大，差异值节省出来的空间不够多，那么压缩还不如不压缩对不对？这个问题作者在下文考虑到了，base数目、base字节数、差异值的字节数多少才最合适？选择哪个value做base效果会一样吗？不一样的话那如何确定呢？都是我们需要考虑权衡的点。</p><p><img src="https://github.com/Malizhen/Malizhen.github.io/blob/master/images/BDI%EF%BC%9ABase-Delta-Immediate%20Compression/2.png?raw=true" alt="images"></p><p>由Figure 4，在perlbench应用程序负载上，同样是一个32-byte的cache line，存储的是pointer，可以看到，同一cache line的pointer值依然具有很高的相似度。</p><p>注意：虽然这里例子使用的是32-byte的cache line，最后实验评估部分有考虑更常见的64-byte cache line。</p><h3 id="Compression-Algorithm"><a href="#Compression-Algorithm" class="headerlink" title="Compression Algorithm"></a>Compression Algorithm</h3><p>关于该算法的具体描述，论文里面给出了公式（貌似有误，反了），也很容易理解，就是通过简单的向量减法得到Delta。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">∆i = Vi - B* ，其中V表示原始值的集合，∆表示差异值的集合，B*表示base值，若cache line的大小为C byte，其中每个value的大小为k byte，那么i的取值为1~C/k</span><br></pre></td></tr></table></figure><p>这里有两个观察：</p><ol><li><p>若存在任意一个Vi和所选base相似度为0，即Delta(i)的大小等于k，那么该缓存行不能压缩。因为本来引入base就加重了开销，压缩效果不好不如不压缩。</p></li><li><p>如何确定哪个value被选为base？要么Vi的最小值或最大值，要么中间值，被认为是最佳的。理论上是这样的，实际上的做法呢？</p></li></ol><p>我们除了确定base，还需要确定k，即每个value的大小，决定了一个cache line能容纳多少个value。</p><h4 id="Determining-k"><a href="#Determining-k" class="headerlink" title="Determining k"></a>Determining k</h4><p>k在2、4、8之间选择最佳压缩率的k值。选择2、4、8是因为几乎所有由各种编程语言支持的基本数据类型都有这三种大小之一。</p><h4 id="Determining-B"><a href="#Determining-B" class="headerlink" title="Determining B*"></a>Determining B*</h4><p>B*可以依据上述观察2来选取，然而，用这种方式寻找base需要计算原始集合的最大value与最小value，这会大大增加硬件的逻辑复杂度，并且会明显增加压缩延迟。所以为了简单起见，选择第一个value作为base即可，并且实验表明，压缩率相比选择理论最优base降低仅仅0.4%，很微不足道了，并且还不会增加硬件复杂度以及压缩延迟。</p><h3 id="Decompression-Algorithm"><a href="#Decompression-Algorithm" class="headerlink" title="Decompression Algorithm"></a>Decompression Algorithm</h3><p>通过B*和∆的值能够计算得到V，实现解压：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Vi = ∆i + B*</span><br></pre></td></tr></table></figure><p>因此，cache line中的值可以使用SIMD-style的向量加法器并行计算得到。即使用一组简单的加法器，可以在执行整数向量加法所需的时间内解压缩整个cache line。</p><h2 id="B∆I-COMPRESSION"><a href="#B∆I-COMPRESSION" class="headerlink" title="B∆I COMPRESSION"></a>B∆I COMPRESSION</h2><p>前一部分介绍了Base + Delta，以此为基础怎样能够更完善我们的压缩算法呢？</p><p>因为尽管B+∆被证明适用于大多数的应用程序，但是不可能所有的cache line都能用这种形式来表示，有一些基准测试压缩率就不见得好，比如mcf。这是因为有些应用程序在同一cache line中间可能混合有不同类型的数据，比如指针和1-byte的整数。这种情况下，很显然，如果我们选取多个base，一种类型一个base的话是不是压缩效果会好很多呢？</p><p><img src="https://github.com/Malizhen/Malizhen.github.io/blob/master/images/BDI%EF%BC%9ABase-Delta-Immediate%20Compression/3.png?raw=true" alt="images"></p><p>如Figure 5所示，我们发现对于在同一cache line可能存储着不同类型的数据的应用程序，多个base压缩效果会更好，但是这会造成更大的base存储开销，所以，存在一个<strong>tradeoff</strong>，因为显然不是多个base一定会更好，那么选取多少个base才是最优的呢？</p><p>光说都是没有依据的，通过实验来说话，作者设计了一个实验，评估了选择不同数量base(使用贪婪算法依次选择次优base)的有效压缩比，Figure 6展示了实验结果。</p><p><img src="https://github.com/Malizhen/Malizhen.github.io/blob/master/images/BDI%EF%BC%9ABase-Delta-Immediate%20Compression/4.png?raw=true" alt="images"></p><p>结果表明，就有效压缩比而言，经验上最优的base个数是2，虽然少数benchmark在1或3个base上也有最优，最后的结论还是B+∆在两个base的情况下，性能明显优于B+∆在base为1时(压缩比平均为1.51:1.40)，说明值得考虑实现。结果还表明有两个以上的base并不会为这些工作负载提供额外的压缩比改进，因为存储更多的base的开销要高于压缩更多cache line的好处。</p><p>注意：Figure 6中我们发现有0个base，这很必要，因为如果不考虑0个base，对于比如说最简单的全0数据，如果使用简单的压缩去冗余，不需要base，直接压缩到1byte，而base越多，显然，压缩率越低，并且增大存储开销。</p><p>那么，如何高效地找到两个base？不增加硬件的复杂度，或者说如何以最小的硬件复杂度寻找两个base来获得最大的压缩好处？下一节介绍</p><h3 id="B∆I-Refining-B-∆-with-Two-Bases-and-Minimal-Complexity"><a href="#B∆I-Refining-B-∆-with-Two-Bases-and-Minimal-Complexity" class="headerlink" title="B∆I: Refining B+∆ with Two Bases and Minimal Complexity"></a>B∆I: Refining B+∆ with Two Bases and Minimal Complexity</h3><p>我们发现，第二个base直接设置为0能够和任意选取任何一个vaule作为第二个base一样，为什么会这样？因为大多数情况下，是动态范围较小的宽值（比如指针）与窄值（比如小整数）混合，那么第一个base可以使用base+delta编码压缩动态范围较低的宽值，而第二个0 base则可以有效地压缩窄值。基于这一观察，我们额外增加一个隐式（implicit）的0 base来改进B+∆，称为Base-Delta-Immediate或B∆I压缩。</p><p>那么两个base的B+∆好还是B∆I好呢？又存在<strong>tradeoff</strong>。显然，B∆I有一个base是隐式的0，存储开销更小，这意味着对于用这两种技术都可压缩的cache line，B∆I的平均压缩率可能更高。有两个base的B+∆需要更多的存储空间来存储第二个base，但是可以压缩更多的cache line，因为base可以是任何value，从中选择最佳。到底哪个好呢？可能取决于cache line的模式，甲之砒霜，乙之蜜糖。关键时刻依然还是得实验来说话</p><p><img src="https://github.com/Malizhen/Malizhen.github.io/blob/master/images/BDI%EF%BC%9ABase-Delta-Immediate%20Compression/5.png?raw=true" alt="images"></p><p>Figure 7表明，虽然有个别负载B+∆的表现比B∆I好，但是总体来说还是B∆I的压缩比（1.53）高于B+∆（1.51），虽然不是高太多，但是考虑到B+∆有两个base，那就有比B∆I更复杂的硬件机制，所以认为缓存压缩设计还是应该基于B∆I的思想。</p><h2 id="Design"><a href="#Design" class="headerlink" title="Design"></a>Design</h2><h3 id="Compress"><a href="#Compress" class="headerlink" title="Compress"></a>Compress</h3><p>在具体的设计中，所有的可能压缩大小是静态已知的，如Table 2。如果cache line有多个压缩选项可用(例如，8-byte base 1-byte ∆或者Zeros压缩)，则Compression Selection 选择压缩cache line大小最小的一个（即选择压缩率最高的）。基于Table 2选择合适的压缩大小，Figure 8中所有压缩单元可并发执行。</p><p><img src="https://github.com/Malizhen/Malizhen.github.io/blob/master/images/BDI%EF%BC%9ABase-Delta-Immediate%20Compression/7.png?raw=true" alt="images"></p><p> <img src="https://github.com/Malizhen/Malizhen.github.io/blob/master/images/BDI%EF%BC%9ABase-Delta-Immediate%20Compression/8.png?raw=true" alt="images"> </p><p>Figure 9展示了32-byte的cache line在8-byte-base 1-byte-∆时压缩单元的情况，每个V通过减法器进行运算之后，判断是否每个V的运算结果∆前七位均为0或者1，如果是的话，cache line能够以该种模式（8-byte-base 1-byte-∆）存储，否则，说明至少有一个∆不能用1-byte表示，那么不压缩该cache line。</p><p><img src="https://github.com/Malizhen/Malizhen.github.io/blob/master/images/BDI%EF%BC%9ABase-Delta-Immediate%20Compression/6.png?raw=true" alt="images"></p><h3 id="Decompress"><a href="#Decompress" class="headerlink" title="Decompress"></a>Decompress</h3><p>解压的硬件设计很简单，如上文描述一样，就是一个减法器。如下图所示</p><p><img src="https://github.com/Malizhen/Malizhen.github.io/blob/master/images/BDI%EF%BC%9ABase-Delta-Immediate%20Compression/9.png?raw=true" alt="imges"></p><p>关于实现的更多细节，以及实验部分，如果感兴趣的话可以阅读原文，本文的分析重在了解基本思想。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Base-Delta-Immediate Compression:Practical Data Compression for On-Chip Caches。&lt;a href=&quot;https://dl.acm.org/citation.cfm?id=2370870&quot; targe
      
    
    </summary>
    
      <category term="论文阅读记录" scheme="http://malizhen.github.io/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E8%AE%B0%E5%BD%95/"/>
    
    
      <category term="compression algorithm" scheme="http://malizhen.github.io/tags/compression-algorithm/"/>
    
  </entry>
  
  <entry>
    <title>重庆四人游</title>
    <link href="http://malizhen.github.io/2019/06/06/Chongqing/"/>
    <id>http://malizhen.github.io/2019/06/06/Chongqing/</id>
    <published>2019-06-06T01:44:35.540Z</published>
    <updated>2019-06-10T13:22:21.820Z</updated>
    
    <content type="html"><![CDATA[<p>2018年5月1日的前一天，我的小Z突然问我想不想五一去重庆，距离我俩上次旅行已经过去快三年，贫穷的大学时期，只是在2015年八月底去了一趟凤凰，好在自从小Z毕业工作以来，似乎异地恋也不再受限于没钱见面，哈哈哈，虽然自从我读研以来科研才是他的情敌。于是有了这次说走就走的旅行。</p><h2 id="前期准备"><a href="#前期准备" class="headerlink" title="前期准备"></a>前期准备</h2><h3 id="出行方式的选择"><a href="#出行方式的选择" class="headerlink" title="出行方式的选择"></a>出行方式的选择</h3><p>我们总共四个人，小姜和他女朋友都在湖南，小Z也是，我在武汉，所以最后我们决定长沙会合，然后坐飞机去重庆。买的五一当晚11点长沙到重庆的特价机票，票价不贵，500元左右，不同买票软件不一样，我发现的最实惠的是智行，比携程飞猪等少大概80。这里真的要吐槽一下西部航空，返程买的奥凯航空，对比起来简直一个天上一个地下，西部航空没有免费行李托运额度，奥凯航空有，而且有充饥曲奇饼和水，hhh，曲奇饼超好吃，可惜产地俄罗斯，淘宝没找到有卖的。</p><p>还有，第一次坐飞机我发现自己不仅晕车居然还晕机，所以晕车的小伙伴坐飞机的话一定记得吃药。话说不管哪个航空公司空姐都人美心善，因为晕机不舒服，下飞机的时候满脸不开心，得到了空乘小姐姐的大大的笑容问候。</p><h3 id="关于住宿"><a href="#关于住宿" class="headerlink" title="关于住宿"></a>关于住宿</h3><p>全程不到两个小时，所以看来比起火车虽然贵点，但是性价比真是不知道高多少。5月1日抵达重庆的时候已经是次日凌晨，所以当晚的住宿定在江北国际机场附近，首选有接机服务的酒店，1日晚的酒店很一般，而且由于五一价钱还不便宜，接近三百，就不说店名了。因为商圈附近住宿都很贵，两个男孩子不想住民宿，最后2日晚选择住宿在南坪，南坪轻轨站附近的金凯斯精品酒店，接近三百一晚，酒店有些陈旧，但是房间面积很大，虽然这并没什么用，卫生间很小，期间马桶还坏了，不过胜在位置很好，从机场坐轻轨到南坪，轻轨站一出来就能看到这家酒店。五一这个价钱只能说无功无过吧。</p><p>之后的两个晚上住在我们东道主煦煦家哈哈哈，这就有了接下来几天连续爆肝用生命没日没夜地浪的契机hhhh。</p><h3 id="咳咳咳正文来了"><a href="#咳咳咳正文来了" class="headerlink" title="咳咳咳正文来了"></a>咳咳咳正文来了</h3><p>去重庆之前做的攻略，在有了李导（煦煦）加持之后都是浮云了，吃了超级正宗的重庆火锅，啊哈好像叫大队长火锅，晚上在路边摊吃的烧烤，虽然菜都从牵牵上弄下来变成了大锅菜的样子，卖相不太好，但是味道真的很棒。</p><p>去了各大网红景点，包括洪崖洞、解放碑、磁器口还有南山一棵树风景区。一个一个说吧，洪崖洞解放碑在一起，就晚上去夜景真的很棒，虽然洪崖洞不知道在地下多少层，当时人山人海，没有电梯，排队进入口，然后一层一层的楼梯走到腿快废了。</p><p><img src="https://raw.githubusercontent.com/Malizhen/Malizhen.github.io/master/images/chongqing/hongyadong.jpg" alt="images"></p><p>解放碑就是那种来了就必去拍张照的地方，hhh，我当时竟然有一种武汉大学校门口的错觉，永远好多人对着那个国立武汉大学咔擦咔擦。</p><p><img src="https://raw.githubusercontent.com/Malizhen/Malizhen.github.io/master/images/chongqing/jiefangbei.jpg" alt="images"></p><p>磁器口吧，有点不是很推荐，在一个在武汉待了五年的人看来，它就是另一个户部巷，一条小吃街也卖一些小玩意，东西很难吃而且很贵，不过有个酒庄老板超好，免费尝了好多酒，要不是坐飞机不能带，当时超想买一小罐女儿红。以上地方总结起来就是五一真的超级多人，多到无法想象的那种，寸步难行。</p><p>4号晚去的南山一棵树，因为假期最后一天，人不多，打车过去的，晚上俯瞰重庆夜景很美，基本照片都在这拍的hhh，原本计划去川美涂鸦一条街拍照的，最后时间不够了。</p><p><img src="https://raw.githubusercontent.com/Malizhen/Malizhen.github.io/master/images/chongqing/nanshan.jpg" alt="images"></p><p>5号租车去了奥陶纪，我们总共五个人，租车比跟团划算而且更方便，这里还是很推荐的，感觉像张家界和大型欢乐谷的结合体，有玻璃桥有很多高空项目，室内冰雪世界很美，虽然这个地方被抖音带火的，这两年才出名，还是去得很值。</p><p><img src="https://raw.githubusercontent.com/Malizhen/Malizhen.github.io/master/images/chongqing/aotaoji.jpg" alt="images"></p><h3 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h3><p>记了一堆流水账，最后想要矫情一下，旅途中的情侣难免会有些小矛盾，不过和小Z在一起的六年以来，很感谢他每次包容我的小性子，有时候觉得，遇到一个三观相合而且三观超正的小奶狗，只想每天多爱对方一点点，也许这就是那啥操蛋的异地恋维持的新鲜感吧，hhhh！</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;2018年5月1日的前一天，我的小Z突然问我想不想五一去重庆，距离我俩上次旅行已经过去快三年，贫穷的大学时期，只是在2015年八月底去了一趟凤凰，好在自从小Z毕业工作以来，似乎异地恋也不再受限于没钱见面，哈哈哈，虽然自从我读研以来科研才是他的情敌。于是有了这次说走就走的旅行
      
    
    </summary>
    
      <category term="随笔" scheme="http://malizhen.github.io/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
      <category term="旅游" scheme="http://malizhen.github.io/tags/%E6%97%85%E6%B8%B8/"/>
    
  </entry>
  
</feed>
